{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "from keras.layers import Input, merge, Conv2D, MaxPooling2D, UpSampling2D,Convolution2D ,BatchNormalization,Activation,concatenate\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler,ReduceLROnPlateau\n",
    "from keras import backend as K\n",
    "from keras.models import Model\n",
    "from keras.losses import binary_crossentropy\n",
    "from sklearn.utils import class_weight, shuffle\n",
    "img_width = 256\n",
    "img_height = 192\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'seaborn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-59abd69b71dd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstyle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'seaborn-white'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_style\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"white\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'seaborn'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "#import pandas as pd\n",
    "import gc\n",
    "import keras\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn-white')\n",
    "import seaborn as sns\n",
    "sns.set_style(\"white\")\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from skimage.transform import resize\n",
    "import tensorflow as tf\n",
    "import keras.backend as K\n",
    "from keras.losses import binary_crossentropy\n",
    "\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras import Model\n",
    "from keras.callbacks import  ModelCheckpoint\n",
    "from keras.layers import Input, Conv2D, Conv2DTranspose, MaxPooling2D, concatenate, Dropout,BatchNormalization\n",
    "from keras.layers import Conv2D, Concatenate, MaxPooling2D\n",
    "from keras.layers import UpSampling2D, Dropout, BatchNormalization\n",
    "from tqdm import tqdm_notebook\n",
    "from keras import initializers\n",
    "from keras import regularizers\n",
    "from keras import constraints\n",
    "from keras.utils import conv_utils\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.engine.topology import get_source_inputs\n",
    "from keras.engine import InputSpec\n",
    "from keras import backend as K\n",
    "from keras.layers import LeakyReLU\n",
    "from keras.layers import ZeroPadding2D\n",
    "from keras.losses import binary_crossentropy\n",
    "import keras.callbacks as callbacks\n",
    "from keras.callbacks import Callback\n",
    "from keras.applications.xception import Xception\n",
    "from keras.layers import multiply\n",
    "\n",
    "\n",
    "from keras import optimizers\n",
    "from keras.legacy import interfaces\n",
    "from keras.utils.generic_utils import get_custom_objects\n",
    "\n",
    "from keras.engine.topology import Input\n",
    "from keras.engine.training import Model\n",
    "from keras.layers.convolutional import Conv2D, UpSampling2D, Conv2DTranspose\n",
    "from keras.layers.core import Activation, SpatialDropout2D\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.layers import Input,Dropout,BatchNormalization,Activation,Add\n",
    "from keras.regularizers import l2\n",
    "from keras.layers.core import Dense, Lambda\n",
    "from keras.layers.merge import concatenate, add\n",
    "from keras.layers import GlobalAveragePooling2D, Reshape, Dense, multiply, Permute\n",
    "from keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_height,original_width = 256,256\n",
    "from albumentations import (\n",
    "    PadIfNeeded,\n",
    "    HorizontalFlip,\n",
    "    VerticalFlip,    \n",
    "    CenterCrop,    \n",
    "    Crop,\n",
    "    Compose,\n",
    "    Transpose,\n",
    "    RandomRotate90,\n",
    "    ShiftScaleRotate,\n",
    "    ElasticTransform,\n",
    "    GridDistortion, \n",
    "    OpticalDistortion,\n",
    "    RandomSizedCrop,\n",
    "    OneOf,\n",
    "    CLAHE,\n",
    "    RandomContrast,\n",
    "    RandomGamma,\n",
    "    RandomBrightness\n",
    ")\n",
    "aug = Compose([\n",
    "    VerticalFlip(p=0.5),              \n",
    "    HorizontalFlip(p=0.5), \n",
    "    GridDistortion(p=0.5),\n",
    "    ShiftScaleRotate(shift_limit=0.0625, scale_limit=0.50, rotate_limit=45, p=0.5),\n",
    "   # OneOf([\n",
    "        #ElasticTransform(p=0.5, alpha=120, sigma=120 * 0.05, alpha_affine=120 * 0.03),\n",
    "        GridDistortion(p=0.5),\n",
    "       # OpticalDistortion(p=1, distort_limit=2, shift_limit=0.5)                  \n",
    "       # ], p=0.8),\n",
    "    #RandomContrast(p=0.8),\n",
    "    #RandomBrightness(p=0.8),\n",
    "       # RandomGamma(p=0.8),\n",
    "    ],p=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class data_generator2016:\n",
    "    def create_train(train_path,label_path,data_info,batch_size,shape,augment=False):            \n",
    "            while True:                \n",
    "                dataset_info = shuffle(data_info)\n",
    "                for start in range(0,len(dataset_info),batch_size):\n",
    "                    end = min(start+batch_size,len(dataset_info))\n",
    "                    batch_images = []\n",
    "                    batch_labels = []\n",
    "                    x_train_batch = dataset_info[start:end]\n",
    "                    \n",
    "                    for i in range(len(x_train_batch)):\n",
    "                        #print(x_train_batch[i])\n",
    "                        image = data_generator2016.load_image(os.path.join(train_path,x_train_batch[i]),shape)\n",
    "                        #mask = data_generator.get_mask(x_train_batch[i],df,shape[:2])\n",
    "                        mask_name = x_train_batch[i].replace('.jpg','_Segmentation.png')\n",
    "                        #mask_name = x_train_batch[i].replace('.bmp','_lesion.bmp')\n",
    "                        mask = data_generator2016.load_image(os.path.join(label_path,mask_name),shape,True)\n",
    "                        if augment:\n",
    "                            image ,mask = data_generator2016.augment(image,mask)\n",
    "                        #image = np.expand_dims(image,axis=-1)\n",
    "                        mask = np.expand_dims(mask,axis=-1)\n",
    "                        batch_images.append(image)\n",
    "                        batch_labels.append(mask)\n",
    "\n",
    "                    yield np.array(batch_images,np.uint8)/255,np.round(np.array(batch_labels,np.uint8)/255)\n",
    "\n",
    "    def load_image(path,shape,is_mask=False):\n",
    "        img = cv2.imread(path)\n",
    "        if not is_mask:            \n",
    "            #img = img[:,:,0]\n",
    "            img = img\n",
    "           # img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
    "        else:\n",
    "            img = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "           #rint(img.shape)\n",
    "        img = cv2.resize(img,(shape[0],shape[1]))\n",
    "        return img\n",
    "    \n",
    "    def augment(image,mask):\n",
    "        augmented = aug(image=image,mask=mask)\n",
    "        image = augmented['image']\n",
    "        mask = augmented['mask']\n",
    "        return image,mask\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "class data_generator2017:\n",
    "    def create_train(train_path,label_path,data_info,batch_size,shape,augment=False):            \n",
    "            while True:                \n",
    "                dataset_info = shuffle(data_info)\n",
    "                for start in range(0,len(dataset_info),batch_size):\n",
    "                    end = min(start+batch_size,len(dataset_info))\n",
    "                    batch_images = []\n",
    "                    batch_labels = []\n",
    "                    x_train_batch = dataset_info[start:end]\n",
    "                    \n",
    "                    for i in range(len(x_train_batch)):\n",
    "                        #print(os.path.join(train_path,x_train_batch[i]))\n",
    "                        image = Image.open(os.path.join(train_path,x_train_batch[i]))\n",
    "                        image = data_generator2017.load_image(os.path.join(train_path,x_train_batch[i]),shape)\n",
    "                        #print(os.path.join(label_path,mask_name))\n",
    "                       #print(image)\n",
    "                        #mask = data_generator.get_mask(x_train_batch[i],df,shape[:2])\n",
    "                        mask_name = x_train_batch[i].replace('.jpg','_segmentation.png')\n",
    "                        #mask_name = x_train_batch[i].replace('.bmp','_lesion.bmp')\n",
    "                        #print(os.path.join(label_path,mask_name))\n",
    "                        mask = data_generator2017.load_image(os.path.join(label_path,mask_name),shape,True)\n",
    "                        if augment:\n",
    "                            image ,mask = data_generator2017.augment(image,mask)\n",
    "                        #image = np.expand_dims(image,axis=-1)\n",
    "                        mask = np.expand_dims(mask,axis=-1)\n",
    "                        batch_images.append(image)\n",
    "                        batch_labels.append(mask)\n",
    "\n",
    "                    yield np.array(batch_images,np.uint8)/255,np.round(np.array(batch_labels,np.uint8)/255)\n",
    "\n",
    "    def load_image(path,shape,is_mask=False):\n",
    "        img = cv2.imread(path)\n",
    "        if not is_mask:            \n",
    "            #img = img[:,:,0]\n",
    "            img = img \n",
    "            #img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
    "        else:\n",
    "            img = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "           #rint(img.shape)\n",
    "        img = cv2.resize(img,(shape[0],shape[1]))\n",
    "        return img\n",
    "    \n",
    "    def augment(image,mask):\n",
    "        augmented = aug(image=image,mask=mask)\n",
    "        image = augmented['image']\n",
    "        mask = augmented['mask']\n",
    "        return image,mask\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] 系统找不到指定的路径。: 'C:/Users/hyc/Desktop/skin_lesion/segmentation/2017/2017/train_img_resized/'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-97e531480ecc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mtest_label_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'C:/Users/hyc/Desktop/skin_lesion/segmentation/2017/2017/test_gt_resized/'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0mtrain_data_info\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[0mval_data_info\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] 系统找不到指定的路径。: 'C:/Users/hyc/Desktop/skin_lesion/segmentation/2017/2017/train_img_resized/'"
     ]
    }
   ],
   "source": [
    "#train_path = 'C:/Users/hyc/Desktop/skin_lesion/segmentation/seg_train/'\n",
    "#label_path = 'C:/Users/hyc/Desktop/skin_lesion/segmentation/train_gt/'\n",
    "#test_path = 'C:/Users/hyc/Desktop/skin_lesion/segmentation/seg_test/'\n",
    "#test_label_path = 'C:/Users/hyc/Desktop/skin_lesion/segmentation/test_gt/'\n",
    "\n",
    "train_path = 'C:/Users/hyc/Desktop/skin_lesion/segmentation/2017/train_img_resized/'\n",
    "label_path = 'C:/Users/hyc/Desktop/skin_lesion/segmentation//2017/train_gt_resized/'\n",
    "test_path = 'C:/Users/hyc/Desktop/skin_lesion/segmentation//2017/test_img_resized/'\n",
    "test_label_path = 'C:/Users/hyc/Desktop/skin_lesion/segmentation//2017/test_gt_resized/'\n",
    "\n",
    "train_data_info = os.listdir(train_path)\n",
    "val_data_info = os.listdir(test_path)\n",
    "\n",
    "train_generator = data_generator2017.create_train(train_path,label_path,train_data_info,8,(img_width,img_height),True)\n",
    "val_generator = data_generator2017.create_train(test_path,test_label_path,val_data_info,8,(img_width,img_height),False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_path = './PH2/img/'\n",
    "#label_path = './PH2/gt/'\n",
    "#train_data_info = os.listdir(train_path)[:160]\n",
    "#train_data_info = os.listdir(train_path)[:160]+os.listdir(train_path)[720:]\n",
    "#val_data_info = os.listdir(train_path)[160:]\n",
    "\n",
    "#train_path = 'C:/Users/hyc/Desktop/skin_lesion/segmentation/seg_train/'\n",
    "#label_path = 'C:/Users/hyc/Desktop/skin_lesion/segmentation/train_gt/'\n",
    "#test_path = 'C:/Users/hyc/Desktop/skin_lesion/segmentation/seg_test/'\n",
    "#test_label_path = 'C:/Users/hyc/Desktop/skin_lesion/segmentation/test_gt/'\n",
    "\n",
    "train_path = 'C:/Users/hyc/Desktop/skin_lesion/segmentation/polar_train/'\n",
    "label_path = 'C:/Users/hyc/Desktop/skin_lesion/segmentation/polar_train_mask/'\n",
    "test_path = 'C:/Users/hyc/Desktop/skin_lesion/segmentation/polar_test/'\n",
    "test_label_path = 'C:/Users/hyc/Desktop/skin_lesion/segmentation/polar_test_mask/'\n",
    "\n",
    "\n",
    "#train_data_info = os.listdir(train_path)\n",
    "#val_data_info = os.listdir(test_path)\n",
    "train_data_info = os.listdir(train_path)[:540]+os.listdir(train_path)[720:]\n",
    "val_data_info = os.listdir(train_path)[540:720]\n",
    "\n",
    "train_generator = data_generator2016.create_train(train_path,label_path,train_data_info,8,(img_width,img_height),True)\n",
    "val_generator = data_generator2016.create_train(train_path,label_path,val_data_info,8,(img_width,img_height),False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 192, 256, 3)\n"
     ]
    }
   ],
   "source": [
    "i,j = next(train_generator)\n",
    "print(i.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x190dac80978>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "demo = j[0,:,:,0]\n",
    "plt.imshow(demo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 192, 256, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x190db650668>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "demo = i[0,:,:,0]\n",
    "print(i.shape)\n",
    "plt.imshow(demo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SnapshotCallbackBuilder:\n",
    "    def __init__(self, nb_epochs, nb_snapshots, init_lr=0.1):\n",
    "        self.T = nb_epochs\n",
    "        self.M = nb_snapshots\n",
    "        self.alpha_zero = init_lr\n",
    "\n",
    "    def get_callbacks(self, model_prefix='Model'):\n",
    "\n",
    "        callback_list = [\n",
    "            callbacks.ModelCheckpoint(\"./keras.model\",monitor='val_dice_coef', \n",
    "                                   mode = 'max', save_best_only=True, verbose=1),\n",
    "            swa,\n",
    "            callbacks.LearningRateScheduler(schedule=self._cosine_anneal_schedule)\n",
    "        ]\n",
    "\n",
    "        return callback_list\n",
    "\n",
    "    def _cosine_anneal_schedule(self, t):\n",
    "        cos_inner = np.pi * (t % (self.T // self.M))  # t - 1 is used when t has 1-based indexing.\n",
    "        cos_inner /= self.T // self.M\n",
    "        cos_out = np.cos(cos_inner) + 1\n",
    "        return float(self.alpha_zero / 2 * cos_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/titu1994/keras-normalized-optimizers\n",
    "# Computes the L-2 norm of the gradient.\n",
    "def l2_norm(grad):\n",
    "    norm = K.sqrt(K.sum(K.square(grad))) + K.epsilon()\n",
    "    return norm\n",
    "\n",
    "class OptimizerWrapper(optimizers.Optimizer):\n",
    "\n",
    "    def __init__(self, optimizer):     \n",
    "        \n",
    "        self.optimizer = optimizers.get(optimizer)\n",
    "\n",
    "        # patch the `get_gradients` call\n",
    "        self._optimizer_get_gradients = self.optimizer.get_gradients\n",
    "\n",
    "    def get_gradients(self, loss, params):      \n",
    "        grads = self._optimizer_get_gradients(loss, params)\n",
    "        return grads\n",
    "\n",
    "    @interfaces.legacy_get_updates_support\n",
    "    def get_updates(self, loss, params):\n",
    "        # monkey patch `get_gradients`\n",
    "        self.optimizer.get_gradients = self.get_gradients\n",
    "\n",
    "        # get the updates\n",
    "        self.optimizer.get_updates(loss, params)\n",
    "\n",
    "        # undo monkey patch\n",
    "        self.optimizer.get_gradients = self._optimizer_get_gradients\n",
    "\n",
    "        return self.updates\n",
    "\n",
    "    def set_weights(self, weights):       \n",
    "        self.optimizer.set_weights(weights)\n",
    "\n",
    "    def get_weights(self):        \n",
    "        return self.optimizer.get_weights()\n",
    "\n",
    "    def get_config(self):       \n",
    "        # properties of NormalizedOptimizer\n",
    "        config = {'optimizer_name': self.optimizer.__class__.__name__.lower()}\n",
    "\n",
    "        # optimizer config\n",
    "        optimizer_config = {'optimizer_config': self.optimizer.get_config()}\n",
    "        return dict(list(optimizer_config.items()) + list(config.items()))\n",
    "\n",
    "    @property\n",
    "    def weights(self):\n",
    "        return self.optimizer.weights\n",
    "\n",
    "    @property\n",
    "    def updates(self):\n",
    "        return self.optimizer.updates\n",
    "\n",
    "    @classmethod\n",
    "    def from_config(cls, config):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    @classmethod\n",
    "    def set_normalization_function(cls, name, func):\n",
    "        global _NORMS\n",
    "        _NORMS[name] = func\n",
    "\n",
    "    @classmethod\n",
    "    def get_normalization_functions(cls):        \n",
    "        global _NORMS\n",
    "        return sorted(list(_NORMS.keys()))\n",
    "\n",
    "\n",
    "class NormalizedOptimizer(OptimizerWrapper):\n",
    "\n",
    "    def __init__(self, optimizer, normalization='l2'):       \n",
    "        super(NormalizedOptimizer, self).__init__(optimizer)\n",
    "\n",
    "        if normalization not in _NORMS:\n",
    "            raise ValueError('`normalization` must be one of %s.\\n' \n",
    "                             'Provided was \"%s\".' % (str(sorted(list(_NORMS.keys()))), normalization))\n",
    "\n",
    "        self.normalization = normalization\n",
    "        self.normalization_fn = _NORMS[normalization]\n",
    "        self.lr = K.variable(1e-3, name='lr')\n",
    "\n",
    "    def get_gradients(self, loss, params):       \n",
    "        grads = super(NormalizedOptimizer, self).get_gradients(loss, params)\n",
    "        grads = [grad / self.normalization_fn(grad) for grad in grads]\n",
    "        return grads\n",
    "\n",
    "    def get_config(self):        \n",
    "        # properties of NormalizedOptimizer\n",
    "        config = {'normalization': self.normalization}\n",
    "\n",
    "        # optimizer config\n",
    "        base_config = super(NormalizedOptimizer, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))\n",
    "\n",
    "    @classmethod\n",
    "    def from_config(cls, config):       \n",
    "        optimizer_config = {'class_name': config['optimizer_name'],\n",
    "                            'config': config['optimizer_config']}\n",
    "\n",
    "        optimizer = optimizers.get(optimizer_config)\n",
    "        normalization = config['normalization']\n",
    "\n",
    "        return cls(optimizer, normalization=normalization)\n",
    "\n",
    "\n",
    "_NORMS = {\n",
    "    'l2': l2_norm,\n",
    "}\n",
    "\n",
    "# register this optimizer to the global custom objects when it is imported\n",
    "get_custom_objects().update({'NormalizedOptimizer': NormalizedOptimizer})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SWA(keras.callbacks.Callback):\n",
    "    \n",
    "    def __init__(self, filepath, swa_epoch):\n",
    "        super(SWA, self).__init__()\n",
    "        self.filepath = filepath\n",
    "        self.swa_epoch = swa_epoch \n",
    "    \n",
    "    def on_train_begin(self, logs=None):\n",
    "        self.nb_epoch = self.params['epochs']\n",
    "        print('Stochastic weight averaging selected for last {} epochs.'\n",
    "              .format(self.nb_epoch - self.swa_epoch))\n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        \n",
    "        if epoch == self.swa_epoch:\n",
    "            self.swa_weights = self.model.get_weights()\n",
    "            \n",
    "        elif epoch > self.swa_epoch:    \n",
    "            for i in range(len(self.swa_weights)):\n",
    "                self.swa_weights[i] = (self.swa_weights[i] * \n",
    "                    (epoch - self.swa_epoch) + self.model.get_weights()[i])/((epoch - self.swa_epoch)  + 1)  \n",
    "\n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "    def on_train_end(self, logs=None):\n",
    "        self.model.set_weights(self.swa_weights)\n",
    "        print('Final model parameters set to stochastic weight average.')\n",
    "        self.model.save_weights(self.filepath)\n",
    "        print('Final stochastic averaged weights saved to file.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_coef(y_true, y_pred):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred = K.cast(y_pred, 'float32')\n",
    "    y_pred_f = K.cast(K.greater(K.flatten(y_pred), 0.5), 'float32')\n",
    "    intersection = y_true_f * y_pred_f\n",
    "    score = 2. * K.sum(intersection) / (K.sum(y_true_f) + K.sum(y_pred_f))\n",
    "    return score\n",
    "\n",
    "def dice_loss(y_true, y_pred):\n",
    "    smooth = 1.\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = y_true_f * y_pred_f\n",
    "    score = (2. * K.sum(intersection) + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "    return 1. - score\n",
    "\n",
    "def bce_dice_loss(y_true, y_pred):\n",
    "    return binary_crossentropy(y_true, y_pred) + dice_loss(y_true, y_pred)\n",
    "\n",
    "def bce_logdice_loss(y_true, y_pred):\n",
    "    return binary_crossentropy(y_true, y_pred) - K.log(1. - dice_loss(y_true, y_pred))\n",
    "\n",
    "def binary_focal_loss(y_true, y_pred):\n",
    "    # # # filter out \"ignore\" anchors\n",
    "    # anchor_state = K.max(y_true, axis=2)  # -1 for ignore, 0 for background, 1+ for objects\n",
    "    # indices = tf.where(K.not_equal(anchor_state, -1))\n",
    "    # y_true = tf.gather_nd(y_true, indices)\n",
    "    # y_pred = tf.gather_nd(y_pred, indices)\n",
    "\n",
    "    # compute the focal loss\n",
    "    # CE(p_t) = -log(p_t)\n",
    "    # FL(p_t) = -(1 - p_t) ** gamma * log(p_t)\n",
    "    alpha_factor = K.ones_like(y_true) * alpha\n",
    "    alpha_factor = tf.where(K.equal(y_true, 1), alpha_factor, 1 - alpha_factor)\n",
    "    focal_weight = tf.where(K.equal(y_true, 1), 1 - y_pred, y_pred)\n",
    "    focal_weight = alpha_factor * focal_weight ** gamma\n",
    "\n",
    "    loss = focal_weight * K.binary_crossentropy(y_true, y_pred)\n",
    "    return loss\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SnapshotCallbackBuilder:\n",
    "    def __init__(self, nb_epochs, nb_snapshots,round_, init_lr=0.1):\n",
    "        self.T = nb_epochs\n",
    "        self.M = nb_snapshots\n",
    "        self.alpha_zero = init_lr\n",
    "        self.round = round_\n",
    "\n",
    "    def get_callbacks(self, model_prefix='Model'):\n",
    "\n",
    "        callback_list = [\n",
    "            callbacks.ModelCheckpoint(\"./keras_{}.model\".format(self.round),monitor='val_loss', \n",
    "                                   mode = 'max', save_best_only=True, verbose=1),\n",
    "            swa,\n",
    "            callbacks.LearningRateScheduler(schedule=self._cosine_anneal_schedule)\n",
    "        ]\n",
    "\n",
    "        return callback_list\n",
    "\n",
    "    def _cosine_anneal_schedule(self, t):\n",
    "        cos_inner = np.pi * (t % (self.T // self.M))  # t - 1 is used when t has 1-based indexing.\n",
    "        cos_inner /= self.T // self.M\n",
    "        cos_out = np.cos(cos_inner) + 1\n",
    "        return float(self.alpha_zero / 2 * cos_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 192, 256, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1 (Conv2D)           (None, 95, 127, 32)  864         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1_bn (BatchNormaliza (None, 95, 127, 32)  128         block1_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1_act (Activation)   (None, 95, 127, 32)  0           block1_conv1_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2 (Conv2D)           (None, 93, 125, 64)  18432       block1_conv1_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2_bn (BatchNormaliza (None, 93, 125, 64)  256         block1_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2_act (Activation)   (None, 93, 125, 64)  0           block1_conv2_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv1 (SeparableConv2 (None, 93, 125, 128) 8768        block1_conv2_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv1_bn (BatchNormal (None, 93, 125, 128) 512         block2_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv2_act (Activation (None, 93, 125, 128) 0           block2_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv2 (SeparableConv2 (None, 93, 125, 128) 17536       block2_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv2_bn (BatchNormal (None, 93, 125, 128) 512         block2_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 47, 63, 128)  8192        block1_conv2_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block2_pool (MaxPooling2D)      (None, 47, 63, 128)  0           block2_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 47, 63, 128)  512         conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 47, 63, 128)  0           block2_pool[0][0]                \n",
      "                                                                 batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv1_act (Activation (None, 47, 63, 128)  0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv1 (SeparableConv2 (None, 47, 63, 256)  33920       block3_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv1_bn (BatchNormal (None, 47, 63, 256)  1024        block3_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv2_act (Activation (None, 47, 63, 256)  0           block3_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv2 (SeparableConv2 (None, 47, 63, 256)  67840       block3_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv2_bn (BatchNormal (None, 47, 63, 256)  1024        block3_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 24, 32, 256)  32768       add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block3_pool (MaxPooling2D)      (None, 24, 32, 256)  0           block3_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 24, 32, 256)  1024        conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 24, 32, 256)  0           block3_pool[0][0]                \n",
      "                                                                 batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv1_act (Activation (None, 24, 32, 256)  0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv1 (SeparableConv2 (None, 24, 32, 728)  188672      block4_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv1_bn (BatchNormal (None, 24, 32, 728)  2912        block4_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv2_act (Activation (None, 24, 32, 728)  0           block4_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv2 (SeparableConv2 (None, 24, 32, 728)  536536      block4_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv2_bn (BatchNormal (None, 24, 32, 728)  2912        block4_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 12, 16, 728)  186368      add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block4_pool (MaxPooling2D)      (None, 12, 16, 728)  0           block4_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 12, 16, 728)  2912        conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 12, 16, 728)  0           block4_pool[0][0]                \n",
      "                                                                 batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv1_act (Activation (None, 12, 16, 728)  0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv1 (SeparableConv2 (None, 12, 16, 728)  536536      block5_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv1_bn (BatchNormal (None, 12, 16, 728)  2912        block5_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv2_act (Activation (None, 12, 16, 728)  0           block5_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv2 (SeparableConv2 (None, 12, 16, 728)  536536      block5_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv2_bn (BatchNormal (None, 12, 16, 728)  2912        block5_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv3_act (Activation (None, 12, 16, 728)  0           block5_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv3 (SeparableConv2 (None, 12, 16, 728)  536536      block5_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv3_bn (BatchNormal (None, 12, 16, 728)  2912        block5_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 12, 16, 728)  0           block5_sepconv3_bn[0][0]         \n",
      "                                                                 add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv1_act (Activation (None, 12, 16, 728)  0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv1 (SeparableConv2 (None, 12, 16, 728)  536536      block6_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv1_bn (BatchNormal (None, 12, 16, 728)  2912        block6_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv2_act (Activation (None, 12, 16, 728)  0           block6_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv2 (SeparableConv2 (None, 12, 16, 728)  536536      block6_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv2_bn (BatchNormal (None, 12, 16, 728)  2912        block6_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv3_act (Activation (None, 12, 16, 728)  0           block6_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv3 (SeparableConv2 (None, 12, 16, 728)  536536      block6_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv3_bn (BatchNormal (None, 12, 16, 728)  2912        block6_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 12, 16, 728)  0           block6_sepconv3_bn[0][0]         \n",
      "                                                                 add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv1_act (Activation (None, 12, 16, 728)  0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv1 (SeparableConv2 (None, 12, 16, 728)  536536      block7_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv1_bn (BatchNormal (None, 12, 16, 728)  2912        block7_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv2_act (Activation (None, 12, 16, 728)  0           block7_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv2 (SeparableConv2 (None, 12, 16, 728)  536536      block7_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv2_bn (BatchNormal (None, 12, 16, 728)  2912        block7_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv3_act (Activation (None, 12, 16, 728)  0           block7_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv3 (SeparableConv2 (None, 12, 16, 728)  536536      block7_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv3_bn (BatchNormal (None, 12, 16, 728)  2912        block7_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 12, 16, 728)  0           block7_sepconv3_bn[0][0]         \n",
      "                                                                 add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv1_act (Activation (None, 12, 16, 728)  0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv1 (SeparableConv2 (None, 12, 16, 728)  536536      block8_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv1_bn (BatchNormal (None, 12, 16, 728)  2912        block8_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv2_act (Activation (None, 12, 16, 728)  0           block8_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv2 (SeparableConv2 (None, 12, 16, 728)  536536      block8_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv2_bn (BatchNormal (None, 12, 16, 728)  2912        block8_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv3_act (Activation (None, 12, 16, 728)  0           block8_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv3 (SeparableConv2 (None, 12, 16, 728)  536536      block8_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv3_bn (BatchNormal (None, 12, 16, 728)  2912        block8_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 12, 16, 728)  0           block8_sepconv3_bn[0][0]         \n",
      "                                                                 add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv1_act (Activation (None, 12, 16, 728)  0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "block9_sepconv1 (SeparableConv2 (None, 12, 16, 728)  536536      block9_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv1_bn (BatchNormal (None, 12, 16, 728)  2912        block9_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv2_act (Activation (None, 12, 16, 728)  0           block9_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv2 (SeparableConv2 (None, 12, 16, 728)  536536      block9_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv2_bn (BatchNormal (None, 12, 16, 728)  2912        block9_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv3_act (Activation (None, 12, 16, 728)  0           block9_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv3 (SeparableConv2 (None, 12, 16, 728)  536536      block9_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv3_bn (BatchNormal (None, 12, 16, 728)  2912        block9_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 12, 16, 728)  0           block9_sepconv3_bn[0][0]         \n",
      "                                                                 add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv1_act (Activatio (None, 12, 16, 728)  0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv1 (SeparableConv (None, 12, 16, 728)  536536      block10_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv1_bn (BatchNorma (None, 12, 16, 728)  2912        block10_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv2_act (Activatio (None, 12, 16, 728)  0           block10_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv2 (SeparableConv (None, 12, 16, 728)  536536      block10_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv2_bn (BatchNorma (None, 12, 16, 728)  2912        block10_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv3_act (Activatio (None, 12, 16, 728)  0           block10_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv3 (SeparableConv (None, 12, 16, 728)  536536      block10_sepconv3_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv3_bn (BatchNorma (None, 12, 16, 728)  2912        block10_sepconv3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 12, 16, 728)  0           block10_sepconv3_bn[0][0]        \n",
      "                                                                 add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv1_act (Activatio (None, 12, 16, 728)  0           add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv1 (SeparableConv (None, 12, 16, 728)  536536      block11_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv1_bn (BatchNorma (None, 12, 16, 728)  2912        block11_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv2_act (Activatio (None, 12, 16, 728)  0           block11_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv2 (SeparableConv (None, 12, 16, 728)  536536      block11_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv2_bn (BatchNorma (None, 12, 16, 728)  2912        block11_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv3_act (Activatio (None, 12, 16, 728)  0           block11_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv3 (SeparableConv (None, 12, 16, 728)  536536      block11_sepconv3_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv3_bn (BatchNorma (None, 12, 16, 728)  2912        block11_sepconv3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 12, 16, 728)  0           block11_sepconv3_bn[0][0]        \n",
      "                                                                 add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv1_act (Activatio (None, 12, 16, 728)  0           add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv1 (SeparableConv (None, 12, 16, 728)  536536      block12_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv1_bn (BatchNorma (None, 12, 16, 728)  2912        block12_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv2_act (Activatio (None, 12, 16, 728)  0           block12_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv2 (SeparableConv (None, 12, 16, 728)  536536      block12_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv2_bn (BatchNorma (None, 12, 16, 728)  2912        block12_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv3_act (Activatio (None, 12, 16, 728)  0           block12_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv3 (SeparableConv (None, 12, 16, 728)  536536      block12_sepconv3_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv3_bn (BatchNorma (None, 12, 16, 728)  2912        block12_sepconv3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 12, 16, 728)  0           block12_sepconv3_bn[0][0]        \n",
      "                                                                 add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv1_act (Activatio (None, 12, 16, 728)  0           add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv1 (SeparableConv (None, 12, 16, 728)  536536      block13_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv1_bn (BatchNorma (None, 12, 16, 728)  2912        block13_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv2_act (Activatio (None, 12, 16, 728)  0           block13_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv2 (SeparableConv (None, 12, 16, 1024) 752024      block13_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv2_bn (BatchNorma (None, 12, 16, 1024) 4096        block13_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)       (None, 12, 16, 1024) 0           block13_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 6, 8, 1024)   0           leaky_re_lu_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 6, 8, 1024)   0           max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 6, 8, 512)    4719104     dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)       (None, 6, 8, 512)    0           conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 6, 8, 512)    2048        leaky_re_lu_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 6, 8, 512)    2359808     batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 6, 8, 512)    2048        conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)       (None, 6, 8, 512)    0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 6, 8, 512)    2359808     leaky_re_lu_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 6, 8, 512)    2048        conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 6, 8, 512)    2048        conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_13 (Add)                    (None, 6, 8, 512)    0           batch_normalization_8[0][0]      \n",
      "                                                                 batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)       (None, 6, 8, 512)    0           add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 6, 8, 512)    2048        leaky_re_lu_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 6, 8, 512)    2359808     batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 6, 8, 512)    2048        conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)       (None, 6, 8, 512)    0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 6, 8, 512)    2359808     leaky_re_lu_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 6, 8, 512)    2048        conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 6, 8, 512)    2048        add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "add_14 (Add)                    (None, 6, 8, 512)    0           batch_normalization_12[0][0]     \n",
      "                                                                 batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)       (None, 6, 8, 512)    0           add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTrans (None, 12, 16, 256)  1179904     leaky_re_lu_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 12, 16, 1280) 0           conv2d_transpose_1[0][0]         \n",
      "                                                                 leaky_re_lu_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 12, 16, 1280) 0           concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 12, 16, 256)  2949376     dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)       (None, 12, 16, 256)  0           conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 12, 16, 256)  1024        leaky_re_lu_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 12, 16, 256)  590080      batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 12, 16, 256)  1024        conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_8 (LeakyReLU)       (None, 12, 16, 256)  0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 12, 16, 256)  590080      leaky_re_lu_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 12, 16, 256)  1024        conv2d_12[0][0]                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 12, 16, 256)  1024        conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_15 (Add)                    (None, 12, 16, 256)  0           batch_normalization_16[0][0]     \n",
      "                                                                 batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_9 (LeakyReLU)       (None, 12, 16, 256)  0           add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 12, 16, 256)  1024        leaky_re_lu_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 12, 16, 256)  590080      batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 12, 16, 256)  1024        conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_10 (LeakyReLU)      (None, 12, 16, 256)  0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 12, 16, 256)  590080      leaky_re_lu_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 12, 16, 256)  1024        conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 12, 16, 256)  1024        add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "add_16 (Add)                    (None, 12, 16, 256)  0           batch_normalization_20[0][0]     \n",
      "                                                                 batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_11 (LeakyReLU)      (None, 12, 16, 256)  0           add_16[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTrans (None, 24, 32, 128)  295040      leaky_re_lu_11[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 24, 32, 856)  0           conv2d_transpose_2[0][0]         \n",
      "                                                                 block4_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 24, 32, 856)  0           concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 24, 32, 128)  986240      dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_12 (LeakyReLU)      (None, 24, 32, 128)  0           conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 24, 32, 128)  512         leaky_re_lu_12[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 24, 32, 128)  147584      batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 24, 32, 128)  512         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_13 (LeakyReLU)      (None, 24, 32, 128)  0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 24, 32, 128)  147584      leaky_re_lu_13[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 24, 32, 128)  512         conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 24, 32, 128)  512         conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_17 (Add)                    (None, 24, 32, 128)  0           batch_normalization_24[0][0]     \n",
      "                                                                 batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_14 (LeakyReLU)      (None, 24, 32, 128)  0           add_17[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 24, 32, 128)  512         leaky_re_lu_14[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 24, 32, 128)  147584      batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 24, 32, 128)  512         conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_15 (LeakyReLU)      (None, 24, 32, 128)  0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 24, 32, 128)  147584      leaky_re_lu_15[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 24, 32, 128)  512         conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 24, 32, 128)  512         add_17[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "add_18 (Add)                    (None, 24, 32, 128)  0           batch_normalization_28[0][0]     \n",
      "                                                                 batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_16 (LeakyReLU)      (None, 24, 32, 128)  0           add_18[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_3 (Conv2DTrans (None, 48, 64, 64)   73792       leaky_re_lu_16[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_1 (ZeroPadding2D (None, 48, 64, 256)  0           block3_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 48, 64, 320)  0           conv2d_transpose_3[0][0]         \n",
      "                                                                 zero_padding2d_1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 48, 64, 320)  0           concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 48, 64, 64)   184384      dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_17 (LeakyReLU)      (None, 48, 64, 64)   0           conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 48, 64, 64)   256         leaky_re_lu_17[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 48, 64, 64)   36928       batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 48, 64, 64)   256         conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_18 (LeakyReLU)      (None, 48, 64, 64)   0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 48, 64, 64)   36928       leaky_re_lu_18[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 48, 64, 64)   256         conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 48, 64, 64)   256         conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_19 (Add)                    (None, 48, 64, 64)   0           batch_normalization_32[0][0]     \n",
      "                                                                 batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_19 (LeakyReLU)      (None, 48, 64, 64)   0           add_19[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 48, 64, 64)   256         leaky_re_lu_19[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 48, 64, 64)   36928       batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 48, 64, 64)   256         conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_20 (LeakyReLU)      (None, 48, 64, 64)   0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 48, 64, 64)   36928       leaky_re_lu_20[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 48, 64, 64)   256         conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 48, 64, 64)   256         add_19[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "add_20 (Add)                    (None, 48, 64, 64)   0           batch_normalization_36[0][0]     \n",
      "                                                                 batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_21 (LeakyReLU)      (None, 48, 64, 64)   0           add_20[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_4 (Conv2DTrans (None, 96, 128, 32)  18464       leaky_re_lu_21[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_2 (ZeroPadding2D (None, 96, 128, 128) 0           block2_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 96, 128, 160) 0           conv2d_transpose_4[0][0]         \n",
      "                                                                 zero_padding2d_2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 96, 128, 160) 0           concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 96, 128, 32)  46112       dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_22 (LeakyReLU)      (None, 96, 128, 32)  0           conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 96, 128, 32)  128         leaky_re_lu_22[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 96, 128, 32)  9248        batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 96, 128, 32)  128         conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_23 (LeakyReLU)      (None, 96, 128, 32)  0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 96, 128, 32)  9248        leaky_re_lu_23[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 96, 128, 32)  128         conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 96, 128, 32)  128         conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_21 (Add)                    (None, 96, 128, 32)  0           batch_normalization_40[0][0]     \n",
      "                                                                 batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_24 (LeakyReLU)      (None, 96, 128, 32)  0           add_21[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 96, 128, 32)  128         leaky_re_lu_24[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 96, 128, 32)  9248        batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, 96, 128, 32)  128         conv2d_28[0][0]                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_25 (LeakyReLU)      (None, 96, 128, 32)  0           batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 96, 128, 32)  9248        leaky_re_lu_25[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, 96, 128, 32)  128         conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, 96, 128, 32)  128         add_21[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "add_22 (Add)                    (None, 96, 128, 32)  0           batch_normalization_44[0][0]     \n",
      "                                                                 batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_26 (LeakyReLU)      (None, 96, 128, 32)  0           add_22[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_5 (Conv2DTrans (None, 192, 256, 16) 4624        leaky_re_lu_26[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 192, 256, 16) 0           conv2d_transpose_5[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 192, 256, 16) 2320        dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_27 (LeakyReLU)      (None, 192, 256, 16) 0           conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, 192, 256, 16) 64          leaky_re_lu_27[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 192, 256, 16) 2320        batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, 192, 256, 16) 64          conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_28 (LeakyReLU)      (None, 192, 256, 16) 0           batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 192, 256, 16) 2320        leaky_re_lu_28[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, 192, 256, 16) 64          conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, 192, 256, 16) 64          conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_23 (Add)                    (None, 192, 256, 16) 0           batch_normalization_48[0][0]     \n",
      "                                                                 batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_29 (LeakyReLU)      (None, 192, 256, 16) 0           add_23[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, 192, 256, 16) 64          leaky_re_lu_29[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 192, 256, 16) 2320        batch_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNo (None, 192, 256, 16) 64          conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_30 (LeakyReLU)      (None, 192, 256, 16) 0           batch_normalization_51[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 192, 256, 16) 2320        leaky_re_lu_30[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_52 (BatchNo (None, 192, 256, 16) 64          conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, 192, 256, 16) 64          add_23[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "add_24 (Add)                    (None, 192, 256, 16) 0           batch_normalization_52[0][0]     \n",
      "                                                                 batch_normalization_50[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_31 (LeakyReLU)      (None, 192, 256, 16) 0           add_24[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 192, 256, 16) 0           leaky_re_lu_31[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 192, 256, 1)  17          dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 192, 256, 1)  0           conv2d_35[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 38,431,449\n",
      "Trainable params: 38,370,009\n",
      "Non-trainable params: 61,440\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "K.clear_session()\n",
    "sgd = SGD(0.01, momentum=0.9, nesterov=True)\n",
    "sgd = NormalizedOptimizer(sgd, normalization='l2')\n",
    "model =UXception(input_shape=(img_height,img_width,3))\n",
    "model.summary()\n",
    "model.compile(loss=bce_dice_loss, optimizer=sgd, metrics=[dice_coef,'acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4.0\n",
      "2.1.5\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      " - 70s - loss: 0.4694 - dice_coef: 0.8287 - acc: 0.9066 - val_loss: 3.7535 - val_dice_coef: 0.7027 - val_acc: 0.7474\n",
      "\n",
      "Epoch 00001: val_dice_coef improved from -inf to 0.70274, saving model to ./keras_0.model\n",
      "Epoch 2/50\n",
      " - 60s - loss: 0.3183 - dice_coef: 0.8836 - acc: 0.9388 - val_loss: 0.7138 - val_dice_coef: 0.8582 - val_acc: 0.9075\n",
      "\n",
      "Epoch 00002: val_dice_coef improved from 0.70274 to 0.85822, saving model to ./keras_0.model\n",
      "Epoch 3/50\n",
      " - 60s - loss: 0.2778 - dice_coef: 0.9016 - acc: 0.9472 - val_loss: 0.6785 - val_dice_coef: 0.8891 - val_acc: 0.9299\n",
      "\n",
      "Epoch 00003: val_dice_coef improved from 0.85822 to 0.88912, saving model to ./keras_0.model\n",
      "Epoch 4/50\n",
      " - 60s - loss: 0.2898 - dice_coef: 0.8945 - acc: 0.9467 - val_loss: 0.6089 - val_dice_coef: 0.8690 - val_acc: 0.9119\n",
      "\n",
      "Epoch 00004: val_dice_coef did not improve\n",
      "Epoch 5/50\n",
      " - 63s - loss: 0.2407 - dice_coef: 0.9125 - acc: 0.9543 - val_loss: 0.9331 - val_dice_coef: 0.7876 - val_acc: 0.8543\n",
      "\n",
      "Epoch 00005: val_dice_coef did not improve\n",
      "Epoch 6/50\n",
      " - 60s - loss: 0.2198 - dice_coef: 0.9211 - acc: 0.9573 - val_loss: 0.4005 - val_dice_coef: 0.8874 - val_acc: 0.9299\n",
      "\n",
      "Epoch 00006: val_dice_coef did not improve\n",
      "Epoch 7/50\n",
      " - 62s - loss: 0.2079 - dice_coef: 0.9223 - acc: 0.9595 - val_loss: 0.3733 - val_dice_coef: 0.9076 - val_acc: 0.9422\n",
      "\n",
      "Epoch 00007: val_dice_coef improved from 0.88912 to 0.90760, saving model to ./keras_0.model\n",
      "Epoch 8/50\n",
      " - 63s - loss: 0.2091 - dice_coef: 0.9236 - acc: 0.9599 - val_loss: 0.3421 - val_dice_coef: 0.8929 - val_acc: 0.9350\n",
      "\n",
      "Epoch 00008: val_dice_coef did not improve\n",
      "Epoch 9/50\n",
      " - 60s - loss: 0.1967 - dice_coef: 0.9260 - acc: 0.9620 - val_loss: 0.4497 - val_dice_coef: 0.8820 - val_acc: 0.9198\n",
      "\n",
      "Epoch 00009: val_dice_coef did not improve\n",
      "Epoch 10/50\n",
      " - 63s - loss: 0.2013 - dice_coef: 0.9273 - acc: 0.9602 - val_loss: 0.2839 - val_dice_coef: 0.9110 - val_acc: 0.9446\n",
      "\n",
      "Epoch 00010: val_dice_coef improved from 0.90760 to 0.91099, saving model to ./keras_0.model\n",
      "Epoch 11/50\n",
      " - 60s - loss: 0.1754 - dice_coef: 0.9345 - acc: 0.9655 - val_loss: 0.3346 - val_dice_coef: 0.9026 - val_acc: 0.9384\n",
      "\n",
      "Epoch 00011: val_dice_coef did not improve\n",
      "Epoch 12/50\n",
      " - 63s - loss: 0.1873 - dice_coef: 0.9308 - acc: 0.9643 - val_loss: 0.2735 - val_dice_coef: 0.9096 - val_acc: 0.9435\n",
      "\n",
      "Epoch 00012: val_dice_coef did not improve\n",
      "Epoch 13/50\n",
      " - 63s - loss: 0.1747 - dice_coef: 0.9356 - acc: 0.9661 - val_loss: 0.3794 - val_dice_coef: 0.8982 - val_acc: 0.9346\n",
      "\n",
      "Epoch 00013: val_dice_coef did not improve\n",
      "Epoch 14/50\n",
      " - 61s - loss: 0.1765 - dice_coef: 0.9361 - acc: 0.9655 - val_loss: 0.3442 - val_dice_coef: 0.8983 - val_acc: 0.9374\n",
      "\n",
      "Epoch 00014: val_dice_coef did not improve\n",
      "Epoch 15/50\n",
      " - 62s - loss: 0.1594 - dice_coef: 0.9401 - acc: 0.9686 - val_loss: 0.2433 - val_dice_coef: 0.9191 - val_acc: 0.9515\n",
      "\n",
      "Epoch 00015: val_dice_coef improved from 0.91099 to 0.91909, saving model to ./keras_0.model\n",
      "Epoch 16/50\n",
      " - 61s - loss: 0.1698 - dice_coef: 0.9361 - acc: 0.9669 - val_loss: 0.3748 - val_dice_coef: 0.8798 - val_acc: 0.9229\n",
      "\n",
      "Epoch 00016: val_dice_coef did not improve\n",
      "Epoch 17/50\n",
      " - 62s - loss: 0.1603 - dice_coef: 0.9412 - acc: 0.9682 - val_loss: 0.2984 - val_dice_coef: 0.9085 - val_acc: 0.9443\n",
      "\n",
      "Epoch 00017: val_dice_coef did not improve\n",
      "Epoch 18/50\n",
      " - 65s - loss: 0.1681 - dice_coef: 0.9376 - acc: 0.9678 - val_loss: 0.2606 - val_dice_coef: 0.9090 - val_acc: 0.9469\n",
      "\n",
      "Epoch 00018: val_dice_coef did not improve\n",
      "Epoch 19/50\n",
      " - 62s - loss: 0.1563 - dice_coef: 0.9422 - acc: 0.9694 - val_loss: 0.2649 - val_dice_coef: 0.9140 - val_acc: 0.9476\n",
      "\n",
      "Epoch 00019: val_dice_coef did not improve\n",
      "Epoch 20/50\n",
      " - 63s - loss: 0.1623 - dice_coef: 0.9403 - acc: 0.9686 - val_loss: 0.3158 - val_dice_coef: 0.8984 - val_acc: 0.9354\n",
      "\n",
      "Epoch 00020: val_dice_coef did not improve\n",
      "Epoch 21/50\n",
      " - 63s - loss: 0.1486 - dice_coef: 0.9445 - acc: 0.9707 - val_loss: 0.2547 - val_dice_coef: 0.9116 - val_acc: 0.9501\n",
      "\n",
      "Epoch 00021: val_dice_coef did not improve\n",
      "Epoch 22/50\n",
      " - 63s - loss: 0.1512 - dice_coef: 0.9439 - acc: 0.9703 - val_loss: 0.3617 - val_dice_coef: 0.9012 - val_acc: 0.9339\n",
      "\n",
      "Epoch 00022: val_dice_coef did not improve\n",
      "Epoch 23/50\n",
      " - 63s - loss: 0.1492 - dice_coef: 0.9449 - acc: 0.9706 - val_loss: 0.2597 - val_dice_coef: 0.9128 - val_acc: 0.9461\n",
      "\n",
      "Epoch 00023: val_dice_coef did not improve\n",
      "Epoch 24/50\n",
      " - 62s - loss: 0.1409 - dice_coef: 0.9471 - acc: 0.9724 - val_loss: 0.3273 - val_dice_coef: 0.8928 - val_acc: 0.9380\n",
      "\n",
      "Epoch 00024: val_dice_coef did not improve\n",
      "Epoch 25/50\n",
      " - 63s - loss: 0.1534 - dice_coef: 0.9435 - acc: 0.9692 - val_loss: 0.3499 - val_dice_coef: 0.8862 - val_acc: 0.9234\n",
      "\n",
      "Epoch 00025: val_dice_coef did not improve\n",
      "Epoch 26/50\n",
      " - 63s - loss: 0.1369 - dice_coef: 0.9485 - acc: 0.9725 - val_loss: 0.2770 - val_dice_coef: 0.8960 - val_acc: 0.9427\n",
      "\n",
      "Epoch 00026: val_dice_coef did not improve\n",
      "Epoch 27/50\n",
      " - 62s - loss: 0.1372 - dice_coef: 0.9491 - acc: 0.9733 - val_loss: 0.3004 - val_dice_coef: 0.9056 - val_acc: 0.9360\n",
      "\n",
      "Epoch 00027: val_dice_coef did not improve\n",
      "Epoch 28/50\n",
      " - 64s - loss: 0.1402 - dice_coef: 0.9474 - acc: 0.9718 - val_loss: 0.2578 - val_dice_coef: 0.9128 - val_acc: 0.9491\n",
      "\n",
      "Epoch 00028: val_dice_coef did not improve\n",
      "Epoch 29/50\n",
      " - 64s - loss: 0.1354 - dice_coef: 0.9501 - acc: 0.9734 - val_loss: 0.5241 - val_dice_coef: 0.8157 - val_acc: 0.9028\n",
      "\n",
      "Epoch 00029: val_dice_coef did not improve\n",
      "Epoch 30/50\n",
      " - 62s - loss: 0.1375 - dice_coef: 0.9497 - acc: 0.9733 - val_loss: 0.2249 - val_dice_coef: 0.9218 - val_acc: 0.9538\n",
      "\n",
      "Epoch 00030: val_dice_coef improved from 0.91909 to 0.92176, saving model to ./keras_0.model\n",
      "Epoch 31/50\n",
      " - 64s - loss: 0.1325 - dice_coef: 0.9500 - acc: 0.9741 - val_loss: 0.3018 - val_dice_coef: 0.8915 - val_acc: 0.9362\n",
      "\n",
      "Epoch 00031: val_dice_coef did not improve\n",
      "Epoch 32/50\n",
      " - 60s - loss: 0.1368 - dice_coef: 0.9490 - acc: 0.9727 - val_loss: 0.2860 - val_dice_coef: 0.9078 - val_acc: 0.9464\n",
      "\n",
      "Epoch 00032: val_dice_coef did not improve\n",
      "Epoch 33/50\n",
      " - 63s - loss: 0.1359 - dice_coef: 0.9492 - acc: 0.9734 - val_loss: 0.2375 - val_dice_coef: 0.9230 - val_acc: 0.9511\n",
      "\n",
      "Epoch 00033: val_dice_coef improved from 0.92176 to 0.92302, saving model to ./keras_0.model\n",
      "Epoch 34/50\n",
      " - 64s - loss: 0.1404 - dice_coef: 0.9483 - acc: 0.9726 - val_loss: 0.3216 - val_dice_coef: 0.9064 - val_acc: 0.9413\n",
      "\n",
      "Epoch 00034: val_dice_coef did not improve\n",
      "Epoch 35/50\n",
      " - 62s - loss: 0.1247 - dice_coef: 0.9531 - acc: 0.9750 - val_loss: 0.2737 - val_dice_coef: 0.9037 - val_acc: 0.9440\n",
      "\n",
      "Epoch 00035: val_dice_coef did not improve\n",
      "Epoch 36/50\n",
      " - 65s - loss: 0.1274 - dice_coef: 0.9524 - acc: 0.9748 - val_loss: 0.3467 - val_dice_coef: 0.8898 - val_acc: 0.9350\n",
      "\n",
      "Epoch 00036: val_dice_coef did not improve\n",
      "Epoch 37/50\n",
      " - 61s - loss: 0.1289 - dice_coef: 0.9530 - acc: 0.9744 - val_loss: 0.2409 - val_dice_coef: 0.9140 - val_acc: 0.9508\n",
      "\n",
      "Epoch 00037: val_dice_coef did not improve\n",
      "Epoch 38/50\n",
      " - 63s - loss: 0.1366 - dice_coef: 0.9482 - acc: 0.9736 - val_loss: 0.3501 - val_dice_coef: 0.8884 - val_acc: 0.9276\n",
      "\n",
      "Epoch 00038: val_dice_coef did not improve\n",
      "Epoch 39/50\n",
      " - 62s - loss: 0.1274 - dice_coef: 0.9523 - acc: 0.9747 - val_loss: 0.2437 - val_dice_coef: 0.9224 - val_acc: 0.9506\n",
      "\n",
      "Epoch 00039: val_dice_coef did not improve\n",
      "Epoch 40/50\n",
      " - 65s - loss: 0.1343 - dice_coef: 0.9504 - acc: 0.9739 - val_loss: 0.2179 - val_dice_coef: 0.9247 - val_acc: 0.9546\n",
      "\n",
      "Epoch 00040: val_dice_coef improved from 0.92302 to 0.92474, saving model to ./keras_0.model\n",
      "Epoch 41/50\n",
      " - 61s - loss: 0.1266 - dice_coef: 0.9531 - acc: 0.9748 - val_loss: 0.2609 - val_dice_coef: 0.9150 - val_acc: 0.9436\n",
      "\n",
      "Epoch 00041: val_dice_coef did not improve\n",
      "Epoch 42/50\n",
      " - 64s - loss: 0.1155 - dice_coef: 0.9561 - acc: 0.9770 - val_loss: 0.2011 - val_dice_coef: 0.9315 - val_acc: 0.9590\n",
      "\n",
      "Epoch 00042: val_dice_coef improved from 0.92474 to 0.93151, saving model to ./keras_0.model\n",
      "Epoch 43/50\n",
      " - 61s - loss: 0.1181 - dice_coef: 0.9552 - acc: 0.9769 - val_loss: 0.2130 - val_dice_coef: 0.9272 - val_acc: 0.9558\n",
      "\n",
      "Epoch 00043: val_dice_coef did not improve\n",
      "Epoch 44/50\n",
      " - 63s - loss: 0.1306 - dice_coef: 0.9524 - acc: 0.9744 - val_loss: 0.3489 - val_dice_coef: 0.8952 - val_acc: 0.9401\n",
      "\n",
      "Epoch 00044: val_dice_coef did not improve\n",
      "Epoch 45/50\n",
      " - 62s - loss: 0.1222 - dice_coef: 0.9534 - acc: 0.9764 - val_loss: 0.2845 - val_dice_coef: 0.8971 - val_acc: 0.9445\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00045: val_dice_coef did not improve\n",
      "Epoch 46/50\n",
      " - 63s - loss: 0.1160 - dice_coef: 0.9565 - acc: 0.9767 - val_loss: 0.3458 - val_dice_coef: 0.8884 - val_acc: 0.9338\n",
      "\n",
      "Epoch 00046: val_dice_coef did not improve\n",
      "Epoch 47/50\n",
      " - 63s - loss: 0.1252 - dice_coef: 0.9535 - acc: 0.9751 - val_loss: 0.3223 - val_dice_coef: 0.9084 - val_acc: 0.9425\n",
      "\n",
      "Epoch 00047: val_dice_coef did not improve\n",
      "Epoch 48/50\n",
      " - 65s - loss: 0.1185 - dice_coef: 0.9552 - acc: 0.9764 - val_loss: 0.2664 - val_dice_coef: 0.9204 - val_acc: 0.9474\n",
      "\n",
      "Epoch 00048: val_dice_coef did not improve\n",
      "Epoch 49/50\n",
      " - 62s - loss: 0.1238 - dice_coef: 0.9536 - acc: 0.9761 - val_loss: 0.2681 - val_dice_coef: 0.9184 - val_acc: 0.9503\n",
      "\n",
      "Epoch 00049: val_dice_coef did not improve\n",
      "Epoch 50/50\n",
      " - 65s - loss: 0.1136 - dice_coef: 0.9568 - acc: 0.9777 - val_loss: 0.2780 - val_dice_coef: 0.9175 - val_acc: 0.9500\n",
      "\n",
      "Epoch 00050: val_dice_coef did not improve\n",
      "Epoch 1/50\n",
      " - 65s - loss: 0.1119 - dice_coef: 0.9592 - acc: 0.9779 - val_loss: 0.2333 - val_dice_coef: 0.9162 - val_acc: 0.9522\n",
      "\n",
      "Epoch 00001: val_dice_coef improved from -inf to 0.91615, saving model to ./keras_1.model\n",
      "Epoch 2/50\n",
      " - 61s - loss: 0.1177 - dice_coef: 0.9563 - acc: 0.9768 - val_loss: 0.2987 - val_dice_coef: 0.9151 - val_acc: 0.9468\n",
      "\n",
      "Epoch 00002: val_dice_coef did not improve\n",
      "Epoch 3/50\n",
      " - 66s - loss: 0.1142 - dice_coef: 0.9575 - acc: 0.9775 - val_loss: 0.2643 - val_dice_coef: 0.9150 - val_acc: 0.9506\n",
      "\n",
      "Epoch 00003: val_dice_coef did not improve\n",
      "Epoch 4/50\n",
      " - 63s - loss: 0.1110 - dice_coef: 0.9585 - acc: 0.9783 - val_loss: 0.2705 - val_dice_coef: 0.9232 - val_acc: 0.9520\n",
      "\n",
      "Epoch 00004: val_dice_coef improved from 0.91615 to 0.92319, saving model to ./keras_1.model\n",
      "Epoch 5/50\n",
      " - 63s - loss: 0.1119 - dice_coef: 0.9578 - acc: 0.9771 - val_loss: 0.2427 - val_dice_coef: 0.9184 - val_acc: 0.9530\n",
      "\n",
      "Epoch 00005: val_dice_coef did not improve\n",
      "Epoch 6/50\n",
      " - 62s - loss: 0.1124 - dice_coef: 0.9582 - acc: 0.9779 - val_loss: 0.2879 - val_dice_coef: 0.9117 - val_acc: 0.9440\n",
      "\n",
      "Epoch 00006: val_dice_coef did not improve\n",
      "Epoch 7/50\n",
      " - 63s - loss: 0.1125 - dice_coef: 0.9579 - acc: 0.9780 - val_loss: 0.2551 - val_dice_coef: 0.9158 - val_acc: 0.9490\n",
      "\n",
      "Epoch 00007: val_dice_coef did not improve\n",
      "Epoch 8/50\n",
      " - 64s - loss: 0.1132 - dice_coef: 0.9583 - acc: 0.9779 - val_loss: 0.3186 - val_dice_coef: 0.9033 - val_acc: 0.9412\n",
      "\n",
      "Epoch 00008: val_dice_coef did not improve\n",
      "Epoch 9/50\n",
      " - 63s - loss: 0.1068 - dice_coef: 0.9592 - acc: 0.9787 - val_loss: 0.4184 - val_dice_coef: 0.8966 - val_acc: 0.9285\n",
      "\n",
      "Epoch 00009: val_dice_coef did not improve\n",
      "Epoch 10/50\n",
      " - 63s - loss: 0.1172 - dice_coef: 0.9570 - acc: 0.9775 - val_loss: 0.2452 - val_dice_coef: 0.9222 - val_acc: 0.9515\n",
      "\n",
      "Epoch 00010: val_dice_coef did not improve\n",
      "Epoch 11/50\n",
      " - 64s - loss: 0.1151 - dice_coef: 0.9580 - acc: 0.9777 - val_loss: 0.2664 - val_dice_coef: 0.9135 - val_acc: 0.9447\n",
      "\n",
      "Epoch 00011: val_dice_coef did not improve\n",
      "Epoch 12/50\n",
      " - 64s - loss: 0.1101 - dice_coef: 0.9579 - acc: 0.9781 - val_loss: 0.2974 - val_dice_coef: 0.9105 - val_acc: 0.9422\n",
      "\n",
      "Epoch 00012: val_dice_coef did not improve\n",
      "Epoch 13/50\n",
      " - 64s - loss: 0.1082 - dice_coef: 0.9602 - acc: 0.9784 - val_loss: 0.3464 - val_dice_coef: 0.8971 - val_acc: 0.9349\n",
      "\n",
      "Epoch 00013: val_dice_coef did not improve\n",
      "Epoch 14/50\n",
      " - 64s - loss: 0.1074 - dice_coef: 0.9600 - acc: 0.9790 - val_loss: 0.2866 - val_dice_coef: 0.9164 - val_acc: 0.9471\n",
      "\n",
      "Epoch 00014: val_dice_coef did not improve\n",
      "Epoch 15/50\n",
      " - 63s - loss: 0.1195 - dice_coef: 0.9555 - acc: 0.9766 - val_loss: 0.2386 - val_dice_coef: 0.9159 - val_acc: 0.9500\n",
      "\n",
      "Epoch 00015: val_dice_coef did not improve\n",
      "Epoch 16/50\n",
      " - 64s - loss: 0.1064 - dice_coef: 0.9599 - acc: 0.9789 - val_loss: 0.4463 - val_dice_coef: 0.8912 - val_acc: 0.9351\n",
      "\n",
      "Epoch 00016: val_dice_coef did not improve\n",
      "Epoch 17/50\n",
      " - 66s - loss: 0.1010 - dice_coef: 0.9618 - acc: 0.9801 - val_loss: 0.3335 - val_dice_coef: 0.9089 - val_acc: 0.9439\n",
      "\n",
      "Epoch 00017: val_dice_coef did not improve\n",
      "Epoch 18/50\n",
      " - 62s - loss: 0.1062 - dice_coef: 0.9608 - acc: 0.9795 - val_loss: 0.2594 - val_dice_coef: 0.9070 - val_acc: 0.9437\n",
      "\n",
      "Epoch 00018: val_dice_coef did not improve\n",
      "Epoch 19/50\n",
      " - 64s - loss: 0.1103 - dice_coef: 0.9594 - acc: 0.9785 - val_loss: 0.2683 - val_dice_coef: 0.9089 - val_acc: 0.9442\n",
      "\n",
      "Epoch 00019: val_dice_coef did not improve\n",
      "Epoch 20/50\n",
      " - 64s - loss: 0.1072 - dice_coef: 0.9605 - acc: 0.9792 - val_loss: 0.3300 - val_dice_coef: 0.8882 - val_acc: 0.9345\n",
      "\n",
      "Epoch 00020: val_dice_coef did not improve\n",
      "Epoch 21/50\n",
      " - 63s - loss: 0.1071 - dice_coef: 0.9593 - acc: 0.9788 - val_loss: 0.3358 - val_dice_coef: 0.8908 - val_acc: 0.9377\n",
      "\n",
      "Epoch 00021: val_dice_coef did not improve\n",
      "Epoch 22/50\n",
      " - 62s - loss: 0.0994 - dice_coef: 0.9627 - acc: 0.9805 - val_loss: 0.2796 - val_dice_coef: 0.9206 - val_acc: 0.9503\n",
      "\n",
      "Epoch 00022: val_dice_coef did not improve\n",
      "Epoch 23/50\n",
      " - 66s - loss: 0.1017 - dice_coef: 0.9618 - acc: 0.9798 - val_loss: 0.2632 - val_dice_coef: 0.9078 - val_acc: 0.9461\n",
      "\n",
      "Epoch 00023: val_dice_coef did not improve\n",
      "Epoch 24/50\n",
      " - 62s - loss: 0.1104 - dice_coef: 0.9585 - acc: 0.9781 - val_loss: 0.3577 - val_dice_coef: 0.9005 - val_acc: 0.9392\n",
      "\n",
      "Epoch 00024: val_dice_coef did not improve\n",
      "Epoch 25/50\n",
      " - 64s - loss: 0.1084 - dice_coef: 0.9597 - acc: 0.9791 - val_loss: 0.2473 - val_dice_coef: 0.9128 - val_acc: 0.9492\n",
      "\n",
      "Epoch 00025: val_dice_coef did not improve\n",
      "Epoch 26/50\n",
      " - 64s - loss: 0.0999 - dice_coef: 0.9631 - acc: 0.9800 - val_loss: 0.3179 - val_dice_coef: 0.9002 - val_acc: 0.9392\n",
      "\n",
      "Epoch 00026: val_dice_coef did not improve\n",
      "Epoch 27/50\n",
      " - 63s - loss: 0.1161 - dice_coef: 0.9575 - acc: 0.9774 - val_loss: 0.2794 - val_dice_coef: 0.9086 - val_acc: 0.9501\n",
      "\n",
      "Epoch 00027: val_dice_coef did not improve\n",
      "Epoch 28/50\n",
      " - 65s - loss: 0.1029 - dice_coef: 0.9614 - acc: 0.9799 - val_loss: 0.2629 - val_dice_coef: 0.9199 - val_acc: 0.9526\n",
      "\n",
      "Epoch 00028: val_dice_coef did not improve\n",
      "Epoch 29/50\n",
      " - 65s - loss: 0.1051 - dice_coef: 0.9618 - acc: 0.9793 - val_loss: 0.2571 - val_dice_coef: 0.9076 - val_acc: 0.9463\n",
      "\n",
      "Epoch 00029: val_dice_coef did not improve\n",
      "Epoch 30/50\n",
      " - 62s - loss: 0.1020 - dice_coef: 0.9618 - acc: 0.9796 - val_loss: 0.2247 - val_dice_coef: 0.9250 - val_acc: 0.9547\n",
      "\n",
      "Epoch 00030: val_dice_coef improved from 0.92319 to 0.92502, saving model to ./keras_1.model\n",
      "Epoch 31/50\n",
      " - 65s - loss: 0.1025 - dice_coef: 0.9612 - acc: 0.9800 - val_loss: 0.3192 - val_dice_coef: 0.9023 - val_acc: 0.9389\n",
      "\n",
      "Epoch 00031: val_dice_coef did not improve\n",
      "Epoch 32/50\n",
      " - 62s - loss: 0.1013 - dice_coef: 0.9632 - acc: 0.9795 - val_loss: 0.2963 - val_dice_coef: 0.9038 - val_acc: 0.9405\n",
      "\n",
      "Epoch 00032: val_dice_coef did not improve\n",
      "Epoch 33/50\n",
      " - 65s - loss: 0.0974 - dice_coef: 0.9633 - acc: 0.9813 - val_loss: 0.2871 - val_dice_coef: 0.9162 - val_acc: 0.9469\n",
      "\n",
      "Epoch 00033: val_dice_coef did not improve\n",
      "Epoch 34/50\n",
      " - 62s - loss: 0.1000 - dice_coef: 0.9628 - acc: 0.9802 - val_loss: 0.2686 - val_dice_coef: 0.9156 - val_acc: 0.9495\n",
      "\n",
      "Epoch 00034: val_dice_coef did not improve\n",
      "Epoch 35/50\n",
      " - 63s - loss: 0.0978 - dice_coef: 0.9631 - acc: 0.9807 - val_loss: 0.3267 - val_dice_coef: 0.8910 - val_acc: 0.9360\n",
      "\n",
      "Epoch 00035: val_dice_coef did not improve\n",
      "Epoch 36/50\n",
      " - 63s - loss: 0.0973 - dice_coef: 0.9631 - acc: 0.9806 - val_loss: 0.2814 - val_dice_coef: 0.9117 - val_acc: 0.9437\n",
      "\n",
      "Epoch 00036: val_dice_coef did not improve\n",
      "Epoch 37/50\n",
      " - 62s - loss: 0.0974 - dice_coef: 0.9628 - acc: 0.9804 - val_loss: 0.3661 - val_dice_coef: 0.8959 - val_acc: 0.9385\n",
      "\n",
      "Epoch 00037: val_dice_coef did not improve\n",
      "Epoch 38/50\n",
      " - 65s - loss: 0.0930 - dice_coef: 0.9648 - acc: 0.9814 - val_loss: 0.2765 - val_dice_coef: 0.9096 - val_acc: 0.9456\n",
      "\n",
      "Epoch 00038: val_dice_coef did not improve\n",
      "Epoch 39/50\n",
      " - 63s - loss: 0.1035 - dice_coef: 0.9619 - acc: 0.9799 - val_loss: 0.2204 - val_dice_coef: 0.9257 - val_acc: 0.9534\n",
      "\n",
      "Epoch 00039: val_dice_coef improved from 0.92502 to 0.92571, saving model to ./keras_1.model\n",
      "Epoch 40/50\n",
      " - 62s - loss: 0.0985 - dice_coef: 0.9635 - acc: 0.9809 - val_loss: 0.2914 - val_dice_coef: 0.9071 - val_acc: 0.9449\n",
      "\n",
      "Epoch 00040: val_dice_coef did not improve\n",
      "Epoch 41/50\n",
      " - 66s - loss: 0.1048 - dice_coef: 0.9612 - acc: 0.9795 - val_loss: 0.3666 - val_dice_coef: 0.8929 - val_acc: 0.9316\n",
      "\n",
      "Epoch 00041: val_dice_coef did not improve\n",
      "Epoch 42/50\n",
      " - 63s - loss: 0.0899 - dice_coef: 0.9661 - acc: 0.9820 - val_loss: 0.3266 - val_dice_coef: 0.8999 - val_acc: 0.9379\n",
      "\n",
      "Epoch 00042: val_dice_coef did not improve\n",
      "Epoch 43/50\n",
      " - 63s - loss: 0.1148 - dice_coef: 0.9592 - acc: 0.9781 - val_loss: 0.2902 - val_dice_coef: 0.9086 - val_acc: 0.9448\n",
      "\n",
      "Epoch 00043: val_dice_coef did not improve\n",
      "Epoch 44/50\n",
      " - 62s - loss: 0.0972 - dice_coef: 0.9635 - acc: 0.9810 - val_loss: 0.2855 - val_dice_coef: 0.9132 - val_acc: 0.9473\n",
      "\n",
      "Epoch 00044: val_dice_coef did not improve\n",
      "Epoch 45/50\n",
      " - 62s - loss: 0.0923 - dice_coef: 0.9649 - acc: 0.9819 - val_loss: 0.3050 - val_dice_coef: 0.9083 - val_acc: 0.9433\n",
      "\n",
      "Epoch 00045: val_dice_coef did not improve\n",
      "Epoch 46/50\n",
      " - 64s - loss: 0.0982 - dice_coef: 0.9638 - acc: 0.9808 - val_loss: 0.3495 - val_dice_coef: 0.9088 - val_acc: 0.9411\n",
      "\n",
      "Epoch 00046: val_dice_coef did not improve\n",
      "Epoch 47/50\n",
      " - 62s - loss: 0.1031 - dice_coef: 0.9615 - acc: 0.9801 - val_loss: 0.2464 - val_dice_coef: 0.9199 - val_acc: 0.9504\n",
      "\n",
      "Epoch 00047: val_dice_coef did not improve\n",
      "Epoch 48/50\n",
      " - 62s - loss: 0.0976 - dice_coef: 0.9638 - acc: 0.9809 - val_loss: 0.2850 - val_dice_coef: 0.9148 - val_acc: 0.9496\n",
      "\n",
      "Epoch 00048: val_dice_coef did not improve\n",
      "Epoch 49/50\n",
      " - 64s - loss: 0.1075 - dice_coef: 0.9627 - acc: 0.9796 - val_loss: 0.2899 - val_dice_coef: 0.9166 - val_acc: 0.9471\n",
      "\n",
      "Epoch 00049: val_dice_coef did not improve\n",
      "Epoch 50/50\n",
      " - 65s - loss: 0.0909 - dice_coef: 0.9654 - acc: 0.9818 - val_loss: 0.2775 - val_dice_coef: 0.9013 - val_acc: 0.9436\n",
      "\n",
      "Epoch 00050: val_dice_coef did not improve\n",
      "Epoch 1/50\n",
      " - 66s - loss: 0.0926 - dice_coef: 0.9656 - acc: 0.9813 - val_loss: 0.3338 - val_dice_coef: 0.9189 - val_acc: 0.9482\n",
      "\n",
      "Epoch 00001: val_dice_coef improved from -inf to 0.91893, saving model to ./keras_2.model\n",
      "Epoch 2/50\n",
      " - 62s - loss: 0.0906 - dice_coef: 0.9658 - acc: 0.9819 - val_loss: 0.2794 - val_dice_coef: 0.9189 - val_acc: 0.9499\n",
      "\n",
      "Epoch 00002: val_dice_coef did not improve\n",
      "Epoch 3/50\n",
      " - 64s - loss: 0.0891 - dice_coef: 0.9666 - acc: 0.9823 - val_loss: 0.4752 - val_dice_coef: 0.8885 - val_acc: 0.9360\n",
      "\n",
      "Epoch 00003: val_dice_coef did not improve\n",
      "Epoch 4/50\n",
      " - 63s - loss: 0.0968 - dice_coef: 0.9642 - acc: 0.9812 - val_loss: 0.2821 - val_dice_coef: 0.9067 - val_acc: 0.9429\n",
      "\n",
      "Epoch 00004: val_dice_coef did not improve\n",
      "Epoch 5/50\n",
      " - 63s - loss: 0.0890 - dice_coef: 0.9663 - acc: 0.9825 - val_loss: 0.3516 - val_dice_coef: 0.9040 - val_acc: 0.9434\n",
      "\n",
      "Epoch 00005: val_dice_coef did not improve\n",
      "Epoch 6/50\n",
      " - 66s - loss: 0.0909 - dice_coef: 0.9662 - acc: 0.9820 - val_loss: 0.2400 - val_dice_coef: 0.9192 - val_acc: 0.9513\n",
      "\n",
      "Epoch 00006: val_dice_coef improved from 0.91893 to 0.91915, saving model to ./keras_2.model\n",
      "Epoch 7/50\n",
      " - 61s - loss: 0.0908 - dice_coef: 0.9653 - acc: 0.9820 - val_loss: 0.4350 - val_dice_coef: 0.8873 - val_acc: 0.9286\n",
      "\n",
      "Epoch 00007: val_dice_coef did not improve\n",
      "Epoch 8/50\n",
      " - 65s - loss: 0.0904 - dice_coef: 0.9662 - acc: 0.9827 - val_loss: 0.3243 - val_dice_coef: 0.9083 - val_acc: 0.9436\n",
      "\n",
      "Epoch 00008: val_dice_coef did not improve\n",
      "Epoch 9/50\n",
      " - 63s - loss: 0.0943 - dice_coef: 0.9651 - acc: 0.9809 - val_loss: 0.2606 - val_dice_coef: 0.9083 - val_acc: 0.9444\n",
      "\n",
      "Epoch 00009: val_dice_coef did not improve\n",
      "Epoch 10/50\n",
      " - 63s - loss: 0.0858 - dice_coef: 0.9678 - acc: 0.9829 - val_loss: 0.3151 - val_dice_coef: 0.9010 - val_acc: 0.9365\n",
      "\n",
      "Epoch 00010: val_dice_coef did not improve\n",
      "Epoch 11/50\n",
      " - 66s - loss: 0.0899 - dice_coef: 0.9662 - acc: 0.9822 - val_loss: 0.2287 - val_dice_coef: 0.9277 - val_acc: 0.9559\n",
      "\n",
      "Epoch 00011: val_dice_coef improved from 0.91915 to 0.92772, saving model to ./keras_2.model\n",
      "Epoch 12/50\n",
      " - 64s - loss: 0.0896 - dice_coef: 0.9666 - acc: 0.9821 - val_loss: 0.2829 - val_dice_coef: 0.9097 - val_acc: 0.9467\n",
      "\n",
      "Epoch 00012: val_dice_coef did not improve\n",
      "Epoch 13/50\n",
      " - 63s - loss: 0.0947 - dice_coef: 0.9649 - acc: 0.9812 - val_loss: 0.4509 - val_dice_coef: 0.8561 - val_acc: 0.9189\n",
      "\n",
      "Epoch 00013: val_dice_coef did not improve\n",
      "Epoch 14/50\n",
      " - 65s - loss: 0.0894 - dice_coef: 0.9668 - acc: 0.9826 - val_loss: 0.3037 - val_dice_coef: 0.9021 - val_acc: 0.9426\n",
      "\n",
      "Epoch 00014: val_dice_coef did not improve\n",
      "Epoch 15/50\n",
      " - 63s - loss: 0.0913 - dice_coef: 0.9662 - acc: 0.9817 - val_loss: 0.2185 - val_dice_coef: 0.9256 - val_acc: 0.9548\n",
      "\n",
      "Epoch 00015: val_dice_coef did not improve\n",
      "Epoch 16/50\n",
      " - 63s - loss: 0.0855 - dice_coef: 0.9681 - acc: 0.9828 - val_loss: 0.2726 - val_dice_coef: 0.9200 - val_acc: 0.9505\n",
      "\n",
      "Epoch 00016: val_dice_coef did not improve\n",
      "Epoch 17/50\n",
      " - 61s - loss: 0.0862 - dice_coef: 0.9677 - acc: 0.9829 - val_loss: 0.3724 - val_dice_coef: 0.8954 - val_acc: 0.9384\n",
      "\n",
      "Epoch 00017: val_dice_coef did not improve\n",
      "Epoch 18/50\n",
      " - 64s - loss: 0.0904 - dice_coef: 0.9664 - acc: 0.9822 - val_loss: 0.2465 - val_dice_coef: 0.9161 - val_acc: 0.9486\n",
      "\n",
      "Epoch 00018: val_dice_coef did not improve\n",
      "Epoch 19/50\n",
      " - 62s - loss: 0.0830 - dice_coef: 0.9682 - acc: 0.9836 - val_loss: 0.2441 - val_dice_coef: 0.9234 - val_acc: 0.9530\n",
      "\n",
      "Epoch 00019: val_dice_coef did not improve\n",
      "Epoch 20/50\n",
      " - 62s - loss: 0.0883 - dice_coef: 0.9674 - acc: 0.9825 - val_loss: 0.5072 - val_dice_coef: 0.8886 - val_acc: 0.9266\n",
      "\n",
      "Epoch 00020: val_dice_coef did not improve\n",
      "Epoch 21/50\n",
      " - 62s - loss: 0.0868 - dice_coef: 0.9674 - acc: 0.9826 - val_loss: 0.2354 - val_dice_coef: 0.9160 - val_acc: 0.9513\n",
      "\n",
      "Epoch 00021: val_dice_coef did not improve\n",
      "Epoch 22/50\n",
      " - 63s - loss: 0.0893 - dice_coef: 0.9664 - acc: 0.9822 - val_loss: 0.3653 - val_dice_coef: 0.9025 - val_acc: 0.9363\n",
      "\n",
      "Epoch 00022: val_dice_coef did not improve\n",
      "Epoch 23/50\n",
      " - 63s - loss: 0.0929 - dice_coef: 0.9658 - acc: 0.9818 - val_loss: 0.2467 - val_dice_coef: 0.9187 - val_acc: 0.9502\n",
      "\n",
      "Epoch 00023: val_dice_coef did not improve\n",
      "Epoch 24/50\n",
      " - 63s - loss: 0.0868 - dice_coef: 0.9672 - acc: 0.9828 - val_loss: 0.2274 - val_dice_coef: 0.9238 - val_acc: 0.9511\n",
      "\n",
      "Epoch 00024: val_dice_coef did not improve\n",
      "Epoch 25/50\n",
      " - 63s - loss: 0.0859 - dice_coef: 0.9680 - acc: 0.9828 - val_loss: 0.2233 - val_dice_coef: 0.9230 - val_acc: 0.9544\n",
      "\n",
      "Epoch 00025: val_dice_coef did not improve\n",
      "Epoch 26/50\n",
      " - 63s - loss: 0.0846 - dice_coef: 0.9682 - acc: 0.9833 - val_loss: 0.2611 - val_dice_coef: 0.9239 - val_acc: 0.9531\n",
      "\n",
      "Epoch 00026: val_dice_coef did not improve\n",
      "Epoch 27/50\n",
      " - 62s - loss: 0.0853 - dice_coef: 0.9680 - acc: 0.9832 - val_loss: 0.2873 - val_dice_coef: 0.9175 - val_acc: 0.9481\n",
      "\n",
      "Epoch 00027: val_dice_coef did not improve\n",
      "Epoch 28/50\n",
      " - 63s - loss: 0.0873 - dice_coef: 0.9675 - acc: 0.9826 - val_loss: 0.2577 - val_dice_coef: 0.9275 - val_acc: 0.9554\n",
      "\n",
      "Epoch 00028: val_dice_coef did not improve\n",
      "Epoch 29/50\n",
      " - 63s - loss: 0.0854 - dice_coef: 0.9678 - acc: 0.9831 - val_loss: 0.2783 - val_dice_coef: 0.9038 - val_acc: 0.9450\n",
      "\n",
      "Epoch 00029: val_dice_coef did not improve\n",
      "Epoch 30/50\n",
      " - 61s - loss: 0.0836 - dice_coef: 0.9688 - acc: 0.9834 - val_loss: 0.2828 - val_dice_coef: 0.9190 - val_acc: 0.9495\n",
      "\n",
      "Epoch 00030: val_dice_coef did not improve\n",
      "Epoch 31/50\n",
      " - 64s - loss: 0.0838 - dice_coef: 0.9686 - acc: 0.9833 - val_loss: 0.2552 - val_dice_coef: 0.9202 - val_acc: 0.9491\n",
      "\n",
      "Epoch 00031: val_dice_coef did not improve\n",
      "Epoch 32/50\n",
      " - 63s - loss: 0.0796 - dice_coef: 0.9706 - acc: 0.9840 - val_loss: 0.3606 - val_dice_coef: 0.8923 - val_acc: 0.9356\n",
      "\n",
      "Epoch 00032: val_dice_coef did not improve\n",
      "Epoch 33/50\n",
      " - 62s - loss: 0.0782 - dice_coef: 0.9701 - acc: 0.9845 - val_loss: 0.2420 - val_dice_coef: 0.9280 - val_acc: 0.9534\n",
      "\n",
      "Epoch 00033: val_dice_coef improved from 0.92772 to 0.92802, saving model to ./keras_2.model\n",
      "Epoch 34/50\n",
      " - 61s - loss: 0.0855 - dice_coef: 0.9677 - acc: 0.9829 - val_loss: 0.2733 - val_dice_coef: 0.9201 - val_acc: 0.9495\n",
      "\n",
      "Epoch 00034: val_dice_coef did not improve\n",
      "Epoch 35/50\n",
      " - 61s - loss: 0.0811 - dice_coef: 0.9697 - acc: 0.9839 - val_loss: 0.2303 - val_dice_coef: 0.9179 - val_acc: 0.9535\n",
      "\n",
      "Epoch 00035: val_dice_coef did not improve\n",
      "Epoch 36/50\n",
      " - 62s - loss: 0.0844 - dice_coef: 0.9684 - acc: 0.9832 - val_loss: 0.2626 - val_dice_coef: 0.9168 - val_acc: 0.9496\n",
      "\n",
      "Epoch 00036: val_dice_coef did not improve\n",
      "Epoch 37/50\n",
      " - 64s - loss: 0.0802 - dice_coef: 0.9698 - acc: 0.9840 - val_loss: 0.3158 - val_dice_coef: 0.9112 - val_acc: 0.9468\n",
      "\n",
      "Epoch 00037: val_dice_coef did not improve\n",
      "Epoch 38/50\n",
      " - 60s - loss: 0.0837 - dice_coef: 0.9686 - acc: 0.9833 - val_loss: 0.3350 - val_dice_coef: 0.9098 - val_acc: 0.9467\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00038: val_dice_coef did not improve\n",
      "Epoch 39/50\n",
      " - 63s - loss: 0.0831 - dice_coef: 0.9686 - acc: 0.9835 - val_loss: 0.4155 - val_dice_coef: 0.8907 - val_acc: 0.9355\n",
      "\n",
      "Epoch 00039: val_dice_coef did not improve\n",
      "Epoch 40/50\n",
      " - 60s - loss: 0.0864 - dice_coef: 0.9677 - acc: 0.9826 - val_loss: 0.3007 - val_dice_coef: 0.8999 - val_acc: 0.9400\n",
      "\n",
      "Epoch 00040: val_dice_coef did not improve\n",
      "Epoch 41/50\n",
      " - 63s - loss: 0.0759 - dice_coef: 0.9715 - acc: 0.9849 - val_loss: 0.2753 - val_dice_coef: 0.9129 - val_acc: 0.9444\n",
      "\n",
      "Epoch 00041: val_dice_coef did not improve\n",
      "Epoch 42/50\n",
      " - 64s - loss: 0.0777 - dice_coef: 0.9705 - acc: 0.9845 - val_loss: 0.2206 - val_dice_coef: 0.9287 - val_acc: 0.9560\n",
      "\n",
      "Epoch 00042: val_dice_coef improved from 0.92802 to 0.92867, saving model to ./keras_2.model\n",
      "Epoch 43/50\n",
      " - 64s - loss: 0.0804 - dice_coef: 0.9701 - acc: 0.9841 - val_loss: 0.3413 - val_dice_coef: 0.9094 - val_acc: 0.9441\n",
      "\n",
      "Epoch 00043: val_dice_coef did not improve\n",
      "Epoch 44/50\n",
      " - 65s - loss: 0.0794 - dice_coef: 0.9699 - acc: 0.9844 - val_loss: 0.2272 - val_dice_coef: 0.9298 - val_acc: 0.9578\n",
      "\n",
      "Epoch 00044: val_dice_coef improved from 0.92867 to 0.92981, saving model to ./keras_2.model\n",
      "Epoch 45/50\n",
      " - 66s - loss: 0.0821 - dice_coef: 0.9698 - acc: 0.9839 - val_loss: 0.2738 - val_dice_coef: 0.9223 - val_acc: 0.9501\n",
      "\n",
      "Epoch 00045: val_dice_coef did not improve\n",
      "Epoch 46/50\n",
      " - 64s - loss: 0.0802 - dice_coef: 0.9699 - acc: 0.9840 - val_loss: 0.3000 - val_dice_coef: 0.9026 - val_acc: 0.9345\n",
      "\n",
      "Epoch 00046: val_dice_coef did not improve\n",
      "Epoch 47/50\n",
      " - 66s - loss: 0.0796 - dice_coef: 0.9706 - acc: 0.9844 - val_loss: 0.3403 - val_dice_coef: 0.9027 - val_acc: 0.9411\n",
      "\n",
      "Epoch 00047: val_dice_coef did not improve\n",
      "Epoch 48/50\n",
      " - 66s - loss: 0.0825 - dice_coef: 0.9696 - acc: 0.9839 - val_loss: 0.3428 - val_dice_coef: 0.9065 - val_acc: 0.9415\n",
      "\n",
      "Epoch 00048: val_dice_coef did not improve\n",
      "Epoch 49/50\n",
      " - 64s - loss: 0.0816 - dice_coef: 0.9693 - acc: 0.9840 - val_loss: 0.2515 - val_dice_coef: 0.9268 - val_acc: 0.9523\n",
      "\n",
      "Epoch 00049: val_dice_coef did not improve\n",
      "Epoch 50/50\n",
      " - 65s - loss: 0.0831 - dice_coef: 0.9693 - acc: 0.9839 - val_loss: 0.3081 - val_dice_coef: 0.9098 - val_acc: 0.9416\n",
      "\n",
      "Epoch 00050: val_dice_coef did not improve\n",
      "Epoch 1/50\n",
      " - 71s - loss: 0.0840 - dice_coef: 0.9687 - acc: 0.9828 - val_loss: 0.2695 - val_dice_coef: 0.9163 - val_acc: 0.9459\n",
      "\n",
      "Epoch 00001: val_dice_coef improved from -inf to 0.91629, saving model to ./keras_3.model\n",
      "Epoch 2/50\n",
      " - 65s - loss: 0.0803 - dice_coef: 0.9699 - acc: 0.9840 - val_loss: 0.4449 - val_dice_coef: 0.8708 - val_acc: 0.9132\n",
      "\n",
      "Epoch 00002: val_dice_coef did not improve\n",
      "Epoch 3/50\n",
      " - 69s - loss: 0.0869 - dice_coef: 0.9678 - acc: 0.9830 - val_loss: 0.2572 - val_dice_coef: 0.9088 - val_acc: 0.9491\n",
      "\n",
      "Epoch 00003: val_dice_coef did not improve\n",
      "Epoch 4/50\n",
      " - 68s - loss: 0.0805 - dice_coef: 0.9697 - acc: 0.9840 - val_loss: 0.2747 - val_dice_coef: 0.9164 - val_acc: 0.9512\n",
      "\n",
      "Epoch 00004: val_dice_coef improved from 0.91629 to 0.91638, saving model to ./keras_3.model\n",
      "Epoch 5/50\n",
      " - 66s - loss: 0.0805 - dice_coef: 0.9696 - acc: 0.9843 - val_loss: 0.2719 - val_dice_coef: 0.9156 - val_acc: 0.9490\n",
      "\n",
      "Epoch 00005: val_dice_coef did not improve\n",
      "Epoch 6/50\n",
      " - 70s - loss: 0.0762 - dice_coef: 0.9714 - acc: 0.9847 - val_loss: 0.2554 - val_dice_coef: 0.9195 - val_acc: 0.9504\n",
      "\n",
      "Epoch 00006: val_dice_coef improved from 0.91638 to 0.91949, saving model to ./keras_3.model\n",
      "Epoch 7/50\n",
      " - 67s - loss: 0.0783 - dice_coef: 0.9707 - acc: 0.9840 - val_loss: 0.3045 - val_dice_coef: 0.9127 - val_acc: 0.9492\n",
      "\n",
      "Epoch 00007: val_dice_coef did not improve\n",
      "Epoch 8/50\n",
      " - 66s - loss: 0.0795 - dice_coef: 0.9704 - acc: 0.9841 - val_loss: 0.3509 - val_dice_coef: 0.9054 - val_acc: 0.9389\n",
      "\n",
      "Epoch 00008: val_dice_coef did not improve\n",
      "Epoch 9/50\n",
      " - 66s - loss: 0.0832 - dice_coef: 0.9688 - acc: 0.9837 - val_loss: 0.2938 - val_dice_coef: 0.9095 - val_acc: 0.9425\n",
      "\n",
      "Epoch 00009: val_dice_coef did not improve\n",
      "Epoch 10/50\n",
      " - 65s - loss: 0.0772 - dice_coef: 0.9704 - acc: 0.9849 - val_loss: 0.3031 - val_dice_coef: 0.9120 - val_acc: 0.9487\n",
      "\n",
      "Epoch 00010: val_dice_coef did not improve\n",
      "Epoch 11/50\n",
      " - 60s - loss: 0.0743 - dice_coef: 0.9721 - acc: 0.9851 - val_loss: 0.2508 - val_dice_coef: 0.9192 - val_acc: 0.9505\n",
      "\n",
      "Epoch 00011: val_dice_coef did not improve\n",
      "Epoch 12/50\n",
      " - 61s - loss: 0.0828 - dice_coef: 0.9695 - acc: 0.9834 - val_loss: 0.2329 - val_dice_coef: 0.9274 - val_acc: 0.9559\n",
      "\n",
      "Epoch 00012: val_dice_coef improved from 0.91949 to 0.92735, saving model to ./keras_3.model\n",
      "Epoch 13/50\n",
      " - 60s - loss: 0.0807 - dice_coef: 0.9702 - acc: 0.9844 - val_loss: 0.2734 - val_dice_coef: 0.9154 - val_acc: 0.9527\n",
      "\n",
      "Epoch 00013: val_dice_coef did not improve\n",
      "Epoch 14/50\n",
      " - 63s - loss: 0.0783 - dice_coef: 0.9710 - acc: 0.9846 - val_loss: 0.2357 - val_dice_coef: 0.9230 - val_acc: 0.9535\n",
      "\n",
      "Epoch 00014: val_dice_coef did not improve\n",
      "Epoch 15/50\n",
      " - 61s - loss: 0.0762 - dice_coef: 0.9716 - acc: 0.9848 - val_loss: 0.2994 - val_dice_coef: 0.9209 - val_acc: 0.9508\n",
      "\n",
      "Epoch 00015: val_dice_coef did not improve\n",
      "Epoch 16/50\n",
      " - 61s - loss: 0.0779 - dice_coef: 0.9704 - acc: 0.9847 - val_loss: 0.2788 - val_dice_coef: 0.9215 - val_acc: 0.9511\n",
      "\n",
      "Epoch 00016: val_dice_coef did not improve\n",
      "Epoch 17/50\n",
      " - 61s - loss: 0.0728 - dice_coef: 0.9726 - acc: 0.9855 - val_loss: 0.2296 - val_dice_coef: 0.9230 - val_acc: 0.9532\n",
      "\n",
      "Epoch 00017: val_dice_coef did not improve\n",
      "Epoch 18/50\n",
      " - 63s - loss: 0.0793 - dice_coef: 0.9703 - acc: 0.9845 - val_loss: 0.2601 - val_dice_coef: 0.9176 - val_acc: 0.9476\n",
      "\n",
      "Epoch 00018: val_dice_coef did not improve\n",
      "Epoch 19/50\n",
      " - 60s - loss: 0.0749 - dice_coef: 0.9721 - acc: 0.9853 - val_loss: 0.3591 - val_dice_coef: 0.9034 - val_acc: 0.9410\n",
      "\n",
      "Epoch 00019: val_dice_coef did not improve\n",
      "Epoch 20/50\n",
      " - 63s - loss: 0.0780 - dice_coef: 0.9712 - acc: 0.9847 - val_loss: 0.2872 - val_dice_coef: 0.9094 - val_acc: 0.9412\n",
      "\n",
      "Epoch 00020: val_dice_coef did not improve\n",
      "Epoch 21/50\n",
      " - 65s - loss: 0.0720 - dice_coef: 0.9728 - acc: 0.9860 - val_loss: 0.3449 - val_dice_coef: 0.9065 - val_acc: 0.9376\n",
      "\n",
      "Epoch 00021: val_dice_coef did not improve\n",
      "Epoch 22/50\n",
      " - 63s - loss: 0.0718 - dice_coef: 0.9729 - acc: 0.9857 - val_loss: 0.3380 - val_dice_coef: 0.9131 - val_acc: 0.9420\n",
      "\n",
      "Epoch 00022: val_dice_coef did not improve\n",
      "Epoch 23/50\n",
      " - 63s - loss: 0.0816 - dice_coef: 0.9709 - acc: 0.9844 - val_loss: 0.2569 - val_dice_coef: 0.9075 - val_acc: 0.9476\n",
      "\n",
      "Epoch 00023: val_dice_coef did not improve\n",
      "Epoch 24/50\n",
      " - 64s - loss: 0.0771 - dice_coef: 0.9706 - acc: 0.9849 - val_loss: 0.3135 - val_dice_coef: 0.9146 - val_acc: 0.9496\n",
      "\n",
      "Epoch 00024: val_dice_coef did not improve\n",
      "Epoch 25/50\n",
      " - 62s - loss: 0.0748 - dice_coef: 0.9722 - acc: 0.9851 - val_loss: 0.2917 - val_dice_coef: 0.9038 - val_acc: 0.9415\n",
      "\n",
      "Epoch 00025: val_dice_coef did not improve\n",
      "Epoch 26/50\n",
      " - 63s - loss: 0.0819 - dice_coef: 0.9707 - acc: 0.9841 - val_loss: 0.3120 - val_dice_coef: 0.9196 - val_acc: 0.9522\n",
      "\n",
      "Epoch 00026: val_dice_coef did not improve\n",
      "Epoch 27/50\n",
      " - 63s - loss: 0.0781 - dice_coef: 0.9707 - acc: 0.9845 - val_loss: 0.3010 - val_dice_coef: 0.9152 - val_acc: 0.9508\n",
      "\n",
      "Epoch 00027: val_dice_coef did not improve\n",
      "Epoch 28/50\n",
      " - 63s - loss: 0.0720 - dice_coef: 0.9729 - acc: 0.9857 - val_loss: 0.3038 - val_dice_coef: 0.9171 - val_acc: 0.9500\n",
      "\n",
      "Epoch 00028: val_dice_coef did not improve\n",
      "Epoch 29/50\n",
      " - 62s - loss: 0.0768 - dice_coef: 0.9716 - acc: 0.9848 - val_loss: 0.3114 - val_dice_coef: 0.9237 - val_acc: 0.9529\n",
      "\n",
      "Epoch 00029: val_dice_coef did not improve\n",
      "Epoch 30/50\n",
      " - 63s - loss: 0.0744 - dice_coef: 0.9717 - acc: 0.9853 - val_loss: 0.2766 - val_dice_coef: 0.9252 - val_acc: 0.9558\n",
      "\n",
      "Epoch 00030: val_dice_coef did not improve\n",
      "Epoch 31/50\n",
      " - 60s - loss: 0.0707 - dice_coef: 0.9735 - acc: 0.9857 - val_loss: 0.3124 - val_dice_coef: 0.9151 - val_acc: 0.9479\n",
      "\n",
      "Epoch 00031: val_dice_coef did not improve\n",
      "Epoch 32/50\n",
      " - 61s - loss: 0.0738 - dice_coef: 0.9727 - acc: 0.9853 - val_loss: 0.2779 - val_dice_coef: 0.9230 - val_acc: 0.9511\n",
      "\n",
      "Epoch 00032: val_dice_coef did not improve\n",
      "Epoch 33/50\n",
      " - 61s - loss: 0.0716 - dice_coef: 0.9731 - acc: 0.9859 - val_loss: 0.2900 - val_dice_coef: 0.9146 - val_acc: 0.9451\n",
      "\n",
      "Epoch 00033: val_dice_coef did not improve\n",
      "Epoch 34/50\n",
      " - 62s - loss: 0.0763 - dice_coef: 0.9716 - acc: 0.9848 - val_loss: 0.2808 - val_dice_coef: 0.9204 - val_acc: 0.9509\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00034: val_dice_coef did not improve\n",
      "Epoch 35/50\n",
      " - 61s - loss: 0.0782 - dice_coef: 0.9712 - acc: 0.9846 - val_loss: 0.2493 - val_dice_coef: 0.9241 - val_acc: 0.9544\n",
      "\n",
      "Epoch 00035: val_dice_coef did not improve\n",
      "Epoch 36/50\n",
      " - 62s - loss: 0.0755 - dice_coef: 0.9716 - acc: 0.9848 - val_loss: 0.3509 - val_dice_coef: 0.9143 - val_acc: 0.9461\n",
      "\n",
      "Epoch 00036: val_dice_coef did not improve\n",
      "Epoch 37/50\n",
      " - 62s - loss: 0.0767 - dice_coef: 0.9727 - acc: 0.9850 - val_loss: 0.2662 - val_dice_coef: 0.9211 - val_acc: 0.9519\n",
      "\n",
      "Epoch 00037: val_dice_coef did not improve\n",
      "Epoch 38/50\n",
      " - 61s - loss: 0.0691 - dice_coef: 0.9744 - acc: 0.9863 - val_loss: 0.3170 - val_dice_coef: 0.9236 - val_acc: 0.9488\n",
      "\n",
      "Epoch 00038: val_dice_coef did not improve\n",
      "Epoch 39/50\n",
      " - 61s - loss: 0.0724 - dice_coef: 0.9727 - acc: 0.9857 - val_loss: 0.2783 - val_dice_coef: 0.9214 - val_acc: 0.9527\n",
      "\n",
      "Epoch 00039: val_dice_coef did not improve\n",
      "Epoch 40/50\n",
      " - 62s - loss: 0.0760 - dice_coef: 0.9722 - acc: 0.9851 - val_loss: 0.2654 - val_dice_coef: 0.9235 - val_acc: 0.9534\n",
      "\n",
      "Epoch 00040: val_dice_coef did not improve\n",
      "Epoch 41/50\n",
      " - 61s - loss: 0.0715 - dice_coef: 0.9731 - acc: 0.9861 - val_loss: 0.2838 - val_dice_coef: 0.9197 - val_acc: 0.9512\n",
      "\n",
      "Epoch 00041: val_dice_coef did not improve\n",
      "Epoch 42/50\n",
      " - 61s - loss: 0.0759 - dice_coef: 0.9725 - acc: 0.9852 - val_loss: 0.2565 - val_dice_coef: 0.9177 - val_acc: 0.9486\n",
      "\n",
      "Epoch 00042: val_dice_coef did not improve\n",
      "Epoch 43/50\n",
      " - 62s - loss: 0.0747 - dice_coef: 0.9723 - acc: 0.9848 - val_loss: 0.2939 - val_dice_coef: 0.9162 - val_acc: 0.9475\n",
      "\n",
      "Epoch 00043: val_dice_coef did not improve\n",
      "Epoch 44/50\n",
      " - 61s - loss: 0.0687 - dice_coef: 0.9738 - acc: 0.9864 - val_loss: 0.2920 - val_dice_coef: 0.9238 - val_acc: 0.9536\n",
      "\n",
      "Epoch 00044: val_dice_coef did not improve\n",
      "Epoch 45/50\n",
      " - 61s - loss: 0.0684 - dice_coef: 0.9740 - acc: 0.9866 - val_loss: 0.3334 - val_dice_coef: 0.9161 - val_acc: 0.9499\n",
      "\n",
      "Epoch 00045: val_dice_coef did not improve\n",
      "Epoch 46/50\n",
      " - 60s - loss: 0.0733 - dice_coef: 0.9721 - acc: 0.9856 - val_loss: 0.2599 - val_dice_coef: 0.9223 - val_acc: 0.9527\n",
      "\n",
      "Epoch 00046: val_dice_coef did not improve\n",
      "Epoch 47/50\n",
      " - 62s - loss: 0.0756 - dice_coef: 0.9718 - acc: 0.9849 - val_loss: 0.2183 - val_dice_coef: 0.9282 - val_acc: 0.9566\n",
      "\n",
      "Epoch 00047: val_dice_coef improved from 0.92735 to 0.92821, saving model to ./keras_3.model\n",
      "Epoch 48/50\n",
      " - 60s - loss: 0.0707 - dice_coef: 0.9734 - acc: 0.9860 - val_loss: 0.2722 - val_dice_coef: 0.9234 - val_acc: 0.9534\n",
      "\n",
      "Epoch 00048: val_dice_coef did not improve\n",
      "Epoch 49/50\n",
      " - 60s - loss: 0.0706 - dice_coef: 0.9739 - acc: 0.9862 - val_loss: 0.2657 - val_dice_coef: 0.9240 - val_acc: 0.9531\n",
      "\n",
      "Epoch 00049: val_dice_coef did not improve\n",
      "Epoch 50/50\n",
      " - 63s - loss: 0.0710 - dice_coef: 0.9733 - acc: 0.9863 - val_loss: 0.2510 - val_dice_coef: 0.9180 - val_acc: 0.9516\n",
      "\n",
      "Epoch 00050: val_dice_coef did not improve\n",
      "Epoch 1/50\n",
      " - 65s - loss: 0.0732 - dice_coef: 0.9730 - acc: 0.9857 - val_loss: 0.2555 - val_dice_coef: 0.9202 - val_acc: 0.9518\n",
      "\n",
      "Epoch 00001: val_dice_coef improved from -inf to 0.92017, saving model to ./keras_4.model\n",
      "Epoch 2/50\n",
      " - 61s - loss: 0.0670 - dice_coef: 0.9751 - acc: 0.9864 - val_loss: 0.3119 - val_dice_coef: 0.9173 - val_acc: 0.9530\n",
      "\n",
      "Epoch 00002: val_dice_coef did not improve\n",
      "Epoch 3/50\n",
      " - 62s - loss: 0.0708 - dice_coef: 0.9733 - acc: 0.9857 - val_loss: 0.2580 - val_dice_coef: 0.9233 - val_acc: 0.9524\n",
      "\n",
      "Epoch 00003: val_dice_coef improved from 0.92017 to 0.92328, saving model to ./keras_4.model\n",
      "Epoch 4/50\n",
      " - 60s - loss: 0.0745 - dice_coef: 0.9721 - acc: 0.9853 - val_loss: 0.2407 - val_dice_coef: 0.9260 - val_acc: 0.9512\n",
      "\n",
      "Epoch 00004: val_dice_coef improved from 0.92328 to 0.92599, saving model to ./keras_4.model\n",
      "Epoch 5/50\n",
      " - 61s - loss: 0.0678 - dice_coef: 0.9737 - acc: 0.9866 - val_loss: 0.2790 - val_dice_coef: 0.9201 - val_acc: 0.9554\n",
      "\n",
      "Epoch 00005: val_dice_coef did not improve\n",
      "Epoch 6/50\n",
      " - 62s - loss: 0.0724 - dice_coef: 0.9727 - acc: 0.9855 - val_loss: 0.3075 - val_dice_coef: 0.9178 - val_acc: 0.9501\n",
      "\n",
      "Epoch 00006: val_dice_coef did not improve\n",
      "Epoch 7/50\n",
      " - 61s - loss: 0.0709 - dice_coef: 0.9734 - acc: 0.9860 - val_loss: 0.2422 - val_dice_coef: 0.9220 - val_acc: 0.9510\n",
      "\n",
      "Epoch 00007: val_dice_coef did not improve\n",
      "Epoch 8/50\n",
      " - 61s - loss: 0.0649 - dice_coef: 0.9757 - acc: 0.9870 - val_loss: 0.3022 - val_dice_coef: 0.9054 - val_acc: 0.9449\n",
      "\n",
      "Epoch 00008: val_dice_coef did not improve\n",
      "Epoch 9/50\n",
      " - 63s - loss: 0.0723 - dice_coef: 0.9730 - acc: 0.9856 - val_loss: 0.3217 - val_dice_coef: 0.9122 - val_acc: 0.9452\n",
      "\n",
      "Epoch 00009: val_dice_coef did not improve\n",
      "Epoch 10/50\n",
      " - 61s - loss: 0.0678 - dice_coef: 0.9750 - acc: 0.9862 - val_loss: 0.2965 - val_dice_coef: 0.9219 - val_acc: 0.9571\n",
      "\n",
      "Epoch 00010: val_dice_coef did not improve\n",
      "Epoch 11/50\n",
      " - 61s - loss: 0.0691 - dice_coef: 0.9741 - acc: 0.9863 - val_loss: 0.3204 - val_dice_coef: 0.9126 - val_acc: 0.9463\n",
      "\n",
      "Epoch 00011: val_dice_coef did not improve\n",
      "Epoch 12/50\n",
      " - 63s - loss: 0.0673 - dice_coef: 0.9744 - acc: 0.9866 - val_loss: 0.3929 - val_dice_coef: 0.9113 - val_acc: 0.9408\n",
      "\n",
      "Epoch 00012: val_dice_coef did not improve\n",
      "Epoch 13/50\n",
      " - 64s - loss: 0.0715 - dice_coef: 0.9736 - acc: 0.9857 - val_loss: 0.2913 - val_dice_coef: 0.9253 - val_acc: 0.9537\n",
      "\n",
      "Epoch 00013: val_dice_coef did not improve\n",
      "Epoch 14/50\n",
      " - 62s - loss: 0.0752 - dice_coef: 0.9723 - acc: 0.9852 - val_loss: 0.2803 - val_dice_coef: 0.9227 - val_acc: 0.9532\n",
      "\n",
      "Epoch 00014: val_dice_coef did not improve\n",
      "Epoch 15/50\n",
      " - 62s - loss: 0.0691 - dice_coef: 0.9743 - acc: 0.9866 - val_loss: 0.2679 - val_dice_coef: 0.9218 - val_acc: 0.9519\n",
      "\n",
      "Epoch 00015: val_dice_coef did not improve\n",
      "Epoch 16/50\n",
      " - 62s - loss: 0.0680 - dice_coef: 0.9745 - acc: 0.9866 - val_loss: 0.3239 - val_dice_coef: 0.9065 - val_acc: 0.9420\n",
      "\n",
      "Epoch 00016: val_dice_coef did not improve\n",
      "Epoch 17/50\n",
      " - 62s - loss: 0.0671 - dice_coef: 0.9745 - acc: 0.9867 - val_loss: 0.2565 - val_dice_coef: 0.9243 - val_acc: 0.9571\n",
      "\n",
      "Epoch 00017: val_dice_coef did not improve\n",
      "Epoch 18/50\n",
      " - 65s - loss: 0.0633 - dice_coef: 0.9762 - acc: 0.9875 - val_loss: 0.3043 - val_dice_coef: 0.9193 - val_acc: 0.9494\n",
      "\n",
      "Epoch 00018: val_dice_coef did not improve\n",
      "Epoch 19/50\n",
      " - 63s - loss: 0.0713 - dice_coef: 0.9734 - acc: 0.9858 - val_loss: 0.2955 - val_dice_coef: 0.9124 - val_acc: 0.9483\n",
      "\n",
      "Epoch 00019: val_dice_coef did not improve\n",
      "Epoch 20/50\n",
      " - 63s - loss: 0.0678 - dice_coef: 0.9748 - acc: 0.9864 - val_loss: 0.3261 - val_dice_coef: 0.9093 - val_acc: 0.9460\n",
      "\n",
      "Epoch 00020: val_dice_coef did not improve\n",
      "Epoch 21/50\n",
      " - 63s - loss: 0.0712 - dice_coef: 0.9736 - acc: 0.9860 - val_loss: 0.3878 - val_dice_coef: 0.9045 - val_acc: 0.9396\n",
      "\n",
      "Epoch 00021: val_dice_coef did not improve\n",
      "Epoch 22/50\n",
      " - 63s - loss: 0.0700 - dice_coef: 0.9737 - acc: 0.9861 - val_loss: 0.2480 - val_dice_coef: 0.9273 - val_acc: 0.9586\n",
      "\n",
      "Epoch 00022: val_dice_coef improved from 0.92599 to 0.92730, saving model to ./keras_4.model\n",
      "Epoch 23/50\n",
      " - 64s - loss: 0.0657 - dice_coef: 0.9750 - acc: 0.9868 - val_loss: 0.2861 - val_dice_coef: 0.9287 - val_acc: 0.9570\n",
      "\n",
      "Epoch 00023: val_dice_coef improved from 0.92730 to 0.92871, saving model to ./keras_4.model\n",
      "Epoch 24/50\n",
      " - 63s - loss: 0.0706 - dice_coef: 0.9737 - acc: 0.9860 - val_loss: 0.2902 - val_dice_coef: 0.9194 - val_acc: 0.9510\n",
      "\n",
      "Epoch 00024: val_dice_coef did not improve\n",
      "Epoch 25/50\n",
      " - 63s - loss: 0.0616 - dice_coef: 0.9769 - acc: 0.9878 - val_loss: 0.2625 - val_dice_coef: 0.9290 - val_acc: 0.9546\n",
      "\n",
      "Epoch 00025: val_dice_coef improved from 0.92871 to 0.92904, saving model to ./keras_4.model\n",
      "Epoch 26/50\n",
      " - 63s - loss: 0.0664 - dice_coef: 0.9744 - acc: 0.9867 - val_loss: 0.3203 - val_dice_coef: 0.9193 - val_acc: 0.9517\n",
      "\n",
      "Epoch 00026: val_dice_coef did not improve\n",
      "Epoch 27/50\n",
      " - 63s - loss: 0.0672 - dice_coef: 0.9756 - acc: 0.9863 - val_loss: 0.2714 - val_dice_coef: 0.9176 - val_acc: 0.9506\n",
      "\n",
      "Epoch 00027: val_dice_coef did not improve\n",
      "Epoch 28/50\n",
      " - 62s - loss: 0.0678 - dice_coef: 0.9743 - acc: 0.9866 - val_loss: 0.3854 - val_dice_coef: 0.9051 - val_acc: 0.9430\n",
      "\n",
      "Epoch 00028: val_dice_coef did not improve\n",
      "Epoch 29/50\n",
      " - 62s - loss: 0.0738 - dice_coef: 0.9728 - acc: 0.9854 - val_loss: 0.3093 - val_dice_coef: 0.9166 - val_acc: 0.9509\n",
      "\n",
      "Epoch 00029: val_dice_coef did not improve\n",
      "Epoch 30/50\n",
      " - 60s - loss: 0.0689 - dice_coef: 0.9741 - acc: 0.9862 - val_loss: 0.3486 - val_dice_coef: 0.9145 - val_acc: 0.9489\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00030: val_dice_coef did not improve\n",
      "Epoch 31/50\n",
      " - 61s - loss: 0.0686 - dice_coef: 0.9744 - acc: 0.9866 - val_loss: 0.3072 - val_dice_coef: 0.9226 - val_acc: 0.9505\n",
      "\n",
      "Epoch 00031: val_dice_coef did not improve\n",
      "Epoch 32/50\n",
      " - 62s - loss: 0.0711 - dice_coef: 0.9734 - acc: 0.9859 - val_loss: 0.2614 - val_dice_coef: 0.9187 - val_acc: 0.9533\n",
      "\n",
      "Epoch 00032: val_dice_coef did not improve\n",
      "Epoch 33/50\n",
      " - 62s - loss: 0.0711 - dice_coef: 0.9740 - acc: 0.9859 - val_loss: 0.3525 - val_dice_coef: 0.9114 - val_acc: 0.9476\n",
      "\n",
      "Epoch 00033: val_dice_coef did not improve\n",
      "Epoch 34/50\n",
      " - 60s - loss: 0.0687 - dice_coef: 0.9741 - acc: 0.9865 - val_loss: 0.2789 - val_dice_coef: 0.9161 - val_acc: 0.9529\n",
      "\n",
      "Epoch 00034: val_dice_coef did not improve\n",
      "Epoch 35/50\n",
      " - 62s - loss: 0.0640 - dice_coef: 0.9761 - acc: 0.9873 - val_loss: 0.2813 - val_dice_coef: 0.9196 - val_acc: 0.9510\n",
      "\n",
      "Epoch 00035: val_dice_coef did not improve\n",
      "Epoch 36/50\n",
      " - 62s - loss: 0.0631 - dice_coef: 0.9762 - acc: 0.9873 - val_loss: 0.2804 - val_dice_coef: 0.9151 - val_acc: 0.9509\n",
      "\n",
      "Epoch 00036: val_dice_coef did not improve\n",
      "Epoch 37/50\n",
      " - 63s - loss: 0.0638 - dice_coef: 0.9757 - acc: 0.9874 - val_loss: 0.2764 - val_dice_coef: 0.9183 - val_acc: 0.9530\n",
      "\n",
      "Epoch 00037: val_dice_coef did not improve\n",
      "Epoch 38/50\n",
      " - 67s - loss: 0.0613 - dice_coef: 0.9772 - acc: 0.9880 - val_loss: 0.3085 - val_dice_coef: 0.9166 - val_acc: 0.9477\n",
      "\n",
      "Epoch 00038: val_dice_coef did not improve\n",
      "Epoch 39/50\n",
      " - 68s - loss: 0.0725 - dice_coef: 0.9735 - acc: 0.9856 - val_loss: 0.3393 - val_dice_coef: 0.9056 - val_acc: 0.9427\n",
      "\n",
      "Epoch 00039: val_dice_coef did not improve\n",
      "Epoch 40/50\n",
      " - 66s - loss: 0.0657 - dice_coef: 0.9750 - acc: 0.9869 - val_loss: 0.3264 - val_dice_coef: 0.9192 - val_acc: 0.9483\n",
      "\n",
      "Epoch 00040: val_dice_coef did not improve\n",
      "Epoch 41/50\n",
      " - 67s - loss: 0.0639 - dice_coef: 0.9759 - acc: 0.9874 - val_loss: 0.3430 - val_dice_coef: 0.9036 - val_acc: 0.9434\n",
      "\n",
      "Epoch 00041: val_dice_coef did not improve\n",
      "Epoch 42/50\n",
      " - 70s - loss: 0.0663 - dice_coef: 0.9754 - acc: 0.9866 - val_loss: 0.3278 - val_dice_coef: 0.9220 - val_acc: 0.9509\n",
      "\n",
      "Epoch 00042: val_dice_coef did not improve\n",
      "Epoch 43/50\n",
      " - 66s - loss: 0.0621 - dice_coef: 0.9769 - acc: 0.9878 - val_loss: 0.2573 - val_dice_coef: 0.9245 - val_acc: 0.9541\n",
      "\n",
      "Epoch 00043: val_dice_coef did not improve\n",
      "Epoch 44/50\n",
      " - 67s - loss: 0.0642 - dice_coef: 0.9759 - acc: 0.9873 - val_loss: 0.3894 - val_dice_coef: 0.9076 - val_acc: 0.9459\n",
      "\n",
      "Epoch 00044: val_dice_coef did not improve\n",
      "Epoch 45/50\n",
      " - 66s - loss: 0.0676 - dice_coef: 0.9746 - acc: 0.9864 - val_loss: 0.3404 - val_dice_coef: 0.9052 - val_acc: 0.9432\n",
      "\n",
      "Epoch 00045: val_dice_coef did not improve\n",
      "Epoch 46/50\n",
      " - 64s - loss: 0.0644 - dice_coef: 0.9758 - acc: 0.9873 - val_loss: 0.3407 - val_dice_coef: 0.9182 - val_acc: 0.9478\n",
      "\n",
      "Epoch 00046: val_dice_coef did not improve\n",
      "Epoch 47/50\n",
      " - 64s - loss: 0.0672 - dice_coef: 0.9747 - acc: 0.9869 - val_loss: 0.2953 - val_dice_coef: 0.9133 - val_acc: 0.9491\n",
      "\n",
      "Epoch 00047: val_dice_coef did not improve\n",
      "Epoch 48/50\n",
      " - 63s - loss: 0.0628 - dice_coef: 0.9767 - acc: 0.9874 - val_loss: 0.2361 - val_dice_coef: 0.9273 - val_acc: 0.9569\n",
      "\n",
      "Epoch 00048: val_dice_coef did not improve\n",
      "Epoch 49/50\n",
      " - 61s - loss: 0.0649 - dice_coef: 0.9757 - acc: 0.9869 - val_loss: 0.2905 - val_dice_coef: 0.9224 - val_acc: 0.9511\n",
      "\n",
      "Epoch 00049: val_dice_coef did not improve\n",
      "Epoch 50/50\n",
      " - 64s - loss: 0.0604 - dice_coef: 0.9769 - acc: 0.9877 - val_loss: 0.2953 - val_dice_coef: 0.9177 - val_acc: 0.9505\n",
      "\n",
      "Epoch 00050: val_dice_coef did not improve\n"
     ]
    }
   ],
   "source": [
    "for round_ in range(5):\n",
    "    epochs = 50\n",
    "    #swa = SWA('./keras_swa_ph2.model',95)\n",
    "    #snapshot = SnapshotCallbackBuilder1(nb_epochs=epochs,nb_snapshots=5,init_lr=1e-3)\n",
    "    snapshot = SnapshotCallbackBuilder(nb_epochs=epochs,nb_snapshots=1,round_=round_,init_lr=1e-3)\n",
    "    batch_size= 8\n",
    "\n",
    "\n",
    "\n",
    "    history = model.fit_generator(train_generator,\n",
    "                            steps_per_epoch=np.ceil(float(len(os.listdir(train_path))) / float(batch_size)),\n",
    "                            epochs=epochs,\n",
    "                            validation_data=val_generator, \n",
    "                            validation_steps=np.ceil(float(len(os.listdir(test_path))) / float(batch_size)),\n",
    "                           # validation_steps=180//8,\n",
    "                            callbacks=snapshot.get_callbacks(),verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stochastic weight averaging selected for last 5 epochs.\n",
      "Epoch 1/50\n",
      " - 66s - loss: 0.3556 - dice_coef: 0.8850 - acc: 0.9202 - val_loss: 1.7995 - val_dice_coef: 0.7720 - val_acc: 0.7933\n",
      "\n",
      "Epoch 00001: val_dice_coef improved from -inf to 0.77204, saving model to ./keras_0.model\n",
      "Epoch 2/50\n",
      " - 52s - loss: 0.2510 - dice_coef: 0.9220 - acc: 0.9473 - val_loss: 1.0127 - val_dice_coef: 0.8602 - val_acc: 0.9021\n",
      "\n",
      "Epoch 00002: val_dice_coef improved from 0.77204 to 0.86023, saving model to ./keras_0.model\n",
      "Epoch 3/50\n",
      " - 52s - loss: 0.2155 - dice_coef: 0.9336 - acc: 0.9549 - val_loss: 0.2793 - val_dice_coef: 0.9343 - val_acc: 0.9500\n",
      "\n",
      "Epoch 00003: val_dice_coef improved from 0.86023 to 0.93432, saving model to ./keras_0.model\n",
      "Epoch 4/50\n",
      " - 52s - loss: 0.2043 - dice_coef: 0.9368 - acc: 0.9567 - val_loss: 0.3855 - val_dice_coef: 0.9226 - val_acc: 0.9427\n",
      "\n",
      "Epoch 00004: val_dice_coef did not improve\n",
      "Epoch 5/50\n",
      " - 52s - loss: 0.1990 - dice_coef: 0.9389 - acc: 0.9587 - val_loss: 0.1935 - val_dice_coef: 0.9412 - val_acc: 0.9544\n",
      "\n",
      "Epoch 00005: val_dice_coef improved from 0.93432 to 0.94118, saving model to ./keras_0.model\n",
      "Epoch 6/50\n",
      " - 52s - loss: 0.1858 - dice_coef: 0.9415 - acc: 0.9600 - val_loss: 0.3652 - val_dice_coef: 0.9232 - val_acc: 0.9383\n",
      "\n",
      "Epoch 00006: val_dice_coef did not improve\n",
      "Epoch 7/50\n",
      " - 52s - loss: 0.1769 - dice_coef: 0.9429 - acc: 0.9622 - val_loss: 0.2558 - val_dice_coef: 0.9268 - val_acc: 0.9453\n",
      "\n",
      "Epoch 00007: val_dice_coef did not improve\n",
      "Epoch 8/50\n",
      " - 52s - loss: 0.1522 - dice_coef: 0.9513 - acc: 0.9668 - val_loss: 0.4527 - val_dice_coef: 0.9143 - val_acc: 0.9302\n",
      "\n",
      "Epoch 00008: val_dice_coef did not improve\n",
      "Epoch 9/50\n",
      " - 52s - loss: 0.1635 - dice_coef: 0.9469 - acc: 0.9643 - val_loss: 0.2221 - val_dice_coef: 0.9367 - val_acc: 0.9528\n",
      "\n",
      "Epoch 00009: val_dice_coef did not improve\n",
      "Epoch 10/50\n",
      " - 52s - loss: 0.1497 - dice_coef: 0.9525 - acc: 0.9674 - val_loss: 0.3539 - val_dice_coef: 0.9210 - val_acc: 0.9359\n",
      "\n",
      "Epoch 00010: val_dice_coef did not improve\n",
      "Epoch 11/50\n",
      " - 52s - loss: 0.1413 - dice_coef: 0.9540 - acc: 0.9691 - val_loss: 0.2700 - val_dice_coef: 0.9257 - val_acc: 0.9492\n",
      "\n",
      "Epoch 00011: val_dice_coef did not improve\n",
      "Epoch 12/50\n",
      " - 52s - loss: 0.1395 - dice_coef: 0.9556 - acc: 0.9699 - val_loss: 0.2719 - val_dice_coef: 0.9371 - val_acc: 0.9518\n",
      "\n",
      "Epoch 00012: val_dice_coef did not improve\n",
      "Epoch 13/50\n",
      " - 52s - loss: 0.1548 - dice_coef: 0.9515 - acc: 0.9676 - val_loss: 0.2275 - val_dice_coef: 0.9368 - val_acc: 0.9513\n",
      "\n",
      "Epoch 00013: val_dice_coef did not improve\n",
      "Epoch 14/50\n",
      " - 52s - loss: 0.1396 - dice_coef: 0.9547 - acc: 0.9694 - val_loss: 0.3292 - val_dice_coef: 0.9266 - val_acc: 0.9445\n",
      "\n",
      "Epoch 00014: val_dice_coef did not improve\n",
      "Epoch 15/50\n",
      " - 52s - loss: 0.1447 - dice_coef: 0.9537 - acc: 0.9685 - val_loss: 0.2026 - val_dice_coef: 0.9371 - val_acc: 0.9524\n",
      "\n",
      "Epoch 00015: val_dice_coef did not improve\n",
      "Epoch 16/50\n",
      " - 52s - loss: 0.1316 - dice_coef: 0.9578 - acc: 0.9713 - val_loss: 0.4304 - val_dice_coef: 0.9110 - val_acc: 0.9228\n",
      "\n",
      "Epoch 00016: val_dice_coef did not improve\n",
      "Epoch 17/50\n",
      " - 52s - loss: 0.1321 - dice_coef: 0.9569 - acc: 0.9715 - val_loss: 0.3036 - val_dice_coef: 0.9303 - val_acc: 0.9494\n",
      "\n",
      "Epoch 00017: val_dice_coef did not improve\n",
      "Epoch 18/50\n",
      " - 52s - loss: 0.1345 - dice_coef: 0.9564 - acc: 0.9707 - val_loss: 0.4223 - val_dice_coef: 0.8826 - val_acc: 0.9104\n",
      "\n",
      "Epoch 00018: val_dice_coef did not improve\n",
      "Epoch 19/50\n",
      " - 52s - loss: 0.1224 - dice_coef: 0.9603 - acc: 0.9729 - val_loss: 0.2598 - val_dice_coef: 0.9341 - val_acc: 0.9514\n",
      "\n",
      "Epoch 00019: val_dice_coef did not improve\n",
      "Epoch 20/50\n",
      " - 52s - loss: 0.1149 - dice_coef: 0.9625 - acc: 0.9747 - val_loss: 0.2980 - val_dice_coef: 0.9201 - val_acc: 0.9424\n",
      "\n",
      "Epoch 00020: val_dice_coef did not improve\n",
      "Epoch 21/50\n",
      " - 52s - loss: 0.1232 - dice_coef: 0.9603 - acc: 0.9729 - val_loss: 0.1557 - val_dice_coef: 0.9529 - val_acc: 0.9633\n",
      "\n",
      "Epoch 00021: val_dice_coef improved from 0.94118 to 0.95286, saving model to ./keras_0.model\n",
      "Epoch 22/50\n",
      " - 52s - loss: 0.1087 - dice_coef: 0.9641 - acc: 0.9756 - val_loss: 0.2841 - val_dice_coef: 0.9361 - val_acc: 0.9516\n",
      "\n",
      "Epoch 00022: val_dice_coef did not improve\n",
      "Epoch 23/50\n",
      " - 52s - loss: 0.1168 - dice_coef: 0.9619 - acc: 0.9739 - val_loss: 0.1960 - val_dice_coef: 0.9426 - val_acc: 0.9554\n",
      "\n",
      "Epoch 00023: val_dice_coef did not improve\n",
      "Epoch 24/50\n",
      " - 52s - loss: 0.1179 - dice_coef: 0.9618 - acc: 0.9745 - val_loss: 0.2300 - val_dice_coef: 0.9372 - val_acc: 0.9518\n",
      "\n",
      "Epoch 00024: val_dice_coef did not improve\n",
      "Epoch 25/50\n",
      " - 52s - loss: 0.1136 - dice_coef: 0.9635 - acc: 0.9753 - val_loss: 0.2871 - val_dice_coef: 0.9234 - val_acc: 0.9452\n",
      "\n",
      "Epoch 00025: val_dice_coef did not improve\n",
      "Epoch 26/50\n",
      " - 52s - loss: 0.1122 - dice_coef: 0.9638 - acc: 0.9755 - val_loss: 0.2499 - val_dice_coef: 0.9483 - val_acc: 0.9595\n",
      "\n",
      "Epoch 00026: val_dice_coef did not improve\n",
      "Epoch 27/50\n",
      " - 52s - loss: 0.1048 - dice_coef: 0.9652 - acc: 0.9766 - val_loss: 0.2307 - val_dice_coef: 0.9389 - val_acc: 0.9528\n",
      "\n",
      "Epoch 00027: val_dice_coef did not improve\n",
      "Epoch 28/50\n",
      " - 52s - loss: 0.1116 - dice_coef: 0.9636 - acc: 0.9754 - val_loss: 0.2822 - val_dice_coef: 0.9340 - val_acc: 0.9458\n",
      "\n",
      "Epoch 00028: val_dice_coef did not improve\n",
      "Epoch 29/50\n",
      " - 52s - loss: 0.1083 - dice_coef: 0.9646 - acc: 0.9762 - val_loss: 0.2791 - val_dice_coef: 0.9378 - val_acc: 0.9508\n",
      "\n",
      "Epoch 00029: val_dice_coef did not improve\n",
      "Epoch 30/50\n",
      " - 52s - loss: 0.1083 - dice_coef: 0.9648 - acc: 0.9759 - val_loss: 0.2666 - val_dice_coef: 0.9398 - val_acc: 0.9539\n",
      "\n",
      "Epoch 00030: val_dice_coef did not improve\n",
      "Epoch 31/50\n",
      " - 52s - loss: 0.1079 - dice_coef: 0.9646 - acc: 0.9763 - val_loss: 0.2367 - val_dice_coef: 0.9457 - val_acc: 0.9581\n",
      "\n",
      "Epoch 00031: val_dice_coef did not improve\n",
      "Epoch 32/50\n",
      " - 52s - loss: 0.1076 - dice_coef: 0.9651 - acc: 0.9765 - val_loss: 0.1953 - val_dice_coef: 0.9467 - val_acc: 0.9586\n",
      "\n",
      "Epoch 00032: val_dice_coef did not improve\n",
      "Epoch 33/50\n",
      " - 52s - loss: 0.1023 - dice_coef: 0.9668 - acc: 0.9771 - val_loss: 0.4041 - val_dice_coef: 0.8887 - val_acc: 0.9221\n",
      "\n",
      "Epoch 00033: val_dice_coef did not improve\n",
      "Epoch 34/50\n",
      " - 52s - loss: 0.1116 - dice_coef: 0.9639 - acc: 0.9759 - val_loss: 0.2314 - val_dice_coef: 0.9394 - val_acc: 0.9546\n",
      "\n",
      "Epoch 00034: val_dice_coef did not improve\n",
      "Epoch 35/50\n",
      " - 52s - loss: 0.1058 - dice_coef: 0.9662 - acc: 0.9769 - val_loss: 0.2713 - val_dice_coef: 0.9364 - val_acc: 0.9533\n",
      "\n",
      "Epoch 00035: val_dice_coef did not improve\n",
      "Epoch 36/50\n",
      " - 52s - loss: 0.0954 - dice_coef: 0.9692 - acc: 0.9787 - val_loss: 0.3462 - val_dice_coef: 0.9273 - val_acc: 0.9396\n",
      "\n",
      "Epoch 00036: val_dice_coef did not improve\n",
      "Epoch 37/50\n",
      " - 52s - loss: 0.0990 - dice_coef: 0.9673 - acc: 0.9783 - val_loss: 0.2644 - val_dice_coef: 0.9445 - val_acc: 0.9583\n",
      "\n",
      "Epoch 00037: val_dice_coef did not improve\n",
      "Epoch 38/50\n",
      " - 52s - loss: 0.0972 - dice_coef: 0.9689 - acc: 0.9787 - val_loss: 0.1988 - val_dice_coef: 0.9432 - val_acc: 0.9582\n",
      "\n",
      "Epoch 00038: val_dice_coef did not improve\n",
      "Epoch 39/50\n",
      " - 52s - loss: 0.1006 - dice_coef: 0.9674 - acc: 0.9779 - val_loss: 0.2342 - val_dice_coef: 0.9389 - val_acc: 0.9532\n",
      "\n",
      "Epoch 00039: val_dice_coef did not improve\n",
      "Epoch 40/50\n",
      " - 52s - loss: 0.1028 - dice_coef: 0.9666 - acc: 0.9773 - val_loss: 0.2317 - val_dice_coef: 0.9474 - val_acc: 0.9595\n",
      "\n",
      "Epoch 00040: val_dice_coef did not improve\n",
      "Epoch 41/50\n",
      " - 52s - loss: 0.1017 - dice_coef: 0.9664 - acc: 0.9778 - val_loss: 0.2377 - val_dice_coef: 0.9492 - val_acc: 0.9619\n",
      "\n",
      "Epoch 00041: val_dice_coef did not improve\n",
      "Epoch 42/50\n",
      " - 52s - loss: 0.0917 - dice_coef: 0.9706 - acc: 0.9794 - val_loss: 0.2216 - val_dice_coef: 0.9496 - val_acc: 0.9596\n",
      "\n",
      "Epoch 00042: val_dice_coef did not improve\n",
      "Epoch 43/50\n",
      " - 52s - loss: 0.0976 - dice_coef: 0.9682 - acc: 0.9788 - val_loss: 0.2746 - val_dice_coef: 0.9393 - val_acc: 0.9529\n",
      "\n",
      "Epoch 00043: val_dice_coef did not improve\n",
      "Epoch 44/50\n",
      " - 52s - loss: 0.0920 - dice_coef: 0.9701 - acc: 0.9799 - val_loss: 0.2775 - val_dice_coef: 0.9261 - val_acc: 0.9470\n",
      "\n",
      "Epoch 00044: val_dice_coef did not improve\n",
      "Epoch 45/50\n",
      " - 52s - loss: 0.0951 - dice_coef: 0.9689 - acc: 0.9793 - val_loss: 0.2226 - val_dice_coef: 0.9453 - val_acc: 0.9588\n",
      "\n",
      "Epoch 00045: val_dice_coef did not improve\n",
      "Epoch 46/50\n",
      " - 52s - loss: 0.0982 - dice_coef: 0.9686 - acc: 0.9786 - val_loss: 0.1947 - val_dice_coef: 0.9484 - val_acc: 0.9592\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00046: val_dice_coef did not improve\n",
      "Epoch 47/50\n",
      " - 52s - loss: 0.0966 - dice_coef: 0.9687 - acc: 0.9789 - val_loss: 0.2851 - val_dice_coef: 0.9393 - val_acc: 0.9546\n",
      "\n",
      "Epoch 00047: val_dice_coef did not improve\n",
      "Epoch 48/50\n",
      " - 52s - loss: 0.0992 - dice_coef: 0.9681 - acc: 0.9785 - val_loss: 0.1818 - val_dice_coef: 0.9524 - val_acc: 0.9625\n",
      "\n",
      "Epoch 00048: val_dice_coef did not improve\n",
      "Epoch 49/50\n",
      " - 52s - loss: 0.0959 - dice_coef: 0.9694 - acc: 0.9790 - val_loss: 0.2447 - val_dice_coef: 0.9447 - val_acc: 0.9557\n",
      "\n",
      "Epoch 00049: val_dice_coef did not improve\n",
      "Epoch 50/50\n",
      " - 52s - loss: 0.0929 - dice_coef: 0.9698 - acc: 0.9796 - val_loss: 0.2182 - val_dice_coef: 0.9369 - val_acc: 0.9507\n",
      "\n",
      "Epoch 00050: val_dice_coef did not improve\n",
      "Final model parameters set to stochastic weight average.\n",
      "Final stochastic averaged weights saved to file.\n"
     ]
    }
   ],
   "source": [
    "epochs = 50\n",
    "swa = SWA('./keras_2016_swa.model',45)\n",
    "snapshot = SnapshotCallbackBuilder(nb_epochs=epochs,nb_snapshots=1,round_=0 ,init_lr=1e-3)\n",
    "batch_size= 8\n",
    "\n",
    "\n",
    "\n",
    "history = model.fit_generator(train_generator,\n",
    "                        steps_per_epoch=np.ceil(float(len(os.listdir(train_path))) / float(batch_size)),\n",
    "                        epochs=epochs,\n",
    "                        validation_data=val_generator, \n",
    "                        #validation_steps=np.ceil(float(len(os.listdir(test_path))) / float(batch_size)),\n",
    "                        validation_steps=np.ceil(float(180) / float(batch_size)),\n",
    "                        callbacks=snapshot.get_callbacks(),verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "# code download from: https://github.com/bermanmaxim/LovaszSoftmax\n",
    "def lovasz_grad(gt_sorted):\n",
    "    \"\"\"\n",
    "    Computes gradient of the Lovasz extension w.r.t sorted errors\n",
    "    See Alg. 1 in paper\n",
    "    \"\"\"\n",
    "    gts = tf.reduce_sum(gt_sorted)\n",
    "    intersection = gts - tf.cumsum(gt_sorted)\n",
    "    union = gts + tf.cumsum(1. - gt_sorted)\n",
    "    jaccard = 1. - intersection / union\n",
    "    jaccard = tf.concat((jaccard[0:1], jaccard[1:] - jaccard[:-1]), 0)\n",
    "    return jaccard\n",
    "\n",
    "\n",
    "# --------------------------- BINARY LOSSES ---------------------------\n",
    "\n",
    "def lovasz_hinge(logits, labels, per_image=True, ignore=None):\n",
    "    \"\"\"\n",
    "    Binary Lovasz hinge loss\n",
    "      logits: [B, H, W] Variable, logits at each pixel (between -\\infty and +\\infty)\n",
    "      labels: [B, H, W] Tensor, binary ground truth masks (0 or 1)\n",
    "      per_image: compute the loss per image instead of per batch\n",
    "      ignore: void class id\n",
    "    \"\"\"\n",
    "    if per_image:\n",
    "        def treat_image(log_lab):\n",
    "            log, lab = log_lab\n",
    "            log, lab = tf.expand_dims(log, 0), tf.expand_dims(lab, 0)\n",
    "            log, lab = flatten_binary_scores(log, lab, ignore)\n",
    "            return lovasz_hinge_flat(log, lab)\n",
    "        losses = tf.map_fn(treat_image, (logits, labels), dtype=tf.float32)\n",
    "        loss = tf.reduce_mean(losses)\n",
    "    else:\n",
    "        loss = lovasz_hinge_flat(*flatten_binary_scores(logits, labels, ignore))\n",
    "    return loss\n",
    "\n",
    "\n",
    "def lovasz_hinge_flat(logits, labels):\n",
    "    \"\"\"\n",
    "    Binary Lovasz hinge loss\n",
    "      logits: [P] Variable, logits at each prediction (between -\\infty and +\\infty)\n",
    "      labels: [P] Tensor, binary ground truth labels (0 or 1)\n",
    "      ignore: label to ignore\n",
    "    \"\"\"\n",
    "\n",
    "    def compute_loss():\n",
    "        labelsf = tf.cast(labels, logits.dtype)\n",
    "        signs = 2. * labelsf - 1.\n",
    "        errors = 1. - logits * tf.stop_gradient(signs)\n",
    "        errors_sorted, perm = tf.nn.top_k(errors, k=tf.shape(errors)[0], name=\"descending_sort\")\n",
    "        gt_sorted = tf.gather(labelsf, perm)\n",
    "        grad = lovasz_grad(gt_sorted)\n",
    "        loss = tf.tensordot(tf.nn.elu(errors_sorted)+1, tf.stop_gradient(grad), 1, name=\"loss_non_void\")\n",
    "        return loss\n",
    "\n",
    "    # deal with the void prediction case (only void pixels)\n",
    "    loss = tf.cond(tf.equal(tf.shape(logits)[0], 0),\n",
    "                   lambda: tf.reduce_sum(logits) * 0.,\n",
    "                   compute_loss,\n",
    "                   strict=True,\n",
    "                   name=\"loss\"\n",
    "                   )\n",
    "    return loss\n",
    "\n",
    "\n",
    "def flatten_binary_scores(scores, labels, ignore=None):\n",
    "    \"\"\"\n",
    "    Flattens predictions in the batch (binary case)\n",
    "    Remove labels equal to 'ignore'\n",
    "    \"\"\"\n",
    "    scores = tf.reshape(scores, (-1,))\n",
    "    labels = tf.reshape(labels, (-1,))\n",
    "    if ignore is None:\n",
    "        return scores, labels\n",
    "    valid = tf.not_equal(labels, ignore)\n",
    "    vscores = tf.boolean_mask(scores, valid, name='valid_scores')\n",
    "    vlabels = tf.boolean_mask(labels, valid, name='valid_labels')\n",
    "    return vscores, vlabels\n",
    "\n",
    "def lovasz_loss(y_true, y_pred):\n",
    "    y_true, y_pred = K.cast(K.squeeze(y_true, -1), 'int32'), K.cast(K.squeeze(y_pred, -1), 'float32')\n",
    "    #logits = K.log(y_pred / (1. - y_pred))\n",
    "    logits = y_pred #Jiaxin\n",
    "    loss = lovasz_hinge(logits, y_true, per_image = True, ignore = None)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from __future__ import absolute_import\n",
    " \n",
    "import warnings\n",
    "import numpy as np\n",
    " \n",
    "from keras.preprocessing import image\n",
    " \n",
    "from keras.models import Model\n",
    "from keras import layers\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Input\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.layers import Activation\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import SeparableConv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import GlobalAveragePooling2D\n",
    "from keras.layers import GlobalMaxPooling2D\n",
    "from keras.engine.topology import get_source_inputs\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras import backend as K\n",
    "from keras.applications.imagenet_utils import decode_predictions\n",
    "from keras.applications.imagenet_utils import _obtain_input_shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Attention_Xception_1(include_top=True, weights='imagenet',\n",
    "             input_tensor=None, input_shape=None,\n",
    "             pooling=None,\n",
    "             classes=1000):\n",
    "   \n",
    "    if weights not in {'imagenet', None}:\n",
    "        raise ValueError('The `weights` argument should be either '\n",
    "                         '`None` (random initialization) or `imagenet` '\n",
    "                         '(pre-training on ImageNet).')\n",
    " \n",
    "    if weights == 'imagenet' and include_top and classes != 1000:\n",
    "        raise ValueError('If using `weights` as imagenet with `include_top`'\n",
    "                         ' as true, `classes` should be 1000')\n",
    " \n",
    "    if K.backend() != 'tensorflow':\n",
    "        raise RuntimeError('The Xception model is only available with '\n",
    "                           'the TensorFlow backend.')\n",
    "    if K.image_data_format() != 'channels_last':\n",
    "        warnings.warn('The Xception model is only available for the '\n",
    "                      'input data format \"channels_last\" '\n",
    "                      '(width, height, channels). '\n",
    "                      'However your settings specify the default '\n",
    "                      'data format \"channels_first\" (channels, width, height). '\n",
    "                      'You should set `image_data_format=\"channels_last\"` in your Keras '\n",
    "                      'config located at ~/.keras/keras.json. '\n",
    "                      'The model being returned right now will expect inputs '\n",
    "                      'to follow the \"channels_last\" data format.')\n",
    "        K.set_image_data_format('channels_last')\n",
    "        old_data_format = 'channels_first'\n",
    "    else:\n",
    "        old_data_format = None\n",
    " \n",
    "    input_shape = _obtain_input_shape(input_shape,\n",
    "                                      default_size=299,\n",
    "                                      min_size=71,\n",
    "                                      data_format=K.image_data_format(),\n",
    "                                      require_flatten=include_top)\n",
    " \n",
    "    if input_tensor is None:\n",
    "        img_input = Input(shape=input_shape)\n",
    "    else:\n",
    "        if not K.is_keras_tensor(input_tensor):\n",
    "            img_input = Input(tensor=input_tensor, shape=input_shape)\n",
    "        else:\n",
    "            img_input = input_tensor\n",
    " \n",
    "    x = Conv2D(32, (3, 3), strides=(2, 2), use_bias=False, name='block1_conv1')(img_input)\n",
    "    x = BatchNormalization(name='block1_conv1_bn')(x)\n",
    "    x = Activation('relu', name='block1_conv1_act')(x)\n",
    "    x = Conv2D(64, (3, 3), use_bias=False, name='block1_conv2')(x)\n",
    "    x = BatchNormalization(name='block1_conv2_bn')(x)\n",
    "    x = Activation('relu', name='block1_conv2_act')(x)\n",
    " \n",
    "    residual = Conv2D(128, (1, 1), strides=(2, 2),\n",
    "                      padding='same', use_bias=False)(x)\n",
    "    residual = BatchNormalization()(residual)\n",
    " \n",
    "\n",
    "    x0_input = Conv2D(128, (3, 3), padding='same', use_bias=False, name='block2_sepconv1')(x)\n",
    "    x0 = BatchNormalization(name='block2_sepconv1_bn')(x0_input)\n",
    "    x0 = Activation('relu', name='block2_sepconv2_act')(x0)\n",
    "    x0 = Conv2D(128, (3, 3), padding='same', use_bias=False, name='block2_sepconv2')(x0)\n",
    "    x0 = BatchNormalization(name='block2_sepconv2_bn')(x0)\n",
    " \n",
    "    x0 = MaxPooling2D((3, 3), strides=(2, 2), padding='same', name='block2_pool')(x0)\n",
    "    \n",
    "    x = layers.add([x, residual])\n",
    " \n",
    "    residual = Conv2D(256, (1, 1), strides=(2, 2),\n",
    "                      padding='same', use_bias=False)(x)\n",
    "    residual = BatchNormalization()(residual)\n",
    " \n",
    "    x = Activation('relu', name='block3_sepconv1_act')(x)\n",
    "    x = Conv2D(256, (3, 3), padding='same', use_bias=False, name='block3_sepconv1')(x)\n",
    "    x = BatchNormalization(name='block3_sepconv1_bn')(x)\n",
    "    x = Activation('relu', name='block3_sepconv2_act')(x)\n",
    "    x = Conv2D(256, (3, 3), padding='same', use_bias=False, name='block3_sepconv2')(x)\n",
    "    x = BatchNormalization(name='block3_sepconv2_bn')(x)\n",
    " \n",
    "    x = MaxPooling2D((3, 3), strides=(2, 2), padding='same', name='block3_pool')(x)\n",
    "    x = layers.add([x, residual])\n",
    " \n",
    "    residual = Conv2D(728, (1, 1), strides=(2, 2),\n",
    "                      padding='same', use_bias=False)(x)\n",
    "    residual = BatchNormalization()(residual)\n",
    " \n",
    "    x = Activation('relu', name='block4_sepconv1_act')(x)\n",
    "    x = Conv2D(728, (3, 3), padding='same', use_bias=False, name='block4_sepconv1')(x)\n",
    "    x = BatchNormalization(name='block4_sepconv1_bn')(x)\n",
    "    x = Activation('relu', name='block4_sepconv2_act')(x)\n",
    "    x = Conv2D(728, (3, 3), padding='same', use_bias=False, name='block4_sepconv2')(x)\n",
    "    x = BatchNormalization(name='block4_sepconv2_bn')(x)\n",
    " \n",
    "    x = MaxPooling2D((3, 3), strides=(2, 2), padding='same', name='block4_pool')(x)\n",
    "    x = layers.add([x, residual])\n",
    " \n",
    "    for i in range(8):\n",
    "        residual = x\n",
    "        prefix = 'block' + str(i + 5)\n",
    " \n",
    "        x = Activation('relu', name=prefix + '_sepconv1_act')(x)\n",
    "        x = Conv2D(728, (3, 3), padding='same', use_bias=False, name=prefix + '_sepconv1')(x)\n",
    "        x = BatchNormalization(name=prefix + '_sepconv1_bn')(x)\n",
    "        x = Activation('relu', name=prefix + '_sepconv2_act')(x)\n",
    "        x = Conv2D(728, (3, 3), padding='same', use_bias=False, name=prefix + '_sepconv2')(x)\n",
    "        x = BatchNormalization(name=prefix + '_sepconv2_bn')(x)\n",
    "        x = Activation('relu', name=prefix + '_sepconv3_act')(x)\n",
    "        x = Conv2D(728, (3, 3), padding='same', use_bias=False, name=prefix + '_sepconv3')(x)\n",
    "        x = BatchNormalization(name=prefix + '_sepconv3_bn')(x)\n",
    " \n",
    "        x = layers.add([x, residual])\n",
    " \n",
    "    residual = Conv2D(1024, (1, 1), strides=(2, 2),\n",
    "                      padding='same', use_bias=False)(x)\n",
    "    residual = BatchNormalization()(residual)\n",
    " \n",
    "    x = Activation('relu', name='block13_sepconv1_act')(x)\n",
    "    x = Conv2D(728, (3, 3), padding='same', use_bias=False, name='block13_sepconv1')(x)\n",
    "    x = BatchNormalization(name='block13_sepconv1_bn')(x)\n",
    "    x = Activation('relu', name='block13_sepconv2_act')(x)\n",
    "    x = Conv2D(1024, (3, 3), padding='same', use_bias=False, name='block13_sepconv2')(x)\n",
    "    x = BatchNormalization(name='block13_sepconv2_bn')(x)\n",
    " \n",
    "    x = MaxPooling2D((3, 3), strides=(2, 2), padding='same', name='block13_pool')(x)\n",
    "    x = layers.add([x, residual])\n",
    " \n",
    "    x = Conv2D(1536, (3, 3), padding='same', use_bias=False, name='block14_sepconv1')(x)\n",
    "    x = BatchNormalization(name='block14_sepconv1_bn')(x)\n",
    "    x = Activation('relu', name='block14_sepconv1_act')(x)\n",
    " \n",
    "    x = Conv2D(2048, (3, 3), padding='same', use_bias=False, name='block14_sepconv2')(x)\n",
    "    x = BatchNormalization(name='block14_sepconv2_bn')(x)\n",
    "    x = Activation('relu', name='block14_sepconv2_act')(x)\n",
    " \n",
    "    if include_top:\n",
    "        x = GlobalAveragePooling2D(name='avg_pool')(x)\n",
    "        x = Dense(classes, activation='softmax', name='predictions')(x)\n",
    "    else:\n",
    "        if pooling == 'avg':\n",
    "            x = GlobalAveragePooling2D()(x)\n",
    "        elif pooling == 'max':\n",
    "            x = GlobalMaxPooling2D()(x)\n",
    " \n",
    "    if input_tensor is not None:\n",
    "        inputs = get_source_inputs(input_tensor)\n",
    "    else:\n",
    "        inputs = img_input\n",
    " \n",
    "    model = Model(inputs, x, name='xception')\n",
    " \n",
    "    if weights == 'imagenet':\n",
    "       # if include_top:\n",
    "           # weights_path = get_file('xception_weights_tf_dim_ordering_tf_kernels.h5',\n",
    "                                   # TF_WEIGHTS_PATH,\n",
    "                                   # cache_subdir='models')\n",
    "       #else:\n",
    "            #weights_path = get_file('xception_weights_tf_dim_ordering_tf_kernels_notop.h5',\n",
    "                                   # TF_WEIGHTS_PATH_NO_TOP,\n",
    "                                   # cache_subdir='models')\n",
    "        #model.load_weights(weights_path)\n",
    "        model.load_weights('xception_weights_tf_dim_ordering_tf_kernels_notop.h5')\n",
    "        K.set_image_data_format(old_data_format)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import SeparableConv2D\n",
    "def convolution_block(x, filters, size, strides=(1,1), padding='same', activation=True):\n",
    "    x = SeparableConv2D(filters, size, strides=strides, padding=padding)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    if activation == True:\n",
    "        x = LeakyReLU(alpha=0.1)(x)\n",
    "    return x\n",
    "\n",
    "def residual_block(blockInput, num_filters=16):\n",
    "    x = LeakyReLU(alpha=0.1)(blockInput)\n",
    "    x = BatchNormalization()(x)\n",
    "    blockInput = BatchNormalization()(blockInput)\n",
    "    x = convolution_block(x, num_filters, (3,3) )\n",
    "    x = convolution_block(x, num_filters, (3,3), activation=False)\n",
    "    x = Add()([x, blockInput])\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def UXception_all_conv(input_shape=(None, None, 3)):\n",
    "\n",
    "    backbone = MyselfXception(input_shape=input_shape,weights=None,include_top=False)\n",
    "    #backbone = Xception(input_shape=input_shape,weights='imagenet',include_top=False)\n",
    "    input = backbone.input\n",
    "    start_neurons = 16\n",
    "\n",
    "    conv4 = backbone.layers[121].output\n",
    "    conv4 = LeakyReLU(alpha=0.1)(conv4)\n",
    "    pool4 = MaxPooling2D((2, 2))(conv4)\n",
    "    pool4 = Dropout(0.1)(pool4)\n",
    "    \n",
    "     # Middle\n",
    "    convm = Conv2D(start_neurons * 32, (3, 3), activation=None, padding=\"same\")(pool4)\n",
    "    convm = residual_block(convm,start_neurons * 32)\n",
    "    convm = residual_block(convm,start_neurons * 32)\n",
    "    convm = LeakyReLU(alpha=0.1)(convm)\n",
    "    \n",
    "    # 10 -> 20\n",
    "    deconv4 = Conv2DTranspose(start_neurons * 16, (3, 3), strides=(2, 2), padding=\"same\")(convm)\n",
    "    uconv4 = concatenate([deconv4, conv4])\n",
    "    uconv4 = Dropout(0.1)(uconv4)\n",
    "    \n",
    "    uconv4 = Conv2D(start_neurons * 16, (3, 3), activation=None, padding=\"same\")(uconv4)\n",
    "    uconv4 = residual_block(uconv4,start_neurons * 16)\n",
    "    uconv4 = residual_block(uconv4,start_neurons * 16)\n",
    "    uconv4 = LeakyReLU(alpha=0.1,name='output_4')(uconv4)\n",
    "    \n",
    "    # 10 -> 20\n",
    "    deconv3 = Conv2DTranspose(start_neurons * 8, (3, 3), strides=(2, 2), padding=\"same\")(uconv4)\n",
    "    conv3 = backbone.layers[31].output\n",
    "    uconv3 = concatenate([deconv3, conv3])    \n",
    "    uconv3 = Dropout(0.1)(uconv3)\n",
    "    \n",
    "    uconv3 = Conv2D(start_neurons * 8, (3, 3), activation=None, padding=\"same\")(uconv3)\n",
    "    uconv3 = residual_block(uconv3,start_neurons * 8)\n",
    "    uconv3 = residual_block(uconv3,start_neurons * 8)\n",
    "    uconv3 = LeakyReLU(alpha=0.1,name='output_3')(uconv3)\n",
    "\n",
    "    # 20 -> 40\n",
    "    deconv2 = Conv2DTranspose(start_neurons * 4, (3, 3), strides=(2, 2), padding=\"same\")(uconv3)\n",
    "    conv2 = backbone.layers[21].output\n",
    "    conv2 = ZeroPadding2D(((1,0),(1,0)))(conv2)\n",
    "    uconv2 = concatenate([deconv2, conv2])\n",
    "        \n",
    "    uconv2 = Dropout(0.1)(uconv2)\n",
    "    uconv2 = Conv2D(start_neurons * 4, (3, 3), activation=None, padding=\"same\")(uconv2)\n",
    "    uconv2 = residual_block(uconv2,start_neurons * 4)\n",
    "    uconv2 = residual_block(uconv2,start_neurons * 4)\n",
    "    uconv2 = LeakyReLU(alpha=0.1,name='output_2')(uconv2)\n",
    "    \n",
    "    # 40 -> 80\n",
    "    deconv1 = Conv2DTranspose(start_neurons * 2, (3, 3), strides=(2, 2), padding=\"same\")(uconv2)\n",
    "    conv1 = backbone.layers[11].output\n",
    "    conv1 = ZeroPadding2D(((3,0),(3,0)))(conv1)\n",
    "    uconv1 = concatenate([deconv1, conv1])\n",
    "    \n",
    "    uconv1 = Dropout(0.1)(uconv1)\n",
    "    uconv1 = Conv2D(start_neurons * 2, (3, 3), activation=None, padding=\"same\")(uconv1)\n",
    "    uconv1 = residual_block(uconv1,start_neurons * 2)\n",
    "    uconv1 = residual_block(uconv1,start_neurons * 2)\n",
    "    uconv1 = LeakyReLU(alpha=0.1,name='output_1')(uconv1)\n",
    "    \n",
    "    \n",
    "    # 80 -> 160\n",
    "    uconv0 = Conv2DTranspose(start_neurons * 1, (3, 3), strides=(2, 2), padding=\"same\")(uconv1)   \n",
    "    uconv0 = Dropout(0.1)(uconv0)\n",
    "    uconv0 = Conv2D(start_neurons * 1, (3, 3), activation=None, padding=\"same\")(uconv0)\n",
    "    uconv0 = residual_block(uconv0,start_neurons * 1)\n",
    "    uconv0 = residual_block(uconv0,start_neurons * 1)\n",
    "    uconv0 = LeakyReLU(alpha=0.1,name='output_0')(uconv0)\n",
    "    \n",
    "    uconv0 = Dropout(0.1/2)(uconv0)\n",
    "    output_layer = Conv2D(1, (1,1),activation=None,padding='same')(uconv0)    \n",
    "    output_layer_sigmoid = Activation('sigmoid',name='prediction')(output_layer)\n",
    "    \n",
    "    model = Model(input, output_layer_sigmoid)\n",
    "    model.name = 'u-xception'\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def UXception_all_separable(input_shape=(None, None, 3)):\n",
    "\n",
    "    #backbone = MyselfXception(input_shape=input_shape,weights=None,include_top=False)\n",
    "    backbone = Xception(input_shape=input_shape,weights='imagenet',include_top=False)\n",
    "    input = backbone.input\n",
    "    start_neurons = 16\n",
    "\n",
    "    conv4 = backbone.layers[121].output\n",
    "    conv4 = LeakyReLU(alpha=0.1)(conv4)\n",
    "    pool4 = MaxPooling2D((2, 2))(conv4)\n",
    "    pool4 = Dropout(0.1)(pool4)\n",
    "    \n",
    "     # Middle\n",
    "    convm = SeparableConv2D(start_neurons * 32, (3, 3), activation=None, padding=\"same\")(pool4)\n",
    "    convm = residual_block(convm,start_neurons * 32)\n",
    "    convm = residual_block(convm,start_neurons * 32)\n",
    "    convm = LeakyReLU(alpha=0.1)(convm)\n",
    "    \n",
    "    # 10 -> 20\n",
    "    deconv4 = Conv2DTranspose(start_neurons * 16, (3, 3), strides=(2, 2), padding=\"same\")(convm)\n",
    "    uconv4 = concatenate([deconv4, conv4])\n",
    "    uconv4 = Dropout(0.1)(uconv4)\n",
    "    \n",
    "    uconv4 = SeparableConv2D(start_neurons * 16, (3, 3), activation=None, padding=\"same\")(uconv4)\n",
    "    uconv4 = residual_block(uconv4,start_neurons * 16)\n",
    "    uconv4 = residual_block(uconv4,start_neurons * 16)\n",
    "    uconv4 = LeakyReLU(alpha=0.1,name='output_4')(uconv4)\n",
    "    \n",
    "    # 10 -> 20\n",
    "    deconv3 = Conv2DTranspose(start_neurons * 8, (3, 3), strides=(2, 2), padding=\"same\")(uconv4)\n",
    "    conv3 = backbone.layers[31].output\n",
    "    uconv3 = concatenate([deconv3, conv3])    \n",
    "    uconv3 = Dropout(0.1)(uconv3)\n",
    "    \n",
    "    uconv3 = SeparableConv2D(start_neurons * 8, (3, 3), activation=None, padding=\"same\")(uconv3)\n",
    "    uconv3 = residual_block(uconv3,start_neurons * 8)\n",
    "    uconv3 = residual_block(uconv3,start_neurons * 8)\n",
    "    uconv3 = LeakyReLU(alpha=0.1,name='output_3')(uconv3)\n",
    "\n",
    "    # 20 -> 40\n",
    "    deconv2 = Conv2DTranspose(start_neurons * 4, (3, 3), strides=(2, 2), padding=\"same\")(uconv3)\n",
    "    conv2 = backbone.layers[21].output\n",
    "    conv2 = ZeroPadding2D(((1,0),(1,0)))(conv2)\n",
    "    uconv2 = concatenate([deconv2, conv2])\n",
    "        \n",
    "    uconv2 = Dropout(0.1)(uconv2)\n",
    "    uconv2 = Conv2D(start_neurons * 4, (3, 3), activation=None, padding=\"same\")(uconv2)\n",
    "    uconv2 = residual_block(uconv2,start_neurons * 4)\n",
    "    uconv2 = residual_block(uconv2,start_neurons * 4)\n",
    "    uconv2 = LeakyReLU(alpha=0.1,name='output_2')(uconv2)\n",
    "    \n",
    "    # 40 -> 80\n",
    "    deconv1 = Conv2DTranspose(start_neurons * 2, (3, 3), strides=(2, 2), padding=\"same\")(uconv2)\n",
    "    conv1 = backbone.layers[11].output\n",
    "    conv1 = ZeroPadding2D(((3,0),(3,0)))(conv1)\n",
    "    uconv1 = concatenate([deconv1, conv1])\n",
    "    \n",
    "    uconv1 = Dropout(0.1)(uconv1)\n",
    "    uconv1 = SeparableConv2D(start_neurons * 2, (3, 3), activation=None, padding=\"same\")(uconv1)\n",
    "    uconv1 = residual_block(uconv1,start_neurons * 2)\n",
    "    uconv1 = residual_block(uconv1,start_neurons * 2)\n",
    "    uconv1 = LeakyReLU(alpha=0.1,name='output_1')(uconv1)\n",
    "    \n",
    "    \n",
    "    # 80 -> 160\n",
    "    uconv0 = Conv2DTranspose(start_neurons * 1, (3, 3), strides=(2, 2), padding=\"same\")(uconv1)   \n",
    "    uconv0 = Dropout(0.1)(uconv0)\n",
    "    uconv0 = SeparableConv2D(start_neurons * 1, (3, 3), activation=None, padding=\"same\")(uconv0)\n",
    "    uconv0 = residual_block(uconv0,start_neurons * 1)\n",
    "    uconv0 = residual_block(uconv0,start_neurons * 1)\n",
    "    uconv0 = LeakyReLU(alpha=0.1,name='output_0')(uconv0)\n",
    "    \n",
    "    uconv0 = Dropout(0.1/2)(uconv0)\n",
    "    output_layer = Conv2D(1, (1,1),activation=None,padding='same')(uconv0)    \n",
    "    output_layer_sigmoid = Activation('sigmoid',name='prediction')(output_layer)\n",
    "    \n",
    "    model = Model(input, output_layer_sigmoid)\n",
    "    model.name = 'u-xception'\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 192, 256, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1 (Conv2D)           (None, 95, 127, 32)  864         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1_bn (BatchNormaliza (None, 95, 127, 32)  128         block1_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1_act (Activation)   (None, 95, 127, 32)  0           block1_conv1_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2 (Conv2D)           (None, 93, 125, 64)  18432       block1_conv1_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2_bn (BatchNormaliza (None, 93, 125, 64)  256         block1_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2_act (Activation)   (None, 93, 125, 64)  0           block1_conv2_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv1 (SeparableConv2 (None, 93, 125, 128) 8768        block1_conv2_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv1_bn (BatchNormal (None, 93, 125, 128) 512         block2_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv2_act (Activation (None, 93, 125, 128) 0           block2_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv2 (SeparableConv2 (None, 93, 125, 128) 17536       block2_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv2_bn (BatchNormal (None, 93, 125, 128) 512         block2_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 47, 63, 128)  8192        block1_conv2_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block2_pool (MaxPooling2D)      (None, 47, 63, 128)  0           block2_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 47, 63, 128)  512         conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 47, 63, 128)  0           block2_pool[0][0]                \n",
      "                                                                 batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv1_act (Activation (None, 47, 63, 128)  0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv1 (SeparableConv2 (None, 47, 63, 256)  33920       block3_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv1_bn (BatchNormal (None, 47, 63, 256)  1024        block3_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv2_act (Activation (None, 47, 63, 256)  0           block3_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv2 (SeparableConv2 (None, 47, 63, 256)  67840       block3_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv2_bn (BatchNormal (None, 47, 63, 256)  1024        block3_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 24, 32, 256)  32768       add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block3_pool (MaxPooling2D)      (None, 24, 32, 256)  0           block3_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 24, 32, 256)  1024        conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 24, 32, 256)  0           block3_pool[0][0]                \n",
      "                                                                 batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv1_act (Activation (None, 24, 32, 256)  0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv1 (SeparableConv2 (None, 24, 32, 728)  188672      block4_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv1_bn (BatchNormal (None, 24, 32, 728)  2912        block4_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv2_act (Activation (None, 24, 32, 728)  0           block4_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv2 (SeparableConv2 (None, 24, 32, 728)  536536      block4_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv2_bn (BatchNormal (None, 24, 32, 728)  2912        block4_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 12, 16, 728)  186368      add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block4_pool (MaxPooling2D)      (None, 12, 16, 728)  0           block4_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 12, 16, 728)  2912        conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 12, 16, 728)  0           block4_pool[0][0]                \n",
      "                                                                 batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv1_act (Activation (None, 12, 16, 728)  0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv1 (SeparableConv2 (None, 12, 16, 728)  536536      block5_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv1_bn (BatchNormal (None, 12, 16, 728)  2912        block5_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv2_act (Activation (None, 12, 16, 728)  0           block5_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv2 (SeparableConv2 (None, 12, 16, 728)  536536      block5_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv2_bn (BatchNormal (None, 12, 16, 728)  2912        block5_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv3_act (Activation (None, 12, 16, 728)  0           block5_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv3 (SeparableConv2 (None, 12, 16, 728)  536536      block5_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv3_bn (BatchNormal (None, 12, 16, 728)  2912        block5_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 12, 16, 728)  0           block5_sepconv3_bn[0][0]         \n",
      "                                                                 add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv1_act (Activation (None, 12, 16, 728)  0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv1 (SeparableConv2 (None, 12, 16, 728)  536536      block6_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv1_bn (BatchNormal (None, 12, 16, 728)  2912        block6_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv2_act (Activation (None, 12, 16, 728)  0           block6_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv2 (SeparableConv2 (None, 12, 16, 728)  536536      block6_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv2_bn (BatchNormal (None, 12, 16, 728)  2912        block6_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv3_act (Activation (None, 12, 16, 728)  0           block6_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv3 (SeparableConv2 (None, 12, 16, 728)  536536      block6_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv3_bn (BatchNormal (None, 12, 16, 728)  2912        block6_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 12, 16, 728)  0           block6_sepconv3_bn[0][0]         \n",
      "                                                                 add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv1_act (Activation (None, 12, 16, 728)  0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv1 (SeparableConv2 (None, 12, 16, 728)  536536      block7_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv1_bn (BatchNormal (None, 12, 16, 728)  2912        block7_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv2_act (Activation (None, 12, 16, 728)  0           block7_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv2 (SeparableConv2 (None, 12, 16, 728)  536536      block7_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv2_bn (BatchNormal (None, 12, 16, 728)  2912        block7_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv3_act (Activation (None, 12, 16, 728)  0           block7_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv3 (SeparableConv2 (None, 12, 16, 728)  536536      block7_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv3_bn (BatchNormal (None, 12, 16, 728)  2912        block7_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 12, 16, 728)  0           block7_sepconv3_bn[0][0]         \n",
      "                                                                 add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv1_act (Activation (None, 12, 16, 728)  0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv1 (SeparableConv2 (None, 12, 16, 728)  536536      block8_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv1_bn (BatchNormal (None, 12, 16, 728)  2912        block8_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv2_act (Activation (None, 12, 16, 728)  0           block8_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv2 (SeparableConv2 (None, 12, 16, 728)  536536      block8_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv2_bn (BatchNormal (None, 12, 16, 728)  2912        block8_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv3_act (Activation (None, 12, 16, 728)  0           block8_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv3 (SeparableConv2 (None, 12, 16, 728)  536536      block8_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv3_bn (BatchNormal (None, 12, 16, 728)  2912        block8_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 12, 16, 728)  0           block8_sepconv3_bn[0][0]         \n",
      "                                                                 add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv1_act (Activation (None, 12, 16, 728)  0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "block9_sepconv1 (SeparableConv2 (None, 12, 16, 728)  536536      block9_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv1_bn (BatchNormal (None, 12, 16, 728)  2912        block9_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv2_act (Activation (None, 12, 16, 728)  0           block9_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv2 (SeparableConv2 (None, 12, 16, 728)  536536      block9_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv2_bn (BatchNormal (None, 12, 16, 728)  2912        block9_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv3_act (Activation (None, 12, 16, 728)  0           block9_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv3 (SeparableConv2 (None, 12, 16, 728)  536536      block9_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv3_bn (BatchNormal (None, 12, 16, 728)  2912        block9_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 12, 16, 728)  0           block9_sepconv3_bn[0][0]         \n",
      "                                                                 add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv1_act (Activatio (None, 12, 16, 728)  0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv1 (SeparableConv (None, 12, 16, 728)  536536      block10_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv1_bn (BatchNorma (None, 12, 16, 728)  2912        block10_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv2_act (Activatio (None, 12, 16, 728)  0           block10_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv2 (SeparableConv (None, 12, 16, 728)  536536      block10_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv2_bn (BatchNorma (None, 12, 16, 728)  2912        block10_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv3_act (Activatio (None, 12, 16, 728)  0           block10_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv3 (SeparableConv (None, 12, 16, 728)  536536      block10_sepconv3_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv3_bn (BatchNorma (None, 12, 16, 728)  2912        block10_sepconv3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 12, 16, 728)  0           block10_sepconv3_bn[0][0]        \n",
      "                                                                 add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv1_act (Activatio (None, 12, 16, 728)  0           add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv1 (SeparableConv (None, 12, 16, 728)  536536      block11_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv1_bn (BatchNorma (None, 12, 16, 728)  2912        block11_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv2_act (Activatio (None, 12, 16, 728)  0           block11_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv2 (SeparableConv (None, 12, 16, 728)  536536      block11_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv2_bn (BatchNorma (None, 12, 16, 728)  2912        block11_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv3_act (Activatio (None, 12, 16, 728)  0           block11_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv3 (SeparableConv (None, 12, 16, 728)  536536      block11_sepconv3_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv3_bn (BatchNorma (None, 12, 16, 728)  2912        block11_sepconv3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 12, 16, 728)  0           block11_sepconv3_bn[0][0]        \n",
      "                                                                 add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv1_act (Activatio (None, 12, 16, 728)  0           add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv1 (SeparableConv (None, 12, 16, 728)  536536      block12_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv1_bn (BatchNorma (None, 12, 16, 728)  2912        block12_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv2_act (Activatio (None, 12, 16, 728)  0           block12_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv2 (SeparableConv (None, 12, 16, 728)  536536      block12_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv2_bn (BatchNorma (None, 12, 16, 728)  2912        block12_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv3_act (Activatio (None, 12, 16, 728)  0           block12_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv3 (SeparableConv (None, 12, 16, 728)  536536      block12_sepconv3_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv3_bn (BatchNorma (None, 12, 16, 728)  2912        block12_sepconv3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 12, 16, 728)  0           block12_sepconv3_bn[0][0]        \n",
      "                                                                 add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv1_act (Activatio (None, 12, 16, 728)  0           add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv1 (SeparableConv (None, 12, 16, 728)  536536      block13_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv1_bn (BatchNorma (None, 12, 16, 728)  2912        block13_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv2_act (Activatio (None, 12, 16, 728)  0           block13_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv2 (SeparableConv (None, 12, 16, 1024) 752024      block13_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv2_bn (BatchNorma (None, 12, 16, 1024) 4096        block13_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)       (None, 12, 16, 1024) 0           block13_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 6, 8, 1024)   0           leaky_re_lu_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 6, 8, 1024)   0           max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_1 (SeparableCo (None, 6, 8, 512)    534016      dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)       (None, 6, 8, 512)    0           separable_conv2d_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 6, 8, 512)    2048        leaky_re_lu_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_2 (SeparableCo (None, 6, 8, 512)    267264      batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 6, 8, 512)    2048        separable_conv2d_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)       (None, 6, 8, 512)    0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_3 (SeparableCo (None, 6, 8, 512)    267264      leaky_re_lu_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 6, 8, 512)    2048        separable_conv2d_3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 6, 8, 512)    2048        separable_conv2d_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "add_13 (Add)                    (None, 6, 8, 512)    0           batch_normalization_8[0][0]      \n",
      "                                                                 batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)       (None, 6, 8, 512)    0           add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 6, 8, 512)    2048        leaky_re_lu_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_4 (SeparableCo (None, 6, 8, 512)    267264      batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 6, 8, 512)    2048        separable_conv2d_4[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)       (None, 6, 8, 512)    0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_5 (SeparableCo (None, 6, 8, 512)    267264      leaky_re_lu_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 6, 8, 512)    2048        separable_conv2d_5[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 6, 8, 512)    2048        add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "add_14 (Add)                    (None, 6, 8, 512)    0           batch_normalization_12[0][0]     \n",
      "                                                                 batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)       (None, 6, 8, 512)    0           add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTrans (None, 12, 16, 256)  1179904     leaky_re_lu_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 12, 16, 1280) 0           conv2d_transpose_1[0][0]         \n",
      "                                                                 leaky_re_lu_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 12, 16, 1280) 0           concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_6 (SeparableCo (None, 12, 16, 256)  339456      dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)       (None, 12, 16, 256)  0           separable_conv2d_6[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 12, 16, 256)  1024        leaky_re_lu_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_7 (SeparableCo (None, 12, 16, 256)  68096       batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 12, 16, 256)  1024        separable_conv2d_7[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_8 (LeakyReLU)       (None, 12, 16, 256)  0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_8 (SeparableCo (None, 12, 16, 256)  68096       leaky_re_lu_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 12, 16, 256)  1024        separable_conv2d_8[0][0]         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 12, 16, 256)  1024        separable_conv2d_6[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "add_15 (Add)                    (None, 12, 16, 256)  0           batch_normalization_16[0][0]     \n",
      "                                                                 batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_9 (LeakyReLU)       (None, 12, 16, 256)  0           add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 12, 16, 256)  1024        leaky_re_lu_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_9 (SeparableCo (None, 12, 16, 256)  68096       batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 12, 16, 256)  1024        separable_conv2d_9[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_10 (LeakyReLU)      (None, 12, 16, 256)  0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_10 (SeparableC (None, 12, 16, 256)  68096       leaky_re_lu_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 12, 16, 256)  1024        separable_conv2d_10[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 12, 16, 256)  1024        add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "add_16 (Add)                    (None, 12, 16, 256)  0           batch_normalization_20[0][0]     \n",
      "                                                                 batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "output_4 (LeakyReLU)            (None, 12, 16, 256)  0           add_16[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTrans (None, 24, 32, 128)  295040      output_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 24, 32, 856)  0           conv2d_transpose_2[0][0]         \n",
      "                                                                 block4_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 24, 32, 856)  0           concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_11 (SeparableC (None, 24, 32, 128)  117400      dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_11 (LeakyReLU)      (None, 24, 32, 128)  0           separable_conv2d_11[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 24, 32, 128)  512         leaky_re_lu_11[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_12 (SeparableC (None, 24, 32, 128)  17664       batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 24, 32, 128)  512         separable_conv2d_12[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_12 (LeakyReLU)      (None, 24, 32, 128)  0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_13 (SeparableC (None, 24, 32, 128)  17664       leaky_re_lu_12[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 24, 32, 128)  512         separable_conv2d_13[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 24, 32, 128)  512         separable_conv2d_11[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "add_17 (Add)                    (None, 24, 32, 128)  0           batch_normalization_24[0][0]     \n",
      "                                                                 batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_13 (LeakyReLU)      (None, 24, 32, 128)  0           add_17[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 24, 32, 128)  512         leaky_re_lu_13[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_14 (SeparableC (None, 24, 32, 128)  17664       batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 24, 32, 128)  512         separable_conv2d_14[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_14 (LeakyReLU)      (None, 24, 32, 128)  0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_15 (SeparableC (None, 24, 32, 128)  17664       leaky_re_lu_14[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 24, 32, 128)  512         separable_conv2d_15[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 24, 32, 128)  512         add_17[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "add_18 (Add)                    (None, 24, 32, 128)  0           batch_normalization_28[0][0]     \n",
      "                                                                 batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "output_3 (LeakyReLU)            (None, 24, 32, 128)  0           add_18[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_3 (Conv2DTrans (None, 48, 64, 64)   73792       output_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_1 (ZeroPadding2D (None, 48, 64, 256)  0           block3_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 48, 64, 320)  0           conv2d_transpose_3[0][0]         \n",
      "                                                                 zero_padding2d_1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 48, 64, 320)  0           concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_16 (SeparableC (None, 48, 64, 64)   23424       dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_15 (LeakyReLU)      (None, 48, 64, 64)   0           separable_conv2d_16[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 48, 64, 64)   256         leaky_re_lu_15[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_17 (SeparableC (None, 48, 64, 64)   4736        batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 48, 64, 64)   256         separable_conv2d_17[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_16 (LeakyReLU)      (None, 48, 64, 64)   0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_18 (SeparableC (None, 48, 64, 64)   4736        leaky_re_lu_16[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 48, 64, 64)   256         separable_conv2d_18[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 48, 64, 64)   256         separable_conv2d_16[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "add_19 (Add)                    (None, 48, 64, 64)   0           batch_normalization_32[0][0]     \n",
      "                                                                 batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_17 (LeakyReLU)      (None, 48, 64, 64)   0           add_19[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 48, 64, 64)   256         leaky_re_lu_17[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_19 (SeparableC (None, 48, 64, 64)   4736        batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 48, 64, 64)   256         separable_conv2d_19[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_18 (LeakyReLU)      (None, 48, 64, 64)   0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_20 (SeparableC (None, 48, 64, 64)   4736        leaky_re_lu_18[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 48, 64, 64)   256         separable_conv2d_20[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 48, 64, 64)   256         add_19[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "add_20 (Add)                    (None, 48, 64, 64)   0           batch_normalization_36[0][0]     \n",
      "                                                                 batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "output_2 (LeakyReLU)            (None, 48, 64, 64)   0           add_20[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_4 (Conv2DTrans (None, 96, 128, 32)  18464       output_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_2 (ZeroPadding2D (None, 96, 128, 128) 0           block2_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 96, 128, 160) 0           conv2d_transpose_4[0][0]         \n",
      "                                                                 zero_padding2d_2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 96, 128, 160) 0           concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_21 (SeparableC (None, 96, 128, 32)  6592        dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_19 (LeakyReLU)      (None, 96, 128, 32)  0           separable_conv2d_21[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 96, 128, 32)  128         leaky_re_lu_19[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_22 (SeparableC (None, 96, 128, 32)  1344        batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 96, 128, 32)  128         separable_conv2d_22[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_20 (LeakyReLU)      (None, 96, 128, 32)  0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_23 (SeparableC (None, 96, 128, 32)  1344        leaky_re_lu_20[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 96, 128, 32)  128         separable_conv2d_23[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 96, 128, 32)  128         separable_conv2d_21[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "add_21 (Add)                    (None, 96, 128, 32)  0           batch_normalization_40[0][0]     \n",
      "                                                                 batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_21 (LeakyReLU)      (None, 96, 128, 32)  0           add_21[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 96, 128, 32)  128         leaky_re_lu_21[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_24 (SeparableC (None, 96, 128, 32)  1344        batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, 96, 128, 32)  128         separable_conv2d_24[0][0]        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_22 (LeakyReLU)      (None, 96, 128, 32)  0           batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_25 (SeparableC (None, 96, 128, 32)  1344        leaky_re_lu_22[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, 96, 128, 32)  128         separable_conv2d_25[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, 96, 128, 32)  128         add_21[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "add_22 (Add)                    (None, 96, 128, 32)  0           batch_normalization_44[0][0]     \n",
      "                                                                 batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "output_1 (LeakyReLU)            (None, 96, 128, 32)  0           add_22[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_5 (Conv2DTrans (None, 192, 256, 16) 4624        output_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 192, 256, 16) 0           conv2d_transpose_5[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_26 (SeparableC (None, 192, 256, 16) 416         dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_23 (LeakyReLU)      (None, 192, 256, 16) 0           separable_conv2d_26[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, 192, 256, 16) 64          leaky_re_lu_23[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_27 (SeparableC (None, 192, 256, 16) 416         batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, 192, 256, 16) 64          separable_conv2d_27[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_24 (LeakyReLU)      (None, 192, 256, 16) 0           batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_28 (SeparableC (None, 192, 256, 16) 416         leaky_re_lu_24[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, 192, 256, 16) 64          separable_conv2d_28[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, 192, 256, 16) 64          separable_conv2d_26[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "add_23 (Add)                    (None, 192, 256, 16) 0           batch_normalization_48[0][0]     \n",
      "                                                                 batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_25 (LeakyReLU)      (None, 192, 256, 16) 0           add_23[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, 192, 256, 16) 64          leaky_re_lu_25[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_29 (SeparableC (None, 192, 256, 16) 416         batch_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNo (None, 192, 256, 16) 64          separable_conv2d_29[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_26 (LeakyReLU)      (None, 192, 256, 16) 0           batch_normalization_51[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_30 (SeparableC (None, 192, 256, 16) 416         leaky_re_lu_26[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_52 (BatchNo (None, 192, 256, 16) 64          separable_conv2d_30[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, 192, 256, 16) 64          add_23[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "add_24 (Add)                    (None, 192, 256, 16) 0           batch_normalization_52[0][0]     \n",
      "                                                                 batch_normalization_50[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "output_0 (LeakyReLU)            (None, 192, 256, 16) 0           add_24[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 192, 256, 16) 0           output_0[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 192, 256, 1)  17          dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "prediction (Activation)         (None, 192, 256, 1)  0           conv2d_5[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 19,419,425\n",
      "Trainable params: 19,357,985\n",
      "Non-trainable params: 61,440\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "K.clear_session()\n",
    "model = UXception_all_separable(input_shape=(img_height,img_width,3))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sgd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-6c391974fcc0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbce_dice_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msgd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdice_coef\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'acc'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'sgd' is not defined"
     ]
    }
   ],
   "source": [
    "model.compile(loss=bce_dice_loss, optimizer=sgd, metrics=[dice_coef,'acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'get_unet' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-a8ea6ecd38cf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_unet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'get_unet' is not defined"
     ]
    }
   ],
   "source": [
    "model = get_unet()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_x = model.layers[0].input\n",
    "output_layer = model.layers[-1].input\n",
    "model_lovasz = Model(input_x, output_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 379/379 [00:27<00:00, 13.67it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "test_path = 'C:/Users/hyc/Desktop/skin_lesion/segmentation/seg_test/'\n",
    "test_img_list = []\n",
    "for name in tqdm(os.listdir(test_path)):\n",
    "    img = cv2.resize(cv2.imread(os.path.join(test_path,name))[:,:,0],(img_width,img_height))\n",
    "    #prediction = model.predict(img)\n",
    "    test_img_list.append(np.expand_dims(img,axis=-1))\n",
    "test_img_array = np.array(test_img_list,np.float32)/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 379/379 [00:13<00:00, 27.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_test_time: 13.934715270996094\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "import gc\n",
    "import os \n",
    "from tqdm import tqdm\n",
    "#model.load_weights('./keras_2016_swa.model')\n",
    "model.load_weights('./keras_2016_swa.modell')\n",
    "#test_path = 'C:/Users/hyc/Desktop/skin_lesion/segmentation/polar_test/'\n",
    "test_path = 'C:/Users/hyc/Desktop/skin_lesion/segmentation/seg_test/'\n",
    "prediction_path ='./prediction_2016_s/'\n",
    "if not os.path.exists(prediction_path):\n",
    "    os.mkdir(prediction_path)\n",
    "test_img_list = []\n",
    "for name in tqdm(os.listdir(test_path)):\n",
    "    #img = cv2.resize(cv2.imread(os.path.join(test_path,name))[:,:,0],(img_width,img_height))/255\n",
    "    img = cv2.resize(cv2.imread(os.path.join(test_path,name)),(img_width,img_height))\n",
    "    img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)/255\n",
    "    #print(img)\n",
    "    #print(img.shape)\n",
    "    img = np.expand_dims(img,axis=0)\n",
    "    #img = np.expand_dims(img,axis=-1)\n",
    "    pred = model.predict(img)\n",
    "    pred = pred[0,:,:,0]*255\n",
    "    cv2.imwrite(prediction_path+name,pred)\n",
    "    \n",
    "end = time.time()\n",
    "print(\"total_test_time: {}\".format(end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 40/40 [00:01<00:00, 26.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_test_time: 9.633894443511963\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "import gc\n",
    "import os \n",
    "from tqdm import tqdm\n",
    "model.load_weights('keras.model')\n",
    "test_path = './ph2/img/'\n",
    "prediction_path ='./ph2/prediction_validataion_swa_speconv/'\n",
    "if not os.path.exists(prediction_path):\n",
    "    os.mkdir(prediction_path)\n",
    "test_img_list = []\n",
    "for name in tqdm(os.listdir(test_path)[160:]):\n",
    "    #img = cv2.resize(cv2.imread(os.path.join(test_path,name))[:,:,0],(img_width,img_height))/255\n",
    "    img = cv2.resize(cv2.imread(os.path.join(test_path,name)),(img_width,img_height))\n",
    "    img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)/255\n",
    "    #print(img)\n",
    "    #print(img.shape)\n",
    "    img = np.expand_dims(img,axis=0)\n",
    "    #img = np.expand_dims(img,axis=-1)\n",
    "    pred = model.predict(img)\n",
    "    pred = pred[0,:,:,0]*255\n",
    "    cv2.imwrite(prediction_path+name,pred)\n",
    "    \n",
    "end = time.time()\n",
    "print(\"total_test_time: {}\".format(end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "  0%|                                                                                          | 0/600 [00:00<?, ?it/s]\n",
      "\n",
      "\n",
      "  0%|▏                                                                                 | 1/600 [00:00<01:07,  8.84it/s]\n",
      "\n",
      "\n",
      "  0%|▎                                                                                 | 2/600 [00:00<01:07,  8.86it/s]\n",
      "\n",
      "\n",
      "  1%|▌                                                                                 | 4/600 [00:00<00:54, 10.94it/s]\n",
      "\n",
      "\n",
      "  1%|▊                                                                                 | 6/600 [00:00<00:50, 11.79it/s]\n",
      "\n",
      "\n",
      "  1%|█                                                                                 | 8/600 [00:00<00:47, 12.37it/s]\n",
      "\n",
      "\n",
      "  2%|█▎                                                                               | 10/600 [00:00<00:47, 12.41it/s]\n",
      "\n",
      "\n",
      "  2%|█▌                                                                               | 12/600 [00:00<00:46, 12.56it/s]\n",
      "\n",
      "\n",
      "  2%|█▉                                                                               | 14/600 [00:01<00:47, 12.35it/s]\n",
      "\n",
      "\n",
      "  3%|██▏                                                                              | 16/600 [00:01<00:49, 11.85it/s]\n",
      "\n",
      "\n",
      "  3%|██▍                                                                              | 18/600 [00:01<00:50, 11.45it/s]\n",
      "\n",
      "\n",
      "  3%|██▋                                                                              | 20/600 [00:01<00:51, 11.17it/s]\n",
      "\n",
      "\n",
      "  4%|██▉                                                                              | 22/600 [00:01<00:51, 11.30it/s]\n",
      "\n",
      "\n",
      "  4%|███▏                                                                             | 24/600 [00:02<00:50, 11.47it/s]\n",
      "\n",
      "\n",
      "  4%|███▌                                                                             | 26/600 [00:02<00:49, 11.55it/s]\n",
      "\n",
      "\n",
      "  5%|███▊                                                                             | 28/600 [00:02<00:49, 11.63it/s]\n",
      "\n",
      "\n",
      "  5%|████                                                                             | 30/600 [00:02<00:49, 11.56it/s]\n",
      "\n",
      "\n",
      "  5%|████▎                                                                            | 32/600 [00:02<00:48, 11.69it/s]\n",
      "\n",
      "\n",
      "  6%|████▌                                                                            | 34/600 [00:02<00:47, 11.80it/s]\n",
      "\n",
      "\n",
      "  6%|████▊                                                                            | 36/600 [00:03<00:48, 11.66it/s]\n",
      "\n",
      "\n",
      "  6%|█████▏                                                                           | 38/600 [00:03<00:48, 11.65it/s]\n",
      "\n",
      "\n",
      "  7%|█████▍                                                                           | 40/600 [00:03<00:47, 11.74it/s]\n",
      "\n",
      "\n",
      "  7%|█████▋                                                                           | 42/600 [00:03<00:47, 11.63it/s]\n",
      "\n",
      "\n",
      "  7%|█████▉                                                                           | 44/600 [00:03<00:48, 11.53it/s]\n",
      "\n",
      "\n",
      "  8%|██████▏                                                                          | 46/600 [00:04<00:48, 11.43it/s]\n",
      "\n",
      "\n",
      "  8%|██████▍                                                                          | 48/600 [00:04<00:48, 11.46it/s]\n",
      "\n",
      "\n",
      "  8%|██████▊                                                                          | 50/600 [00:04<00:47, 11.53it/s]\n",
      "\n",
      "\n",
      "  9%|███████                                                                          | 52/600 [00:04<00:47, 11.55it/s]\n",
      "\n",
      "\n",
      "  9%|███████▎                                                                         | 54/600 [00:04<00:46, 11.63it/s]\n",
      "\n",
      "\n",
      "  9%|███████▌                                                                         | 56/600 [00:04<00:47, 11.57it/s]\n",
      "\n",
      "\n",
      " 10%|███████▊                                                                         | 58/600 [00:05<00:47, 11.42it/s]\n",
      "\n",
      "\n",
      " 10%|████████                                                                         | 60/600 [00:05<00:47, 11.36it/s]\n",
      "\n",
      "\n",
      " 10%|████████▎                                                                        | 62/600 [00:05<00:47, 11.35it/s]\n",
      "\n",
      "\n",
      " 11%|████████▋                                                                        | 64/600 [00:05<00:48, 11.15it/s]\n",
      "\n",
      "\n",
      " 11%|████████▊                                                                        | 65/600 [00:05<00:48, 11.10it/s]\n",
      "\n",
      "\n",
      " 11%|████████▉                                                                        | 66/600 [00:05<00:48, 11.07it/s]\n",
      "\n",
      "\n",
      " 11%|█████████                                                                        | 67/600 [00:06<00:48, 11.05it/s]\n",
      "\n",
      "\n",
      " 12%|█████████▎                                                                       | 69/600 [00:06<00:47, 11.08it/s]\n",
      "\n",
      "\n",
      " 12%|█████████▌                                                                       | 71/600 [00:06<00:47, 11.09it/s]\n",
      "\n",
      "\n",
      " 12%|█████████▊                                                                       | 73/600 [00:06<00:47, 11.12it/s]\n",
      "\n",
      "\n",
      " 12%|██████████▏                                                                      | 75/600 [00:06<00:47, 11.16it/s]\n",
      "\n",
      "\n",
      " 13%|██████████▍                                                                      | 77/600 [00:06<00:46, 11.17it/s]\n",
      "\n",
      "\n",
      " 13%|██████████▋                                                                      | 79/600 [00:07<00:46, 11.21it/s]\n",
      "\n",
      "\n",
      " 14%|██████████▉                                                                      | 81/600 [00:07<00:46, 11.26it/s]\n",
      "\n",
      "\n",
      " 14%|███████████▏                                                                     | 83/600 [00:07<00:45, 11.29it/s]\n",
      "\n",
      "\n",
      " 14%|███████████▍                                                                     | 85/600 [00:07<00:45, 11.26it/s]\n",
      "\n",
      "\n",
      " 14%|███████████▋                                                                     | 87/600 [00:07<00:45, 11.25it/s]\n",
      "\n",
      "\n",
      " 15%|████████████                                                                     | 89/600 [00:07<00:45, 11.19it/s]\n",
      "\n",
      "\n",
      " 15%|████████████▎                                                                    | 91/600 [00:08<00:45, 11.16it/s]\n",
      "\n",
      "\n",
      " 16%|████████████▌                                                                    | 93/600 [00:08<00:45, 11.10it/s]\n",
      "\n",
      "\n",
      " 16%|████████████▊                                                                    | 95/600 [00:08<00:45, 11.01it/s]\n",
      "\n",
      "\n",
      " 16%|████████████▉                                                                    | 96/600 [00:08<00:45, 11.00it/s]\n",
      "\n",
      "\n",
      " 16%|█████████████                                                                    | 97/600 [00:08<00:45, 10.96it/s]\n",
      "\n",
      "\n",
      " 16%|█████████████▏                                                                   | 98/600 [00:08<00:45, 10.93it/s]\n",
      "\n",
      "\n",
      " 16%|█████████████▎                                                                   | 99/600 [00:09<00:45, 10.92it/s]\n",
      "\n",
      "\n",
      " 17%|█████████████▎                                                                  | 100/600 [00:09<00:45, 10.90it/s]\n",
      "\n",
      "\n",
      " 17%|█████████████▍                                                                  | 101/600 [00:09<00:45, 10.88it/s]\n",
      "\n",
      "\n",
      " 17%|█████████████▌                                                                  | 102/600 [00:09<00:45, 10.86it/s]\n",
      "\n",
      "\n",
      " 17%|█████████████▋                                                                  | 103/600 [00:09<00:45, 10.84it/s]\n",
      "\n",
      "\n",
      " 17%|█████████████▊                                                                  | 104/600 [00:09<00:45, 10.83it/s]\n",
      "\n",
      "\n",
      " 18%|██████████████                                                                  | 105/600 [00:09<00:45, 10.81it/s]\n",
      "\n",
      "\n",
      " 18%|██████████████▏                                                                 | 106/600 [00:09<00:45, 10.80it/s]\n",
      "\n",
      "\n",
      " 18%|██████████████▎                                                                 | 107/600 [00:09<00:45, 10.76it/s]\n",
      "\n",
      "\n",
      " 18%|██████████████▍                                                                 | 108/600 [00:10<00:45, 10.75it/s]\n",
      "\n",
      "\n",
      " 18%|██████████████▋                                                                 | 110/600 [00:10<00:45, 10.78it/s]\n",
      "\n",
      "\n",
      " 19%|██████████████▉                                                                 | 112/600 [00:10<00:45, 10.75it/s]\n",
      "\n",
      "\n",
      " 19%|███████████████                                                                 | 113/600 [00:10<00:45, 10.73it/s]\n",
      "\n",
      "\n",
      " 19%|███████████████▏                                                                | 114/600 [00:10<00:45, 10.71it/s]\n",
      "\n",
      "\n",
      " 19%|███████████████▎                                                                | 115/600 [00:10<00:45, 10.70it/s]\n",
      "\n",
      "\n",
      " 20%|███████████████▌                                                                | 117/600 [00:10<00:45, 10.68it/s]\n",
      "\n",
      "\n",
      " 20%|███████████████▋                                                                | 118/600 [00:11<00:45, 10.66it/s]\n",
      "\n",
      "\n",
      " 20%|███████████████▊                                                                | 119/600 [00:11<00:45, 10.64it/s]\n",
      "\n",
      "\n",
      " 20%|████████████████▏                                                               | 121/600 [00:11<00:44, 10.69it/s]\n",
      "\n",
      "\n",
      " 20%|████████████████▍                                                               | 123/600 [00:11<00:44, 10.69it/s]\n",
      "\n",
      "\n",
      " 21%|████████████████▋                                                               | 125/600 [00:11<00:44, 10.67it/s]\n",
      "\n",
      "\n",
      " 21%|████████████████▉                                                               | 127/600 [00:11<00:44, 10.69it/s]\n",
      "\n",
      "\n",
      " 22%|█████████████████▏                                                              | 129/600 [00:12<00:44, 10.67it/s]\n",
      "\n",
      "\n",
      " 22%|█████████████████▍                                                              | 131/600 [00:12<00:43, 10.68it/s]\n",
      "\n",
      "\n",
      " 22%|█████████████████▋                                                              | 133/600 [00:12<00:43, 10.66it/s]\n",
      "\n",
      "\n",
      " 22%|██████████████████                                                              | 135/600 [00:12<00:43, 10.67it/s]\n",
      "\n",
      "\n",
      " 23%|██████████████████▎                                                             | 137/600 [00:12<00:43, 10.65it/s]\n",
      "\n",
      "\n",
      " 23%|██████████████████▌                                                             | 139/600 [00:13<00:43, 10.65it/s]\n",
      "\n",
      "\n",
      " 24%|██████████████████▊                                                             | 141/600 [00:13<00:43, 10.66it/s]\n",
      "\n",
      "\n",
      " 24%|███████████████████                                                             | 143/600 [00:13<00:42, 10.70it/s]\n",
      "\n",
      "\n",
      " 24%|███████████████████▎                                                            | 145/600 [00:13<00:42, 10.70it/s]\n",
      "\n",
      "\n",
      " 24%|███████████████████▌                                                            | 147/600 [00:13<00:42, 10.74it/s]\n",
      "\n",
      "\n",
      " 25%|███████████████████▊                                                            | 149/600 [00:13<00:41, 10.75it/s]\n",
      "\n",
      "\n",
      " 25%|████████████████████▏                                                           | 151/600 [00:14<00:41, 10.73it/s]\n",
      "\n",
      "\n",
      " 26%|████████████████████▍                                                           | 153/600 [00:14<00:41, 10.71it/s]\n",
      "\n",
      "\n",
      " 26%|████████████████████▋                                                           | 155/600 [00:14<00:41, 10.69it/s]\n",
      "\n",
      "\n",
      " 26%|████████████████████▉                                                           | 157/600 [00:14<00:41, 10.67it/s]\n",
      "\n",
      "\n",
      " 26%|█████████████████████▏                                                          | 159/600 [00:14<00:41, 10.65it/s]\n",
      "\n",
      "\n",
      " 27%|█████████████████████▎                                                          | 160/600 [00:15<00:41, 10.63it/s]\n",
      "\n",
      "\n",
      " 27%|█████████████████████▍                                                          | 161/600 [00:15<00:41, 10.63it/s]\n",
      "\n",
      "\n",
      " 27%|█████████████████████▌                                                          | 162/600 [00:15<00:41, 10.61it/s]\n",
      "\n",
      "\n",
      " 27%|█████████████████████▋                                                          | 163/600 [00:15<00:41, 10.61it/s]\n",
      "\n",
      "\n",
      " 27%|█████████████████████▊                                                          | 164/600 [00:15<00:41, 10.60it/s]\n",
      "\n",
      "\n",
      " 28%|██████████████████████                                                          | 165/600 [00:15<00:41, 10.60it/s]\n",
      "\n",
      "\n",
      " 28%|██████████████████████▏                                                         | 166/600 [00:15<00:41, 10.58it/s]\n",
      "\n",
      "\n",
      " 28%|██████████████████████▎                                                         | 167/600 [00:15<00:40, 10.58it/s]\n",
      "\n",
      "\n",
      " 28%|██████████████████████▍                                                         | 168/600 [00:15<00:40, 10.57it/s]\n",
      "\n",
      "\n",
      " 28%|██████████████████████▌                                                         | 169/600 [00:15<00:40, 10.56it/s]\n",
      "\n",
      "\n",
      " 28%|██████████████████████▋                                                         | 170/600 [00:16<00:40, 10.55it/s]\n",
      "\n",
      "\n",
      " 28%|██████████████████████▊                                                         | 171/600 [00:16<00:40, 10.54it/s]\n",
      "\n",
      "\n",
      " 29%|██████████████████████▉                                                         | 172/600 [00:16<00:40, 10.53it/s]\n",
      "\n",
      "\n",
      " 29%|███████████████████████                                                         | 173/600 [00:16<00:40, 10.52it/s]\n",
      "\n",
      "\n",
      " 29%|███████████████████████▏                                                        | 174/600 [00:16<00:40, 10.52it/s]\n",
      "\n",
      "\n",
      " 29%|███████████████████████▎                                                        | 175/600 [00:16<00:40, 10.51it/s]\n",
      "\n",
      "\n",
      " 29%|███████████████████████▍                                                        | 176/600 [00:16<00:40, 10.50it/s]\n",
      "\n",
      "\n",
      " 30%|███████████████████████▌                                                        | 177/600 [00:16<00:40, 10.49it/s]\n",
      "\n",
      "\n",
      " 30%|███████████████████████▋                                                        | 178/600 [00:16<00:40, 10.49it/s]\n",
      "\n",
      "\n",
      " 30%|███████████████████████▊                                                        | 179/600 [00:17<00:40, 10.48it/s]\n",
      "\n",
      "\n",
      " 30%|████████████████████████                                                        | 180/600 [00:17<00:40, 10.47it/s]\n",
      "\n",
      "\n",
      " 30%|████████████████████████▏                                                       | 181/600 [00:17<00:40, 10.46it/s]\n",
      "\n",
      "\n",
      " 30%|████████████████████████▎                                                       | 182/600 [00:17<00:39, 10.45it/s]\n",
      "\n",
      "\n",
      " 30%|████████████████████████▍                                                       | 183/600 [00:17<00:39, 10.45it/s]\n",
      "\n",
      "\n",
      " 31%|████████████████████████▌                                                       | 184/600 [00:17<00:39, 10.44it/s]\n",
      "\n",
      "\n",
      " 31%|████████████████████████▋                                                       | 185/600 [00:17<00:39, 10.44it/s]\n",
      "\n",
      "\n",
      " 31%|████████████████████████▊                                                       | 186/600 [00:17<00:39, 10.43it/s]\n",
      "\n",
      "\n",
      " 31%|████████████████████████▉                                                       | 187/600 [00:17<00:39, 10.42it/s]\n",
      "\n",
      "\n",
      " 31%|█████████████████████████                                                       | 188/600 [00:18<00:39, 10.42it/s]\n",
      "\n",
      "\n",
      " 32%|█████████████████████████▏                                                      | 189/600 [00:18<00:39, 10.41it/s]\n",
      "\n",
      "\n",
      " 32%|█████████████████████████▎                                                      | 190/600 [00:18<00:39, 10.40it/s]\n",
      "\n",
      "\n",
      " 32%|█████████████████████████▍                                                      | 191/600 [00:18<00:39, 10.38it/s]\n",
      "\n",
      "\n",
      " 32%|█████████████████████████▌                                                      | 192/600 [00:18<00:39, 10.37it/s]\n",
      "\n",
      "\n",
      " 32%|█████████████████████████▋                                                      | 193/600 [00:18<00:39, 10.37it/s]\n",
      "\n",
      "\n",
      " 32%|█████████████████████████▊                                                      | 194/600 [00:18<00:39, 10.36it/s]\n",
      "\n",
      "\n",
      " 32%|██████████████████████████                                                      | 195/600 [00:18<00:39, 10.35it/s]\n",
      "\n",
      "\n",
      " 33%|██████████████████████████▏                                                     | 196/600 [00:18<00:39, 10.35it/s]\n",
      "\n",
      "\n",
      " 33%|██████████████████████████▎                                                     | 197/600 [00:19<00:38, 10.34it/s]\n",
      "\n",
      "\n",
      " 33%|██████████████████████████▌                                                     | 199/600 [00:19<00:38, 10.38it/s]\n",
      "\n",
      "\n",
      " 34%|██████████████████████████▊                                                     | 201/600 [00:19<00:38, 10.37it/s]\n",
      "\n",
      "\n",
      " 34%|███████████████████████████                                                     | 203/600 [00:19<00:38, 10.40it/s]\n",
      "\n",
      "\n",
      " 34%|███████████████████████████▎                                                    | 205/600 [00:19<00:37, 10.44it/s]\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███████████████████████████▌                                                    | 207/600 [00:19<00:37, 10.47it/s]\n",
      "\n",
      "\n",
      " 35%|███████████████████████████▊                                                    | 209/600 [00:19<00:37, 10.50it/s]\n",
      "\n",
      "\n",
      " 35%|████████████████████████████▏                                                   | 211/600 [00:20<00:36, 10.53it/s]\n",
      "\n",
      "\n",
      " 36%|████████████████████████████▍                                                   | 213/600 [00:20<00:36, 10.50it/s]\n",
      "\n",
      "\n",
      " 36%|████████████████████████████▋                                                   | 215/600 [00:20<00:36, 10.46it/s]\n",
      "\n",
      "\n",
      " 36%|████████████████████████████▉                                                   | 217/600 [00:20<00:36, 10.49it/s]\n",
      "\n",
      "\n",
      " 36%|█████████████████████████████▏                                                  | 219/600 [00:20<00:36, 10.52it/s]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-979d31a96131>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[1;31m#img = cv2.resize(cv2.imread(os.path.join(test_path,name))[:,:,0],(img_width,img_height))/255\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m     \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_path\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_width\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mimg_height\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m     \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCOLOR_BGR2RGB\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m255\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[1;31m#print(img)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 36%|█████████████████████████████▏                                                  | 219/600 [00:33<00:57,  6.59it/s]"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "import gc\n",
    "import os \n",
    "from tqdm import tqdm\n",
    "model.load_weights('keras_ph2_swa.model')\n",
    "test_path = 'C:/Users/hyc/Desktop/skin_lesion/2017/2017/test_gt/'\n",
    "prediction_path ='C:/Users/hyc/Desktop/skin_lesion/2017/prediction/'\n",
    "if not os.path.exists(prediction_path):\n",
    "    os.mkdir(prediction_path)\n",
    "test_img_list = []\n",
    "for name in tqdm(os.listdir(test_path)):\n",
    "    #img = cv2.resize(cv2.imread(os.path.join(test_path,name))[:,:,0],(img_width,img_height))/255\n",
    "    img = cv2.resize(cv2.imread(os.path.join(test_path,name)),(img_width,img_height))\n",
    "    img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)/255\n",
    "    #print(img)\n",
    "    #print(img.shape)\n",
    "    img = np.expand_dims(img,axis=0)\n",
    "    #img = np.expand_dims(img,axis=-1)\n",
    "    pred = model.predict(img)\n",
    "    pred = 255-pred[0,:,:,0]*255\n",
    "    cv2.imwrite(prediction_path+name,pred)\n",
    "    \n",
    "end = time.time()\n",
    "print(\"total_test_time: {}\".format(end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 379/379 [00:19<00:00, 19.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_testing_time:19.85120916366577\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import gc\n",
    "import os \n",
    "from tqdm import tqdm\n",
    "start = time.time()\n",
    "model.load_weights('./keras.model')\n",
    "test_path = './seg_test/'\n",
    "prediction_path ='./predictio_B/'\n",
    "if not os.path.exists(prediction_path):\n",
    "    os.mkdir(prediction_path)\n",
    "test_img_list = []\n",
    "for name in tqdm(os.listdir(test_path)):\n",
    "    orig = cv2.imread(os.path.join(test_path,name))\n",
    "    img = cv2.resize(orig,(img_width,img_height))/255\n",
    "    #print(img)\n",
    "    #print(img.shape)\n",
    "    img = np.expand_dims(img,axis=0)\n",
    "    #img = np.expand_dims(img,axis=-1)\n",
    "    pred = model.predict(img)\n",
    "    pred = (pred[0,:,:,0]>0.5)*255\n",
    "    try:\n",
    "\n",
    "        label_img = label(pred)\n",
    "        regions = regionprops(label_img)\n",
    "        area_list = []\n",
    "        for region in regions:\n",
    "            area_list.append(region.area)\n",
    "        \n",
    "        index_max = np.argmax(area_list)\n",
    "        pred[label_img!=index_max+1]=0\n",
    "    except:\n",
    "        pass\n",
    "    #pred = cv2.cvtColor(pred,cv2.COLOR_GRAY2BGR)\n",
    "    #print(pred.shape)\n",
    "    #pred = cv2.resize(pred,orig.shape[:2])\n",
    "    cv2.imwrite(prediction_path+name,pred)\n",
    "    \n",
    "end = time.time()\n",
    "print('total_testing_time:{}'.format(end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model_lovasz' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-50-aef7a5a0f71a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel_lovasz\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'unet.hdf5'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_lovasz\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mActivation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'sigmoid'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mmodel_lovasz_sigmoid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_lovasz\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mmodel_lovasz_sigmoid\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model_lovasz' is not defined"
     ]
    }
   ],
   "source": [
    "model_lovasz.load_weights('unet.hdf5')\n",
    "x = model_lovasz.output\n",
    "x = Activation('sigmoid')(x)\n",
    "model_lovasz_sigmoid = Model(model_lovasz.input,x)\n",
    "model_lovasz_sigmoid.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(900, 256, 256, 1)\n"
     ]
    }
   ],
   "source": [
    "print(prediction.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "prediction_path ='./prediction/'\n",
    "if not os.path.exists(prediction_path):\n",
    "    os.mkdir(prediction_path)\n",
    "\n",
    "name_list = os.listdir(test_path)\n",
    "for i in range(prediction.shape[0]):\n",
    "    \n",
    "    pred = prediction[i,:,:]\n",
    "   # print(np.sum(pred))\n",
    "    cv2.imwrite(prediction_path+name_list[i],pred*255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 192, 256, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1 (Conv2D)           (None, 95, 127, 32)  864         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1_bn (BatchNormaliza (None, 95, 127, 32)  128         block1_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1_act (Activation)   (None, 95, 127, 32)  0           block1_conv1_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2 (Conv2D)           (None, 93, 125, 64)  18432       block1_conv1_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2_bn (BatchNormaliza (None, 93, 125, 64)  256         block1_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2_act (Activation)   (None, 93, 125, 64)  0           block1_conv2_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv1 (SeparableConv2 (None, 93, 125, 128) 8768        block1_conv2_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv1_bn (BatchNormal (None, 93, 125, 128) 512         block2_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv2_act (Activation (None, 93, 125, 128) 0           block2_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv2 (SeparableConv2 (None, 93, 125, 128) 17536       block2_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv2_bn (BatchNormal (None, 93, 125, 128) 512         block2_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 47, 63, 128)  8192        block1_conv2_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block2_pool (MaxPooling2D)      (None, 47, 63, 128)  0           block2_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 47, 63, 128)  512         conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 47, 63, 128)  0           block2_pool[0][0]                \n",
      "                                                                 batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv1_act (Activation (None, 47, 63, 128)  0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv1 (SeparableConv2 (None, 47, 63, 256)  33920       block3_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv1_bn (BatchNormal (None, 47, 63, 256)  1024        block3_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv2_act (Activation (None, 47, 63, 256)  0           block3_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv2 (SeparableConv2 (None, 47, 63, 256)  67840       block3_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv2_bn (BatchNormal (None, 47, 63, 256)  1024        block3_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 24, 32, 256)  32768       add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block3_pool (MaxPooling2D)      (None, 24, 32, 256)  0           block3_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 24, 32, 256)  1024        conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 24, 32, 256)  0           block3_pool[0][0]                \n",
      "                                                                 batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv1_act (Activation (None, 24, 32, 256)  0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv1 (SeparableConv2 (None, 24, 32, 728)  188672      block4_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv1_bn (BatchNormal (None, 24, 32, 728)  2912        block4_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv2_act (Activation (None, 24, 32, 728)  0           block4_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv2 (SeparableConv2 (None, 24, 32, 728)  536536      block4_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv2_bn (BatchNormal (None, 24, 32, 728)  2912        block4_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 12, 16, 728)  186368      add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block4_pool (MaxPooling2D)      (None, 12, 16, 728)  0           block4_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 12, 16, 728)  2912        conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 12, 16, 728)  0           block4_pool[0][0]                \n",
      "                                                                 batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv1_act (Activation (None, 12, 16, 728)  0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv1 (SeparableConv2 (None, 12, 16, 728)  536536      block5_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv1_bn (BatchNormal (None, 12, 16, 728)  2912        block5_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv2_act (Activation (None, 12, 16, 728)  0           block5_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv2 (SeparableConv2 (None, 12, 16, 728)  536536      block5_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv2_bn (BatchNormal (None, 12, 16, 728)  2912        block5_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv3_act (Activation (None, 12, 16, 728)  0           block5_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv3 (SeparableConv2 (None, 12, 16, 728)  536536      block5_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv3_bn (BatchNormal (None, 12, 16, 728)  2912        block5_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 12, 16, 728)  0           block5_sepconv3_bn[0][0]         \n",
      "                                                                 add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv1_act (Activation (None, 12, 16, 728)  0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv1 (SeparableConv2 (None, 12, 16, 728)  536536      block6_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv1_bn (BatchNormal (None, 12, 16, 728)  2912        block6_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv2_act (Activation (None, 12, 16, 728)  0           block6_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv2 (SeparableConv2 (None, 12, 16, 728)  536536      block6_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv2_bn (BatchNormal (None, 12, 16, 728)  2912        block6_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv3_act (Activation (None, 12, 16, 728)  0           block6_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv3 (SeparableConv2 (None, 12, 16, 728)  536536      block6_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv3_bn (BatchNormal (None, 12, 16, 728)  2912        block6_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 12, 16, 728)  0           block6_sepconv3_bn[0][0]         \n",
      "                                                                 add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv1_act (Activation (None, 12, 16, 728)  0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv1 (SeparableConv2 (None, 12, 16, 728)  536536      block7_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv1_bn (BatchNormal (None, 12, 16, 728)  2912        block7_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv2_act (Activation (None, 12, 16, 728)  0           block7_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv2 (SeparableConv2 (None, 12, 16, 728)  536536      block7_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv2_bn (BatchNormal (None, 12, 16, 728)  2912        block7_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv3_act (Activation (None, 12, 16, 728)  0           block7_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv3 (SeparableConv2 (None, 12, 16, 728)  536536      block7_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv3_bn (BatchNormal (None, 12, 16, 728)  2912        block7_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 12, 16, 728)  0           block7_sepconv3_bn[0][0]         \n",
      "                                                                 add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv1_act (Activation (None, 12, 16, 728)  0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv1 (SeparableConv2 (None, 12, 16, 728)  536536      block8_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv1_bn (BatchNormal (None, 12, 16, 728)  2912        block8_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv2_act (Activation (None, 12, 16, 728)  0           block8_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv2 (SeparableConv2 (None, 12, 16, 728)  536536      block8_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv2_bn (BatchNormal (None, 12, 16, 728)  2912        block8_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv3_act (Activation (None, 12, 16, 728)  0           block8_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv3 (SeparableConv2 (None, 12, 16, 728)  536536      block8_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv3_bn (BatchNormal (None, 12, 16, 728)  2912        block8_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 12, 16, 728)  0           block8_sepconv3_bn[0][0]         \n",
      "                                                                 add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv1_act (Activation (None, 12, 16, 728)  0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "block9_sepconv1 (SeparableConv2 (None, 12, 16, 728)  536536      block9_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv1_bn (BatchNormal (None, 12, 16, 728)  2912        block9_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv2_act (Activation (None, 12, 16, 728)  0           block9_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv2 (SeparableConv2 (None, 12, 16, 728)  536536      block9_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv2_bn (BatchNormal (None, 12, 16, 728)  2912        block9_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv3_act (Activation (None, 12, 16, 728)  0           block9_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv3 (SeparableConv2 (None, 12, 16, 728)  536536      block9_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv3_bn (BatchNormal (None, 12, 16, 728)  2912        block9_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 12, 16, 728)  0           block9_sepconv3_bn[0][0]         \n",
      "                                                                 add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv1_act (Activatio (None, 12, 16, 728)  0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv1 (SeparableConv (None, 12, 16, 728)  536536      block10_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv1_bn (BatchNorma (None, 12, 16, 728)  2912        block10_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv2_act (Activatio (None, 12, 16, 728)  0           block10_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv2 (SeparableConv (None, 12, 16, 728)  536536      block10_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv2_bn (BatchNorma (None, 12, 16, 728)  2912        block10_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv3_act (Activatio (None, 12, 16, 728)  0           block10_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv3 (SeparableConv (None, 12, 16, 728)  536536      block10_sepconv3_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv3_bn (BatchNorma (None, 12, 16, 728)  2912        block10_sepconv3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 12, 16, 728)  0           block10_sepconv3_bn[0][0]        \n",
      "                                                                 add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv1_act (Activatio (None, 12, 16, 728)  0           add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv1 (SeparableConv (None, 12, 16, 728)  536536      block11_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv1_bn (BatchNorma (None, 12, 16, 728)  2912        block11_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv2_act (Activatio (None, 12, 16, 728)  0           block11_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv2 (SeparableConv (None, 12, 16, 728)  536536      block11_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv2_bn (BatchNorma (None, 12, 16, 728)  2912        block11_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv3_act (Activatio (None, 12, 16, 728)  0           block11_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv3 (SeparableConv (None, 12, 16, 728)  536536      block11_sepconv3_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv3_bn (BatchNorma (None, 12, 16, 728)  2912        block11_sepconv3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 12, 16, 728)  0           block11_sepconv3_bn[0][0]        \n",
      "                                                                 add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv1_act (Activatio (None, 12, 16, 728)  0           add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv1 (SeparableConv (None, 12, 16, 728)  536536      block12_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv1_bn (BatchNorma (None, 12, 16, 728)  2912        block12_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv2_act (Activatio (None, 12, 16, 728)  0           block12_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv2 (SeparableConv (None, 12, 16, 728)  536536      block12_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv2_bn (BatchNorma (None, 12, 16, 728)  2912        block12_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv3_act (Activatio (None, 12, 16, 728)  0           block12_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv3 (SeparableConv (None, 12, 16, 728)  536536      block12_sepconv3_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv3_bn (BatchNorma (None, 12, 16, 728)  2912        block12_sepconv3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 12, 16, 728)  0           block12_sepconv3_bn[0][0]        \n",
      "                                                                 add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv1_act (Activatio (None, 12, 16, 728)  0           add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv1 (SeparableConv (None, 12, 16, 728)  536536      block13_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv1_bn (BatchNorma (None, 12, 16, 728)  2912        block13_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv2_act (Activatio (None, 12, 16, 728)  0           block13_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv2 (SeparableConv (None, 12, 16, 1024) 752024      block13_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv2_bn (BatchNorma (None, 12, 16, 1024) 4096        block13_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)       (None, 12, 16, 1024) 0           block13_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 6, 8, 1024)   0           leaky_re_lu_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 6, 8, 1024)   0           max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_1 (SeparableCo (None, 6, 8, 512)    534016      dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)       (None, 6, 8, 512)    0           separable_conv2d_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 6, 8, 512)    2048        leaky_re_lu_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_2 (SeparableCo (None, 6, 8, 512)    267264      batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 6, 8, 512)    2048        separable_conv2d_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)       (None, 6, 8, 512)    0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_3 (SeparableCo (None, 6, 8, 512)    267264      leaky_re_lu_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 6, 8, 512)    2048        separable_conv2d_3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 6, 8, 512)    2048        separable_conv2d_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "add_13 (Add)                    (None, 6, 8, 512)    0           batch_normalization_8[0][0]      \n",
      "                                                                 batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)       (None, 6, 8, 512)    0           add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 6, 8, 512)    2048        leaky_re_lu_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_4 (SeparableCo (None, 6, 8, 512)    267264      batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 6, 8, 512)    2048        separable_conv2d_4[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)       (None, 6, 8, 512)    0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_5 (SeparableCo (None, 6, 8, 512)    267264      leaky_re_lu_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 6, 8, 512)    2048        separable_conv2d_5[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 6, 8, 512)    2048        add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "add_14 (Add)                    (None, 6, 8, 512)    0           batch_normalization_12[0][0]     \n",
      "                                                                 batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)       (None, 6, 8, 512)    0           add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTrans (None, 12, 16, 256)  1179904     leaky_re_lu_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 12, 16, 1280) 0           conv2d_transpose_1[0][0]         \n",
      "                                                                 leaky_re_lu_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 12, 16, 1280) 0           concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_6 (SeparableCo (None, 12, 16, 256)  339456      dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)       (None, 12, 16, 256)  0           separable_conv2d_6[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 12, 16, 256)  1024        leaky_re_lu_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_7 (SeparableCo (None, 12, 16, 256)  68096       batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 12, 16, 256)  1024        separable_conv2d_7[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_8 (LeakyReLU)       (None, 12, 16, 256)  0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_8 (SeparableCo (None, 12, 16, 256)  68096       leaky_re_lu_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 12, 16, 256)  1024        separable_conv2d_8[0][0]         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 12, 16, 256)  1024        separable_conv2d_6[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "add_15 (Add)                    (None, 12, 16, 256)  0           batch_normalization_16[0][0]     \n",
      "                                                                 batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_9 (LeakyReLU)       (None, 12, 16, 256)  0           add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 12, 16, 256)  1024        leaky_re_lu_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_9 (SeparableCo (None, 12, 16, 256)  68096       batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 12, 16, 256)  1024        separable_conv2d_9[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_10 (LeakyReLU)      (None, 12, 16, 256)  0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_10 (SeparableC (None, 12, 16, 256)  68096       leaky_re_lu_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 12, 16, 256)  1024        separable_conv2d_10[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 12, 16, 256)  1024        add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "add_16 (Add)                    (None, 12, 16, 256)  0           batch_normalization_20[0][0]     \n",
      "                                                                 batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "output_4 (LeakyReLU)            (None, 12, 16, 256)  0           add_16[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTrans (None, 24, 32, 128)  295040      output_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 24, 32, 856)  0           conv2d_transpose_2[0][0]         \n",
      "                                                                 block4_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 24, 32, 856)  0           concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_11 (SeparableC (None, 24, 32, 128)  117400      dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_11 (LeakyReLU)      (None, 24, 32, 128)  0           separable_conv2d_11[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 24, 32, 128)  512         leaky_re_lu_11[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_12 (SeparableC (None, 24, 32, 128)  17664       batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 24, 32, 128)  512         separable_conv2d_12[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_12 (LeakyReLU)      (None, 24, 32, 128)  0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_13 (SeparableC (None, 24, 32, 128)  17664       leaky_re_lu_12[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 24, 32, 128)  512         separable_conv2d_13[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 24, 32, 128)  512         separable_conv2d_11[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "add_17 (Add)                    (None, 24, 32, 128)  0           batch_normalization_24[0][0]     \n",
      "                                                                 batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_13 (LeakyReLU)      (None, 24, 32, 128)  0           add_17[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 24, 32, 128)  512         leaky_re_lu_13[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_14 (SeparableC (None, 24, 32, 128)  17664       batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 24, 32, 128)  512         separable_conv2d_14[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_14 (LeakyReLU)      (None, 24, 32, 128)  0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_15 (SeparableC (None, 24, 32, 128)  17664       leaky_re_lu_14[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 24, 32, 128)  512         separable_conv2d_15[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 24, 32, 128)  512         add_17[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "add_18 (Add)                    (None, 24, 32, 128)  0           batch_normalization_28[0][0]     \n",
      "                                                                 batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "output_3 (LeakyReLU)            (None, 24, 32, 128)  0           add_18[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_3 (Conv2DTrans (None, 48, 64, 64)   73792       output_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_1 (ZeroPadding2D (None, 48, 64, 256)  0           block3_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 48, 64, 320)  0           conv2d_transpose_3[0][0]         \n",
      "                                                                 zero_padding2d_1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 48, 64, 320)  0           concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 48, 64, 64)   184384      dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_15 (LeakyReLU)      (None, 48, 64, 64)   0           conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 48, 64, 64)   256         leaky_re_lu_15[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_16 (SeparableC (None, 48, 64, 64)   4736        batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 48, 64, 64)   256         separable_conv2d_16[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_16 (LeakyReLU)      (None, 48, 64, 64)   0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_17 (SeparableC (None, 48, 64, 64)   4736        leaky_re_lu_16[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 48, 64, 64)   256         separable_conv2d_17[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 48, 64, 64)   256         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_19 (Add)                    (None, 48, 64, 64)   0           batch_normalization_32[0][0]     \n",
      "                                                                 batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_17 (LeakyReLU)      (None, 48, 64, 64)   0           add_19[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 48, 64, 64)   256         leaky_re_lu_17[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_18 (SeparableC (None, 48, 64, 64)   4736        batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 48, 64, 64)   256         separable_conv2d_18[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_18 (LeakyReLU)      (None, 48, 64, 64)   0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_19 (SeparableC (None, 48, 64, 64)   4736        leaky_re_lu_18[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 48, 64, 64)   256         separable_conv2d_19[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 48, 64, 64)   256         add_19[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "add_20 (Add)                    (None, 48, 64, 64)   0           batch_normalization_36[0][0]     \n",
      "                                                                 batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "output_2 (LeakyReLU)            (None, 48, 64, 64)   0           add_20[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_4 (Conv2DTrans (None, 96, 128, 32)  18464       output_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_2 (ZeroPadding2D (None, 96, 128, 128) 0           block2_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 96, 128, 160) 0           conv2d_transpose_4[0][0]         \n",
      "                                                                 zero_padding2d_2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 96, 128, 160) 0           concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_20 (SeparableC (None, 96, 128, 32)  6592        dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_19 (LeakyReLU)      (None, 96, 128, 32)  0           separable_conv2d_20[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 96, 128, 32)  128         leaky_re_lu_19[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_21 (SeparableC (None, 96, 128, 32)  1344        batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 96, 128, 32)  128         separable_conv2d_21[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_20 (LeakyReLU)      (None, 96, 128, 32)  0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_22 (SeparableC (None, 96, 128, 32)  1344        leaky_re_lu_20[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 96, 128, 32)  128         separable_conv2d_22[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 96, 128, 32)  128         separable_conv2d_20[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "add_21 (Add)                    (None, 96, 128, 32)  0           batch_normalization_40[0][0]     \n",
      "                                                                 batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_21 (LeakyReLU)      (None, 96, 128, 32)  0           add_21[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 96, 128, 32)  128         leaky_re_lu_21[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_23 (SeparableC (None, 96, 128, 32)  1344        batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, 96, 128, 32)  128         separable_conv2d_23[0][0]        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_22 (LeakyReLU)      (None, 96, 128, 32)  0           batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_24 (SeparableC (None, 96, 128, 32)  1344        leaky_re_lu_22[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, 96, 128, 32)  128         separable_conv2d_24[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, 96, 128, 32)  128         add_21[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "add_22 (Add)                    (None, 96, 128, 32)  0           batch_normalization_44[0][0]     \n",
      "                                                                 batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "output_1 (LeakyReLU)            (None, 96, 128, 32)  0           add_22[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_5 (Conv2DTrans (None, 192, 256, 16) 4624        output_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 192, 256, 16) 0           conv2d_transpose_5[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_25 (SeparableC (None, 192, 256, 16) 416         dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_23 (LeakyReLU)      (None, 192, 256, 16) 0           separable_conv2d_25[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, 192, 256, 16) 64          leaky_re_lu_23[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_26 (SeparableC (None, 192, 256, 16) 416         batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, 192, 256, 16) 64          separable_conv2d_26[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_24 (LeakyReLU)      (None, 192, 256, 16) 0           batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_27 (SeparableC (None, 192, 256, 16) 416         leaky_re_lu_24[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, 192, 256, 16) 64          separable_conv2d_27[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, 192, 256, 16) 64          separable_conv2d_25[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "add_23 (Add)                    (None, 192, 256, 16) 0           batch_normalization_48[0][0]     \n",
      "                                                                 batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_25 (LeakyReLU)      (None, 192, 256, 16) 0           add_23[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, 192, 256, 16) 64          leaky_re_lu_25[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_28 (SeparableC (None, 192, 256, 16) 416         batch_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNo (None, 192, 256, 16) 64          separable_conv2d_28[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_26 (LeakyReLU)      (None, 192, 256, 16) 0           batch_normalization_51[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_29 (SeparableC (None, 192, 256, 16) 416         leaky_re_lu_26[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_52 (BatchNo (None, 192, 256, 16) 64          separable_conv2d_29[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, 192, 256, 16) 64          add_23[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "add_24 (Add)                    (None, 192, 256, 16) 0           batch_normalization_52[0][0]     \n",
      "                                                                 batch_normalization_50[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "output_0 (LeakyReLU)            (None, 192, 256, 16) 0           add_24[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 192, 256, 16) 0           output_0[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 192, 256, 1)  17          dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "prediction (Activation)         (None, 192, 256, 1)  0           conv2d_6[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 19,580,385\n",
      "Trainable params: 19,518,945\n",
      "Non-trainable params: 61,440\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|                                                                                          | 0/600 [00:00<?, ?it/s]\n",
      "\n",
      "  0%|▏                                                                                 | 1/600 [00:03<30:17,  3.03s/it]\n",
      "\n",
      "  0%|▎                                                                                 | 2/600 [00:03<15:53,  1.59s/it]\n",
      "\n",
      "  0%|▍                                                                                 | 3/600 [00:03<11:08,  1.12s/it]\n",
      "\n",
      "  1%|▌                                                                                 | 4/600 [00:03<08:43,  1.14it/s]\n",
      "\n",
      "  1%|▋                                                                                 | 5/600 [00:03<07:15,  1.37it/s]\n",
      "\n",
      "  1%|▊                                                                                 | 6/600 [00:03<06:16,  1.58it/s]\n",
      "\n",
      "  1%|▉                                                                                 | 7/600 [00:03<05:34,  1.77it/s]\n",
      "\n",
      "  1%|█                                                                                 | 8/600 [00:04<05:03,  1.95it/s]\n",
      "\n",
      "  2%|█▏                                                                                | 9/600 [00:04<04:38,  2.12it/s]\n",
      "\n",
      "  2%|█▎                                                                               | 10/600 [00:04<04:19,  2.27it/s]\n",
      "\n",
      "  2%|█▍                                                                               | 11/600 [00:04<04:03,  2.42it/s]\n",
      "\n",
      "  2%|█▌                                                                               | 12/600 [00:04<03:49,  2.56it/s]\n",
      "\n",
      "  2%|█▊                                                                               | 13/600 [00:04<03:38,  2.69it/s]\n",
      "\n",
      "  2%|█▉                                                                               | 14/600 [00:04<03:28,  2.81it/s]\n",
      "\n",
      "  2%|██                                                                               | 15/600 [00:05<03:20,  2.92it/s]\n",
      "\n",
      "  3%|██▏                                                                              | 16/600 [00:05<03:12,  3.04it/s]\n",
      "\n",
      "  3%|██▎                                                                              | 17/600 [00:05<03:07,  3.11it/s]\n",
      "\n",
      "  3%|██▍                                                                              | 18/600 [00:05<03:01,  3.21it/s]\n",
      "\n",
      "  3%|██▌                                                                              | 19/600 [00:05<02:56,  3.30it/s]\n",
      "\n",
      "  3%|██▋                                                                              | 20/600 [00:05<02:51,  3.37it/s]\n",
      "\n",
      "  4%|██▊                                                                              | 21/600 [00:06<02:47,  3.45it/s]\n",
      "\n",
      "  4%|██▉                                                                              | 22/600 [00:06<02:43,  3.53it/s]\n",
      "\n",
      "  4%|███                                                                              | 23/600 [00:06<02:39,  3.61it/s]\n",
      "\n",
      "  4%|███▏                                                                             | 24/600 [00:06<02:38,  3.64it/s]\n",
      "\n",
      "  4%|███▍                                                                             | 25/600 [00:06<02:34,  3.71it/s]\n",
      "\n",
      "  4%|███▌                                                                             | 26/600 [00:06<02:32,  3.78it/s]\n",
      "\n",
      "  4%|███▋                                                                             | 27/600 [00:07<02:35,  3.69it/s]\n",
      "\n",
      "  5%|███▊                                                                             | 28/600 [00:07<02:33,  3.74it/s]\n",
      "\n",
      "  5%|███▉                                                                             | 29/600 [00:07<02:30,  3.79it/s]\n",
      "\n",
      "  5%|████                                                                             | 30/600 [00:07<02:28,  3.84it/s]\n",
      "\n",
      "  5%|████▏                                                                            | 31/600 [00:07<02:26,  3.89it/s]\n",
      "\n",
      "  5%|████▎                                                                            | 32/600 [00:08<02:24,  3.92it/s]\n",
      "\n",
      "  6%|████▍                                                                            | 33/600 [00:08<02:22,  3.97it/s]\n",
      "\n",
      "  6%|████▌                                                                            | 34/600 [00:08<02:21,  4.01it/s]\n",
      "\n",
      "  6%|████▋                                                                            | 35/600 [00:08<02:19,  4.05it/s]\n",
      "\n",
      "  6%|████▊                                                                            | 36/600 [00:08<02:17,  4.09it/s]\n",
      "\n",
      "  6%|████▉                                                                            | 37/600 [00:08<02:16,  4.13it/s]\n",
      "\n",
      "  6%|█████▏                                                                           | 38/600 [00:09<02:14,  4.17it/s]\n",
      "\n",
      "  6%|█████▎                                                                           | 39/600 [00:09<02:13,  4.21it/s]\n",
      "\n",
      "  7%|█████▍                                                                           | 40/600 [00:09<02:11,  4.25it/s]\n",
      "\n",
      "  7%|█████▌                                                                           | 41/600 [00:09<02:10,  4.29it/s]\n",
      "\n",
      "  7%|█████▋                                                                           | 42/600 [00:09<02:09,  4.32it/s]\n",
      "\n",
      "  7%|█████▊                                                                           | 43/600 [00:09<02:07,  4.35it/s]\n",
      "\n",
      "  7%|█████▉                                                                           | 44/600 [00:10<02:06,  4.39it/s]\n",
      "\n",
      "  8%|██████                                                                           | 45/600 [00:10<02:05,  4.43it/s]\n",
      "\n",
      "  8%|██████▏                                                                          | 46/600 [00:10<02:04,  4.46it/s]\n",
      "\n",
      "  8%|██████▎                                                                          | 47/600 [00:10<02:03,  4.49it/s]\n",
      "\n",
      "  8%|██████▍                                                                          | 48/600 [00:10<02:02,  4.52it/s]\n",
      "\n",
      "  8%|██████▌                                                                          | 49/600 [00:10<02:01,  4.55it/s]\n",
      "\n",
      "  8%|██████▊                                                                          | 50/600 [00:10<02:00,  4.58it/s]\n",
      "\n",
      "  8%|██████▉                                                                          | 51/600 [00:11<01:59,  4.60it/s]\n",
      "\n",
      "  9%|███████                                                                          | 52/600 [00:11<01:58,  4.63it/s]\n",
      "\n",
      "  9%|███████▏                                                                         | 53/600 [00:11<02:01,  4.50it/s]\n",
      "\n",
      "  9%|███████▎                                                                         | 54/600 [00:11<02:00,  4.53it/s]\n",
      "\n",
      "  9%|███████▍                                                                         | 55/600 [00:12<01:59,  4.55it/s]\n",
      "\n",
      "  9%|███████▌                                                                         | 56/600 [00:12<01:58,  4.58it/s]\n",
      "\n",
      " 10%|███████▋                                                                         | 57/600 [00:12<01:57,  4.61it/s]\n",
      "\n",
      " 10%|███████▊                                                                         | 58/600 [00:12<01:57,  4.63it/s]\n",
      "\n",
      " 10%|███████▉                                                                         | 59/600 [00:12<01:57,  4.59it/s]\n",
      "\n",
      " 10%|████████                                                                         | 60/600 [00:13<01:57,  4.61it/s]\n",
      "\n",
      " 10%|████████▏                                                                        | 61/600 [00:13<01:56,  4.63it/s]\n",
      "\n",
      " 10%|████████▎                                                                        | 62/600 [00:13<01:55,  4.65it/s]\n",
      "\n",
      " 10%|████████▌                                                                        | 63/600 [00:13<01:54,  4.68it/s]\n",
      "\n",
      " 11%|████████▋                                                                        | 64/600 [00:13<01:54,  4.70it/s]\n",
      "\n",
      " 11%|████████▊                                                                        | 65/600 [00:13<01:53,  4.72it/s]\n",
      "\n",
      " 11%|████████▉                                                                        | 66/600 [00:13<01:52,  4.74it/s]\n",
      "\n",
      " 11%|█████████                                                                        | 67/600 [00:14<01:51,  4.76it/s]\n",
      "\n",
      " 11%|█████████▏                                                                       | 68/600 [00:14<01:51,  4.78it/s]\n",
      "\n",
      " 12%|█████████▎                                                                       | 69/600 [00:14<01:50,  4.80it/s]\n",
      "\n",
      " 12%|█████████▍                                                                       | 70/600 [00:14<01:49,  4.82it/s]\n",
      "\n",
      " 12%|█████████▌                                                                       | 71/600 [00:14<01:49,  4.84it/s]\n",
      "\n",
      " 12%|█████████▋                                                                       | 72/600 [00:14<01:48,  4.86it/s]\n",
      "\n",
      " 12%|█████████▊                                                                       | 73/600 [00:14<01:48,  4.87it/s]\n",
      "\n",
      " 12%|█████████▉                                                                       | 74/600 [00:15<01:47,  4.88it/s]\n",
      "\n",
      " 12%|██████████▏                                                                      | 75/600 [00:15<01:47,  4.90it/s]\n",
      "\n",
      " 13%|██████████▎                                                                      | 76/600 [00:15<01:46,  4.92it/s]\n",
      "\n",
      " 13%|██████████▍                                                                      | 77/600 [00:15<01:45,  4.94it/s]\n",
      "\n",
      " 13%|██████████▌                                                                      | 78/600 [00:15<01:45,  4.96it/s]\n",
      "\n",
      " 13%|██████████▋                                                                      | 79/600 [00:15<01:44,  4.98it/s]\n",
      "\n",
      " 13%|██████████▊                                                                      | 80/600 [00:16<01:44,  4.99it/s]\n",
      "\n",
      " 14%|██████████▉                                                                      | 81/600 [00:16<01:43,  5.01it/s]\n",
      "\n",
      " 14%|███████████                                                                      | 82/600 [00:16<01:43,  5.02it/s]\n",
      "\n",
      " 14%|███████████▏                                                                     | 83/600 [00:16<01:42,  5.04it/s]\n",
      "\n",
      " 14%|███████████▎                                                                     | 84/600 [00:16<01:42,  5.05it/s]\n",
      "\n",
      " 14%|███████████▍                                                                     | 85/600 [00:16<01:41,  5.07it/s]\n",
      "\n",
      " 14%|███████████▌                                                                     | 86/600 [00:16<01:41,  5.09it/s]\n",
      "\n",
      " 14%|███████████▋                                                                     | 87/600 [00:17<01:40,  5.10it/s]\n",
      "\n",
      " 15%|███████████▉                                                                     | 88/600 [00:17<01:40,  5.12it/s]\n",
      "\n",
      " 15%|████████████                                                                     | 89/600 [00:17<01:39,  5.13it/s]\n",
      "\n",
      " 15%|████████████▏                                                                    | 90/600 [00:17<01:39,  5.15it/s]\n",
      "\n",
      " 15%|████████████▎                                                                    | 91/600 [00:17<01:38,  5.17it/s]\n",
      "\n",
      " 15%|████████████▍                                                                    | 92/600 [00:17<01:38,  5.17it/s]\n",
      "\n",
      " 16%|████████████▌                                                                    | 93/600 [00:17<01:37,  5.19it/s]\n",
      "\n",
      " 16%|████████████▋                                                                    | 94/600 [00:18<01:37,  5.19it/s]\n",
      "\n",
      " 16%|████████████▊                                                                    | 95/600 [00:18<01:38,  5.10it/s]\n",
      "\n",
      " 16%|████████████▉                                                                    | 96/600 [00:18<01:38,  5.11it/s]\n",
      "\n",
      " 16%|█████████████                                                                    | 97/600 [00:18<01:38,  5.12it/s]\n",
      "\n",
      " 16%|█████████████▏                                                                   | 98/600 [00:19<01:37,  5.13it/s]\n",
      "\n",
      " 16%|█████████████▎                                                                   | 99/600 [00:19<01:37,  5.14it/s]\n",
      "\n",
      " 17%|█████████████▎                                                                  | 100/600 [00:19<01:37,  5.15it/s]\n",
      "\n",
      " 17%|█████████████▍                                                                  | 101/600 [00:19<01:36,  5.16it/s]\n",
      "\n",
      " 17%|█████████████▌                                                                  | 102/600 [00:19<01:36,  5.17it/s]\n",
      "\n",
      " 17%|█████████████▋                                                                  | 103/600 [00:19<01:35,  5.19it/s]\n",
      "\n",
      " 17%|█████████████▊                                                                  | 104/600 [00:20<01:35,  5.20it/s]\n",
      "\n",
      " 18%|██████████████                                                                  | 105/600 [00:20<01:34,  5.21it/s]\n",
      "\n",
      " 18%|██████████████▏                                                                 | 106/600 [00:20<01:34,  5.23it/s]\n",
      "\n",
      " 18%|██████████████▎                                                                 | 107/600 [00:20<01:34,  5.24it/s]\n",
      "\n",
      " 18%|██████████████▍                                                                 | 108/600 [00:20<01:33,  5.25it/s]\n",
      "\n",
      " 18%|██████████████▌                                                                 | 109/600 [00:20<01:33,  5.26it/s]\n",
      "\n",
      " 18%|██████████████▋                                                                 | 110/600 [00:20<01:33,  5.27it/s]\n",
      "\n",
      " 18%|██████████████▊                                                                 | 111/600 [00:21<01:32,  5.28it/s]\n",
      "\n",
      " 19%|██████████████▉                                                                 | 112/600 [00:21<01:32,  5.29it/s]\n",
      "\n",
      " 19%|███████████████                                                                 | 113/600 [00:21<01:31,  5.30it/s]\n",
      "\n",
      " 19%|███████████████▏                                                                | 114/600 [00:21<01:31,  5.30it/s]\n",
      "\n",
      " 19%|███████████████▎                                                                | 115/600 [00:21<01:31,  5.32it/s]\n",
      "\n",
      " 19%|███████████████▍                                                                | 116/600 [00:21<01:30,  5.33it/s]\n",
      "\n",
      " 20%|███████████████▌                                                                | 117/600 [00:21<01:30,  5.34it/s]\n",
      "\n",
      " 20%|███████████████▋                                                                | 118/600 [00:22<01:30,  5.32it/s]\n",
      "\n",
      " 20%|███████████████▊                                                                | 119/600 [00:22<01:30,  5.33it/s]\n",
      "\n",
      " 20%|████████████████                                                                | 120/600 [00:22<01:29,  5.34it/s]\n",
      "\n",
      " 20%|████████████████▏                                                               | 121/600 [00:22<01:29,  5.34it/s]\n",
      "\n",
      " 20%|████████████████▎                                                               | 122/600 [00:22<01:29,  5.35it/s]\n",
      "\n",
      " 20%|████████████████▍                                                               | 123/600 [00:22<01:28,  5.36it/s]\n",
      "\n",
      " 21%|████████████████▌                                                               | 124/600 [00:23<01:28,  5.38it/s]\n",
      "\n",
      " 21%|████████████████▋                                                               | 125/600 [00:23<01:28,  5.39it/s]\n",
      "\n",
      " 21%|████████████████▊                                                               | 126/600 [00:23<01:27,  5.40it/s]\n",
      "\n",
      " 21%|████████████████▉                                                               | 127/600 [00:23<01:27,  5.41it/s]\n",
      "\n",
      " 21%|█████████████████                                                               | 128/600 [00:23<01:27,  5.42it/s]\n",
      "\n",
      " 22%|█████████████████▏                                                              | 129/600 [00:23<01:26,  5.43it/s]\n",
      "\n",
      " 22%|█████████████████▎                                                              | 130/600 [00:23<01:26,  5.42it/s]\n",
      "\n",
      " 22%|█████████████████▍                                                              | 131/600 [00:24<01:26,  5.43it/s]\n",
      "\n",
      " 22%|█████████████████▌                                                              | 132/600 [00:24<01:26,  5.44it/s]\n",
      "\n",
      " 22%|█████████████████▋                                                              | 133/600 [00:24<01:25,  5.45it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|█████████████████▊                                                              | 134/600 [00:24<01:25,  5.46it/s]\n",
      "\n",
      " 22%|██████████████████                                                              | 135/600 [00:24<01:25,  5.47it/s]\n",
      "\n",
      " 23%|██████████████████▏                                                             | 136/600 [00:24<01:24,  5.47it/s]\n",
      "\n",
      " 23%|██████████████████▎                                                             | 137/600 [00:25<01:24,  5.47it/s]\n",
      "\n",
      " 23%|██████████████████▍                                                             | 138/600 [00:25<01:24,  5.48it/s]\n",
      "\n",
      " 23%|██████████████████▌                                                             | 139/600 [00:25<01:25,  5.40it/s]\n",
      "\n",
      " 23%|██████████████████▋                                                             | 140/600 [00:25<01:25,  5.41it/s]\n",
      "\n",
      " 24%|██████████████████▊                                                             | 141/600 [00:26<01:24,  5.41it/s]\n",
      "\n",
      " 24%|██████████████████▉                                                             | 142/600 [00:26<01:24,  5.41it/s]\n",
      "\n",
      " 24%|███████████████████                                                             | 143/600 [00:26<01:24,  5.38it/s]\n",
      "\n",
      " 24%|███████████████████▏                                                            | 144/600 [00:26<01:25,  5.36it/s]\n",
      "\n",
      " 24%|███████████████████▎                                                            | 145/600 [00:27<01:24,  5.36it/s]\n",
      "\n",
      " 24%|███████████████████▍                                                            | 146/600 [00:27<01:24,  5.37it/s]\n",
      "\n",
      " 24%|███████████████████▌                                                            | 147/600 [00:27<01:24,  5.38it/s]\n",
      "\n",
      " 25%|███████████████████▋                                                            | 148/600 [00:27<01:23,  5.38it/s]\n",
      "\n",
      " 25%|███████████████████▊                                                            | 149/600 [00:27<01:24,  5.33it/s]\n",
      "\n",
      " 25%|████████████████████                                                            | 150/600 [00:28<01:24,  5.33it/s]\n",
      "\n",
      " 25%|████████████████████▏                                                           | 151/600 [00:28<01:24,  5.34it/s]\n",
      "\n",
      " 25%|████████████████████▎                                                           | 152/600 [00:28<01:23,  5.34it/s]\n",
      "\n",
      " 26%|████████████████████▍                                                           | 153/600 [00:28<01:23,  5.35it/s]\n",
      "\n",
      " 26%|████████████████████▌                                                           | 154/600 [00:28<01:23,  5.36it/s]\n",
      "\n",
      " 26%|████████████████████▋                                                           | 155/600 [00:28<01:22,  5.37it/s]\n",
      "\n",
      " 26%|████████████████████▊                                                           | 156/600 [00:29<01:22,  5.37it/s]\n",
      "\n",
      " 26%|████████████████████▉                                                           | 157/600 [00:29<01:22,  5.37it/s]\n",
      "\n",
      " 26%|█████████████████████                                                           | 158/600 [00:29<01:22,  5.38it/s]\n",
      "\n",
      " 26%|█████████████████████▏                                                          | 159/600 [00:29<01:21,  5.38it/s]\n",
      "\n",
      " 27%|█████████████████████▎                                                          | 160/600 [00:29<01:21,  5.39it/s]\n",
      "\n",
      " 27%|█████████████████████▍                                                          | 161/600 [00:29<01:21,  5.40it/s]\n",
      "\n",
      " 27%|█████████████████████▌                                                          | 162/600 [00:29<01:21,  5.41it/s]\n",
      "\n",
      " 27%|█████████████████████▋                                                          | 163/600 [00:30<01:20,  5.41it/s]\n",
      "\n",
      " 27%|█████████████████████▊                                                          | 164/600 [00:30<01:20,  5.42it/s]\n",
      "\n",
      " 28%|██████████████████████                                                          | 165/600 [00:30<01:20,  5.43it/s]\n",
      "\n",
      " 28%|██████████████████████▏                                                         | 166/600 [00:30<01:19,  5.43it/s]\n",
      "\n",
      " 28%|██████████████████████▎                                                         | 167/600 [00:30<01:19,  5.44it/s]\n",
      "\n",
      " 28%|██████████████████████▍                                                         | 168/600 [00:30<01:19,  5.45it/s]\n",
      "\n",
      " 28%|██████████████████████▌                                                         | 169/600 [00:30<01:19,  5.45it/s]\n",
      "\n",
      " 28%|██████████████████████▋                                                         | 170/600 [00:31<01:18,  5.46it/s]\n",
      "\n",
      " 28%|██████████████████████▊                                                         | 171/600 [00:31<01:18,  5.47it/s]\n",
      "\n",
      " 29%|██████████████████████▉                                                         | 172/600 [00:31<01:18,  5.47it/s]\n",
      "\n",
      " 29%|███████████████████████                                                         | 173/600 [00:31<01:18,  5.43it/s]\n",
      "\n",
      " 29%|███████████████████████▏                                                        | 174/600 [00:32<01:18,  5.43it/s]\n",
      "\n",
      " 29%|███████████████████████▎                                                        | 175/600 [00:32<01:18,  5.44it/s]\n",
      "\n",
      " 29%|███████████████████████▍                                                        | 176/600 [00:32<01:17,  5.44it/s]\n",
      "\n",
      " 30%|███████████████████████▌                                                        | 177/600 [00:32<01:17,  5.45it/s]\n",
      "\n",
      " 30%|███████████████████████▋                                                        | 178/600 [00:32<01:17,  5.45it/s]\n",
      "\n",
      " 30%|███████████████████████▊                                                        | 179/600 [00:32<01:17,  5.44it/s]\n",
      "\n",
      " 30%|████████████████████████                                                        | 180/600 [00:33<01:17,  5.44it/s]\n",
      "\n",
      " 30%|████████████████████████▏                                                       | 181/600 [00:33<01:16,  5.45it/s]\n",
      "\n",
      " 30%|████████████████████████▎                                                       | 182/600 [00:33<01:16,  5.46it/s]\n",
      "\n",
      " 30%|████████████████████████▍                                                       | 183/600 [00:33<01:16,  5.46it/s]\n",
      "\n",
      " 31%|████████████████████████▌                                                       | 184/600 [00:33<01:16,  5.47it/s]\n",
      "\n",
      " 31%|████████████████████████▋                                                       | 185/600 [00:33<01:15,  5.48it/s]\n",
      "\n",
      " 31%|████████████████████████▊                                                       | 186/600 [00:33<01:15,  5.48it/s]\n",
      "\n",
      " 31%|████████████████████████▉                                                       | 187/600 [00:34<01:15,  5.49it/s]\n",
      "\n",
      " 31%|█████████████████████████                                                       | 188/600 [00:34<01:15,  5.49it/s]\n",
      "\n",
      " 32%|█████████████████████████▏                                                      | 189/600 [00:34<01:14,  5.50it/s]\n",
      "\n",
      " 32%|█████████████████████████▎                                                      | 190/600 [00:34<01:14,  5.51it/s]\n",
      "\n",
      " 32%|█████████████████████████▍                                                      | 191/600 [00:34<01:14,  5.51it/s]\n",
      "\n",
      " 32%|█████████████████████████▌                                                      | 192/600 [00:34<01:13,  5.52it/s]\n",
      "\n",
      " 32%|█████████████████████████▋                                                      | 193/600 [00:34<01:13,  5.52it/s]\n",
      "\n",
      " 32%|█████████████████████████▊                                                      | 194/600 [00:35<01:13,  5.53it/s]\n",
      "\n",
      " 32%|██████████████████████████                                                      | 195/600 [00:35<01:13,  5.53it/s]\n",
      "\n",
      " 33%|██████████████████████████▏                                                     | 196/600 [00:35<01:12,  5.54it/s]\n",
      "\n",
      " 33%|██████████████████████████▎                                                     | 197/600 [00:35<01:12,  5.54it/s]\n",
      "\n",
      " 33%|██████████████████████████▍                                                     | 198/600 [00:35<01:12,  5.54it/s]\n",
      "\n",
      " 33%|██████████████████████████▌                                                     | 199/600 [00:35<01:12,  5.55it/s]\n",
      "\n",
      " 33%|██████████████████████████▋                                                     | 200/600 [00:36<01:12,  5.55it/s]\n",
      "\n",
      " 34%|██████████████████████████▊                                                     | 201/600 [00:36<01:11,  5.54it/s]\n",
      "\n",
      " 34%|██████████████████████████▉                                                     | 202/600 [00:36<01:11,  5.55it/s]\n",
      "\n",
      " 34%|███████████████████████████                                                     | 203/600 [00:36<01:11,  5.55it/s]\n",
      "\n",
      " 34%|███████████████████████████▏                                                    | 204/600 [00:36<01:11,  5.56it/s]\n",
      "\n",
      " 34%|███████████████████████████▎                                                    | 205/600 [00:36<01:11,  5.56it/s]\n",
      "\n",
      " 34%|███████████████████████████▍                                                    | 206/600 [00:37<01:10,  5.56it/s]\n",
      "\n",
      " 34%|███████████████████████████▌                                                    | 207/600 [00:37<01:10,  5.56it/s]\n",
      "\n",
      " 35%|███████████████████████████▋                                                    | 208/600 [00:37<01:10,  5.57it/s]\n",
      "\n",
      " 35%|███████████████████████████▊                                                    | 209/600 [00:37<01:10,  5.57it/s]\n",
      "\n",
      " 35%|████████████████████████████                                                    | 210/600 [00:37<01:09,  5.57it/s]\n",
      "\n",
      " 35%|████████████████████████████▏                                                   | 211/600 [00:37<01:09,  5.58it/s]\n",
      "\n",
      " 35%|████████████████████████████▎                                                   | 212/600 [00:37<01:09,  5.58it/s]\n",
      "\n",
      " 36%|████████████████████████████▍                                                   | 213/600 [00:38<01:09,  5.59it/s]\n",
      "\n",
      " 36%|████████████████████████████▌                                                   | 214/600 [00:38<01:09,  5.59it/s]\n",
      "\n",
      " 36%|████████████████████████████▋                                                   | 215/600 [00:38<01:08,  5.59it/s]\n",
      "\n",
      " 36%|████████████████████████████▊                                                   | 216/600 [00:38<01:08,  5.59it/s]\n",
      "\n",
      " 36%|████████████████████████████▉                                                   | 217/600 [00:38<01:08,  5.60it/s]\n",
      "\n",
      " 36%|█████████████████████████████                                                   | 218/600 [00:38<01:08,  5.59it/s]\n",
      "\n",
      " 36%|█████████████████████████████▏                                                  | 219/600 [00:39<01:08,  5.60it/s]\n",
      "\n",
      " 37%|█████████████████████████████▎                                                  | 220/600 [00:39<01:07,  5.60it/s]\n",
      "\n",
      " 37%|█████████████████████████████▍                                                  | 221/600 [00:39<01:07,  5.60it/s]\n",
      "\n",
      " 37%|█████████████████████████████▌                                                  | 222/600 [00:39<01:07,  5.61it/s]\n",
      "\n",
      " 37%|█████████████████████████████▋                                                  | 223/600 [00:39<01:07,  5.58it/s]\n",
      "\n",
      " 37%|█████████████████████████████▊                                                  | 224/600 [00:40<01:07,  5.58it/s]\n",
      "\n",
      " 38%|██████████████████████████████                                                  | 225/600 [00:40<01:07,  5.59it/s]\n",
      "\n",
      " 38%|██████████████████████████████▏                                                 | 226/600 [00:40<01:06,  5.59it/s]\n",
      "\n",
      " 38%|██████████████████████████████▎                                                 | 227/600 [00:40<01:06,  5.59it/s]\n",
      "\n",
      " 38%|██████████████████████████████▍                                                 | 228/600 [00:40<01:06,  5.59it/s]\n",
      "\n",
      " 38%|██████████████████████████████▌                                                 | 229/600 [00:40<01:06,  5.59it/s]\n",
      "\n",
      " 38%|██████████████████████████████▋                                                 | 230/600 [00:41<01:06,  5.59it/s]\n",
      "\n",
      " 38%|██████████████████████████████▊                                                 | 231/600 [00:41<01:05,  5.60it/s]\n",
      "\n",
      " 39%|██████████████████████████████▉                                                 | 232/600 [00:41<01:05,  5.60it/s]\n",
      "\n",
      " 39%|███████████████████████████████                                                 | 233/600 [00:41<01:05,  5.60it/s]\n",
      "\n",
      " 39%|███████████████████████████████▏                                                | 234/600 [00:41<01:05,  5.60it/s]\n",
      "\n",
      " 39%|███████████████████████████████▎                                                | 235/600 [00:41<01:05,  5.60it/s]\n",
      "\n",
      " 39%|███████████████████████████████▍                                                | 236/600 [00:42<01:04,  5.60it/s]\n",
      "\n",
      " 40%|███████████████████████████████▌                                                | 237/600 [00:42<01:04,  5.61it/s]\n",
      "\n",
      " 40%|███████████████████████████████▋                                                | 238/600 [00:42<01:04,  5.61it/s]\n",
      "\n",
      " 40%|███████████████████████████████▊                                                | 239/600 [00:42<01:04,  5.61it/s]\n",
      "\n",
      " 40%|████████████████████████████████                                                | 240/600 [00:42<01:04,  5.62it/s]\n",
      "\n",
      " 40%|████████████████████████████████▏                                               | 241/600 [00:42<01:03,  5.62it/s]\n",
      "\n",
      " 40%|████████████████████████████████▎                                               | 242/600 [00:43<01:03,  5.62it/s]\n",
      "\n",
      " 40%|████████████████████████████████▍                                               | 243/600 [00:43<01:03,  5.62it/s]\n",
      "\n",
      " 41%|████████████████████████████████▌                                               | 244/600 [00:44<01:05,  5.43it/s]\n",
      "\n",
      " 41%|████████████████████████████████▋                                               | 245/600 [00:45<01:05,  5.43it/s]\n",
      "\n",
      " 41%|████████████████████████████████▊                                               | 246/600 [00:45<01:05,  5.44it/s]\n",
      "\n",
      " 41%|████████████████████████████████▉                                               | 247/600 [00:45<01:04,  5.44it/s]\n",
      "\n",
      " 41%|█████████████████████████████████                                               | 248/600 [00:45<01:04,  5.44it/s]\n",
      "\n",
      " 42%|█████████████████████████████████▏                                              | 249/600 [00:45<01:04,  5.44it/s]\n",
      "\n",
      " 42%|█████████████████████████████████▎                                              | 250/600 [00:45<01:04,  5.44it/s]\n",
      "\n",
      " 42%|█████████████████████████████████▍                                              | 251/600 [00:46<01:04,  5.44it/s]\n",
      "\n",
      " 42%|█████████████████████████████████▌                                              | 252/600 [00:46<01:03,  5.45it/s]\n",
      "\n",
      " 42%|█████████████████████████████████▋                                              | 253/600 [00:46<01:03,  5.45it/s]\n",
      "\n",
      " 42%|█████████████████████████████████▊                                              | 254/600 [00:46<01:03,  5.46it/s]\n",
      "\n",
      " 42%|██████████████████████████████████                                              | 255/600 [00:46<01:03,  5.46it/s]\n",
      "\n",
      " 43%|██████████████████████████████████▏                                             | 256/600 [00:46<01:02,  5.46it/s]\n",
      "\n",
      " 43%|██████████████████████████████████▎                                             | 257/600 [00:47<01:02,  5.47it/s]\n",
      "\n",
      " 43%|██████████████████████████████████▍                                             | 258/600 [00:47<01:02,  5.47it/s]\n",
      "\n",
      " 43%|██████████████████████████████████▌                                             | 259/600 [00:47<01:02,  5.47it/s]\n",
      "\n",
      " 43%|██████████████████████████████████▋                                             | 260/600 [00:47<01:02,  5.48it/s]\n",
      "\n",
      " 44%|██████████████████████████████████▊                                             | 261/600 [00:47<01:01,  5.48it/s]\n",
      "\n",
      " 44%|██████████████████████████████████▉                                             | 262/600 [00:47<01:01,  5.49it/s]\n",
      "\n",
      " 44%|███████████████████████████████████                                             | 263/600 [00:47<01:01,  5.49it/s]\n",
      "\n",
      " 44%|███████████████████████████████████▏                                            | 264/600 [00:48<01:01,  5.50it/s]\n",
      "\n",
      " 44%|███████████████████████████████████▎                                            | 265/600 [00:48<01:00,  5.50it/s]\n",
      "\n",
      " 44%|███████████████████████████████████▍                                            | 266/600 [00:48<01:00,  5.50it/s]\n",
      "\n",
      " 44%|███████████████████████████████████▌                                            | 267/600 [00:48<01:00,  5.51it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|███████████████████████████████████▋                                            | 268/600 [00:48<01:00,  5.51it/s]\n",
      "\n",
      " 45%|███████████████████████████████████▊                                            | 269/600 [00:48<01:00,  5.52it/s]\n",
      "\n",
      " 45%|████████████████████████████████████                                            | 270/600 [00:48<00:59,  5.52it/s]\n",
      "\n",
      " 45%|████████████████████████████████████▏                                           | 271/600 [00:49<00:59,  5.52it/s]\n",
      "\n",
      " 45%|████████████████████████████████████▎                                           | 272/600 [00:49<00:59,  5.53it/s]\n",
      "\n",
      " 46%|████████████████████████████████████▍                                           | 273/600 [00:49<00:59,  5.53it/s]\n",
      "\n",
      " 46%|████████████████████████████████████▌                                           | 274/600 [00:49<00:58,  5.53it/s]\n",
      "\n",
      " 46%|████████████████████████████████████▋                                           | 275/600 [00:49<00:58,  5.53it/s]\n",
      "\n",
      " 46%|████████████████████████████████████▊                                           | 276/600 [00:49<00:58,  5.53it/s]\n",
      "\n",
      " 46%|████████████████████████████████████▉                                           | 277/600 [00:50<00:58,  5.53it/s]\n",
      "\n",
      " 46%|█████████████████████████████████████                                           | 278/600 [00:50<00:58,  5.54it/s]\n",
      "\n",
      " 46%|█████████████████████████████████████▏                                          | 279/600 [00:50<00:57,  5.54it/s]\n",
      "\n",
      " 47%|█████████████████████████████████████▎                                          | 280/600 [00:50<00:57,  5.54it/s]\n",
      "\n",
      " 47%|█████████████████████████████████████▍                                          | 281/600 [00:50<00:57,  5.54it/s]\n",
      "\n",
      " 47%|█████████████████████████████████████▌                                          | 282/600 [00:50<00:57,  5.55it/s]\n",
      "\n",
      " 47%|█████████████████████████████████████▋                                          | 283/600 [00:51<00:57,  5.55it/s]\n",
      "\n",
      " 47%|█████████████████████████████████████▊                                          | 284/600 [00:51<00:56,  5.55it/s]\n",
      "\n",
      " 48%|██████████████████████████████████████                                          | 285/600 [00:51<00:56,  5.55it/s]\n",
      "\n",
      " 48%|██████████████████████████████████████▏                                         | 286/600 [00:51<00:56,  5.55it/s]\n",
      "\n",
      " 48%|██████████████████████████████████████▎                                         | 287/600 [00:51<00:56,  5.55it/s]\n",
      "\n",
      " 48%|██████████████████████████████████████▍                                         | 288/600 [00:51<00:56,  5.56it/s]\n",
      "\n",
      " 48%|██████████████████████████████████████▌                                         | 289/600 [00:51<00:55,  5.56it/s]\n",
      "\n",
      " 48%|██████████████████████████████████████▋                                         | 290/600 [00:52<00:55,  5.56it/s]\n",
      "\n",
      " 48%|██████████████████████████████████████▊                                         | 291/600 [00:52<00:55,  5.56it/s]\n",
      "\n",
      " 49%|██████████████████████████████████████▉                                         | 292/600 [00:52<00:55,  5.57it/s]\n",
      "\n",
      " 49%|███████████████████████████████████████                                         | 293/600 [00:52<00:55,  5.57it/s]\n",
      "\n",
      " 49%|███████████████████████████████████████▏                                        | 294/600 [00:52<00:54,  5.57it/s]\n",
      "\n",
      " 49%|███████████████████████████████████████▎                                        | 295/600 [00:52<00:54,  5.57it/s]\n",
      "\n",
      " 49%|███████████████████████████████████████▍                                        | 296/600 [00:53<00:54,  5.58it/s]\n",
      "\n",
      " 50%|███████████████████████████████████████▌                                        | 297/600 [00:53<00:54,  5.58it/s]\n",
      "\n",
      " 50%|███████████████████████████████████████▋                                        | 298/600 [00:53<00:54,  5.58it/s]\n",
      "\n",
      " 50%|███████████████████████████████████████▊                                        | 299/600 [00:53<00:54,  5.54it/s]\n",
      "\n",
      " 50%|████████████████████████████████████████                                        | 300/600 [00:54<00:54,  5.54it/s]\n",
      "\n",
      " 50%|████████████████████████████████████████▏                                       | 301/600 [00:54<00:53,  5.54it/s]\n",
      "\n",
      " 50%|████████████████████████████████████████▎                                       | 302/600 [00:54<00:53,  5.54it/s]\n",
      "\n",
      " 50%|████████████████████████████████████████▍                                       | 303/600 [00:54<00:53,  5.55it/s]\n",
      "\n",
      " 51%|████████████████████████████████████████▌                                       | 304/600 [00:54<00:53,  5.55it/s]\n",
      "\n",
      " 51%|████████████████████████████████████████▋                                       | 305/600 [00:54<00:53,  5.55it/s]\n",
      "\n",
      " 51%|████████████████████████████████████████▊                                       | 306/600 [00:55<00:53,  5.53it/s]\n",
      "\n",
      " 51%|████████████████████████████████████████▉                                       | 307/600 [00:55<00:53,  5.53it/s]\n",
      "\n",
      " 51%|█████████████████████████████████████████                                       | 308/600 [00:55<00:52,  5.53it/s]\n",
      "\n",
      " 52%|█████████████████████████████████████████▏                                      | 309/600 [00:55<00:52,  5.53it/s]\n",
      "\n",
      " 52%|█████████████████████████████████████████▎                                      | 310/600 [00:56<00:52,  5.53it/s]\n",
      "\n",
      " 52%|█████████████████████████████████████████▍                                      | 311/600 [00:56<00:52,  5.54it/s]\n",
      "\n",
      " 52%|█████████████████████████████████████████▌                                      | 312/600 [00:56<00:51,  5.54it/s]\n",
      "\n",
      " 52%|█████████████████████████████████████████▋                                      | 313/600 [00:56<00:51,  5.54it/s]\n",
      "\n",
      " 52%|█████████████████████████████████████████▊                                      | 314/600 [00:56<00:51,  5.55it/s]\n",
      "\n",
      " 52%|██████████████████████████████████████████                                      | 315/600 [00:56<00:51,  5.55it/s]\n",
      "\n",
      " 53%|██████████████████████████████████████████▏                                     | 316/600 [00:56<00:51,  5.55it/s]\n",
      "\n",
      " 53%|██████████████████████████████████████████▎                                     | 317/600 [00:57<00:50,  5.55it/s]\n",
      "\n",
      " 53%|██████████████████████████████████████████▍                                     | 318/600 [00:57<00:50,  5.56it/s]\n",
      "\n",
      " 53%|██████████████████████████████████████████▌                                     | 319/600 [00:57<00:50,  5.56it/s]\n",
      "\n",
      " 53%|██████████████████████████████████████████▋                                     | 320/600 [00:57<00:50,  5.56it/s]\n",
      "\n",
      " 54%|██████████████████████████████████████████▊                                     | 321/600 [00:57<00:50,  5.56it/s]\n",
      "\n",
      " 54%|██████████████████████████████████████████▉                                     | 322/600 [00:57<00:49,  5.56it/s]\n",
      "\n",
      " 54%|███████████████████████████████████████████                                     | 323/600 [00:58<00:49,  5.56it/s]\n",
      "\n",
      " 54%|███████████████████████████████████████████▏                                    | 324/600 [00:58<00:49,  5.57it/s]\n",
      "\n",
      " 54%|███████████████████████████████████████████▎                                    | 325/600 [00:58<00:49,  5.57it/s]\n",
      "\n",
      " 54%|███████████████████████████████████████████▍                                    | 326/600 [00:58<00:49,  5.57it/s]\n",
      "\n",
      " 55%|███████████████████████████████████████████▌                                    | 327/600 [00:58<00:48,  5.57it/s]\n",
      "\n",
      " 55%|███████████████████████████████████████████▋                                    | 328/600 [00:58<00:48,  5.57it/s]\n",
      "\n",
      " 55%|███████████████████████████████████████████▊                                    | 329/600 [00:59<00:48,  5.57it/s]\n",
      "\n",
      " 55%|████████████████████████████████████████████                                    | 330/600 [00:59<00:48,  5.58it/s]\n",
      "\n",
      " 55%|████████████████████████████████████████████▏                                   | 331/600 [00:59<00:48,  5.58it/s]\n",
      "\n",
      " 55%|████████████████████████████████████████████▎                                   | 332/600 [00:59<00:48,  5.58it/s]\n",
      "\n",
      " 56%|████████████████████████████████████████████▍                                   | 333/600 [00:59<00:47,  5.58it/s]\n",
      "\n",
      " 56%|████████████████████████████████████████████▌                                   | 334/600 [00:59<00:47,  5.59it/s]\n",
      "\n",
      " 56%|████████████████████████████████████████████▋                                   | 335/600 [00:59<00:47,  5.59it/s]\n",
      "\n",
      " 56%|████████████████████████████████████████████▊                                   | 336/600 [01:00<00:47,  5.58it/s]\n",
      "\n",
      " 56%|████████████████████████████████████████████▉                                   | 337/600 [01:00<00:47,  5.58it/s]\n",
      "\n",
      " 56%|█████████████████████████████████████████████                                   | 338/600 [01:00<00:46,  5.58it/s]\n",
      "\n",
      " 56%|█████████████████████████████████████████████▏                                  | 339/600 [01:00<00:46,  5.58it/s]\n",
      "\n",
      " 57%|█████████████████████████████████████████████▎                                  | 340/600 [01:00<00:46,  5.58it/s]\n",
      "\n",
      " 57%|█████████████████████████████████████████████▍                                  | 341/600 [01:01<00:46,  5.59it/s]\n",
      "\n",
      " 57%|█████████████████████████████████████████████▌                                  | 342/600 [01:01<00:46,  5.59it/s]\n",
      "\n",
      " 57%|█████████████████████████████████████████████▋                                  | 343/600 [01:01<00:45,  5.59it/s]\n",
      "\n",
      " 57%|█████████████████████████████████████████████▊                                  | 344/600 [01:01<00:45,  5.59it/s]\n",
      "\n",
      " 57%|██████████████████████████████████████████████                                  | 345/600 [01:01<00:45,  5.59it/s]\n",
      "\n",
      " 58%|██████████████████████████████████████████████▏                                 | 346/600 [01:01<00:45,  5.59it/s]\n",
      "\n",
      " 58%|██████████████████████████████████████████████▎                                 | 347/600 [01:02<00:45,  5.60it/s]\n",
      "\n",
      " 58%|██████████████████████████████████████████████▍                                 | 348/600 [01:02<00:45,  5.60it/s]\n",
      "\n",
      " 58%|██████████████████████████████████████████████▌                                 | 349/600 [01:02<00:44,  5.60it/s]\n",
      "\n",
      " 58%|██████████████████████████████████████████████▋                                 | 350/600 [01:02<00:44,  5.60it/s]\n",
      "\n",
      " 58%|██████████████████████████████████████████████▊                                 | 351/600 [01:02<00:44,  5.61it/s]\n",
      "\n",
      " 59%|██████████████████████████████████████████████▉                                 | 352/600 [01:02<00:44,  5.61it/s]\n",
      "\n",
      " 59%|███████████████████████████████████████████████                                 | 353/600 [01:02<00:44,  5.61it/s]\n",
      "\n",
      " 59%|███████████████████████████████████████████████▏                                | 354/600 [01:03<00:43,  5.61it/s]\n",
      "\n",
      " 59%|███████████████████████████████████████████████▎                                | 355/600 [01:03<00:43,  5.61it/s]\n",
      "\n",
      " 59%|███████████████████████████████████████████████▍                                | 356/600 [01:03<00:43,  5.62it/s]\n",
      "\n",
      " 60%|███████████████████████████████████████████████▌                                | 357/600 [01:03<00:43,  5.62it/s]\n",
      "\n",
      " 60%|███████████████████████████████████████████████▋                                | 358/600 [01:03<00:43,  5.62it/s]\n",
      "\n",
      " 60%|███████████████████████████████████████████████▊                                | 359/600 [01:03<00:42,  5.62it/s]\n",
      "\n",
      " 60%|████████████████████████████████████████████████                                | 360/600 [01:04<00:42,  5.62it/s]\n",
      "\n",
      " 60%|████████████████████████████████████████████████▏                               | 361/600 [01:04<00:42,  5.63it/s]\n",
      "\n",
      " 60%|████████████████████████████████████████████████▎                               | 362/600 [01:04<00:42,  5.63it/s]\n",
      "\n",
      " 60%|████████████████████████████████████████████████▍                               | 363/600 [01:04<00:42,  5.63it/s]\n",
      "\n",
      " 61%|████████████████████████████████████████████████▌                               | 364/600 [01:04<00:42,  5.60it/s]\n",
      "\n",
      " 61%|████████████████████████████████████████████████▋                               | 365/600 [01:05<00:41,  5.60it/s]\n",
      "\n",
      " 61%|████████████████████████████████████████████████▊                               | 366/600 [01:05<00:41,  5.60it/s]\n",
      "\n",
      " 61%|████████████████████████████████████████████████▉                               | 367/600 [01:05<00:41,  5.60it/s]\n",
      "\n",
      " 61%|█████████████████████████████████████████████████                               | 368/600 [01:05<00:41,  5.60it/s]\n",
      "\n",
      " 62%|█████████████████████████████████████████████████▏                              | 369/600 [01:05<00:41,  5.60it/s]\n",
      "\n",
      " 62%|█████████████████████████████████████████████████▎                              | 370/600 [01:06<00:41,  5.60it/s]\n",
      "\n",
      " 62%|█████████████████████████████████████████████████▍                              | 371/600 [01:06<00:40,  5.60it/s]\n",
      "\n",
      " 62%|█████████████████████████████████████████████████▌                              | 372/600 [01:06<00:40,  5.60it/s]\n",
      "\n",
      " 62%|█████████████████████████████████████████████████▋                              | 373/600 [01:06<00:40,  5.60it/s]\n",
      "\n",
      " 62%|█████████████████████████████████████████████████▊                              | 374/600 [01:06<00:40,  5.61it/s]\n",
      "\n",
      " 62%|██████████████████████████████████████████████████                              | 375/600 [01:06<00:40,  5.61it/s]\n",
      "\n",
      " 63%|██████████████████████████████████████████████████▏                             | 376/600 [01:07<00:39,  5.61it/s]\n",
      "\n",
      " 63%|██████████████████████████████████████████████████▎                             | 377/600 [01:07<00:39,  5.61it/s]\n",
      "\n",
      " 63%|██████████████████████████████████████████████████▍                             | 378/600 [01:07<00:39,  5.61it/s]\n",
      "\n",
      " 63%|██████████████████████████████████████████████████▌                             | 379/600 [01:07<00:39,  5.61it/s]\n",
      "\n",
      " 63%|██████████████████████████████████████████████████▋                             | 380/600 [01:07<00:39,  5.61it/s]\n",
      "\n",
      " 64%|██████████████████████████████████████████████████▊                             | 381/600 [01:07<00:38,  5.62it/s]\n",
      "\n",
      " 64%|██████████████████████████████████████████████████▉                             | 382/600 [01:08<00:38,  5.62it/s]\n",
      "\n",
      " 64%|███████████████████████████████████████████████████                             | 383/600 [01:08<00:38,  5.62it/s]\n",
      "\n",
      " 64%|███████████████████████████████████████████████████▏                            | 384/600 [01:08<00:38,  5.62it/s]\n",
      "\n",
      " 64%|███████████████████████████████████████████████████▎                            | 385/600 [01:08<00:38,  5.62it/s]\n",
      "\n",
      " 64%|███████████████████████████████████████████████████▍                            | 386/600 [01:08<00:38,  5.62it/s]\n",
      "\n",
      " 64%|███████████████████████████████████████████████████▌                            | 387/600 [01:08<00:37,  5.62it/s]\n",
      "\n",
      " 65%|███████████████████████████████████████████████████▋                            | 388/600 [01:09<00:37,  5.61it/s]\n",
      "\n",
      " 65%|███████████████████████████████████████████████████▊                            | 389/600 [01:09<00:37,  5.61it/s]\n",
      "\n",
      " 65%|████████████████████████████████████████████████████                            | 390/600 [01:09<00:37,  5.61it/s]\n",
      "\n",
      " 65%|████████████████████████████████████████████████████▏                           | 391/600 [01:09<00:37,  5.61it/s]\n",
      "\n",
      " 65%|████████████████████████████████████████████████████▎                           | 392/600 [01:09<00:37,  5.61it/s]\n",
      "\n",
      " 66%|████████████████████████████████████████████████████▍                           | 393/600 [01:10<00:36,  5.61it/s]\n",
      "\n",
      " 66%|████████████████████████████████████████████████████▌                           | 394/600 [01:10<00:36,  5.61it/s]\n",
      "\n",
      " 66%|████████████████████████████████████████████████████▋                           | 395/600 [01:10<00:36,  5.60it/s]\n",
      "\n",
      " 66%|████████████████████████████████████████████████████▊                           | 396/600 [01:10<00:36,  5.61it/s]\n",
      "\n",
      " 66%|████████████████████████████████████████████████████▉                           | 397/600 [01:10<00:36,  5.61it/s]\n",
      "\n",
      " 66%|█████████████████████████████████████████████████████                           | 398/600 [01:10<00:36,  5.61it/s]\n",
      "\n",
      " 66%|█████████████████████████████████████████████████████▏                          | 399/600 [01:11<00:35,  5.61it/s]\n",
      "\n",
      " 67%|█████████████████████████████████████████████████████▎                          | 400/600 [01:11<00:35,  5.61it/s]\n",
      "\n",
      " 67%|█████████████████████████████████████████████████████▍                          | 401/600 [01:11<00:35,  5.61it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|█████████████████████████████████████████████████████▌                          | 402/600 [01:11<00:35,  5.61it/s]\n",
      "\n",
      " 67%|█████████████████████████████████████████████████████▋                          | 403/600 [01:11<00:35,  5.61it/s]\n",
      "\n",
      " 67%|█████████████████████████████████████████████████████▊                          | 404/600 [01:11<00:34,  5.61it/s]\n",
      "\n",
      " 68%|██████████████████████████████████████████████████████                          | 405/600 [01:12<00:34,  5.61it/s]\n",
      "\n",
      " 68%|██████████████████████████████████████████████████████▏                         | 406/600 [01:12<00:34,  5.62it/s]\n",
      "\n",
      " 68%|██████████████████████████████████████████████████████▎                         | 407/600 [01:12<00:34,  5.62it/s]\n",
      "\n",
      " 68%|██████████████████████████████████████████████████████▍                         | 408/600 [01:12<00:34,  5.62it/s]\n",
      "\n",
      " 68%|██████████████████████████████████████████████████████▌                         | 409/600 [01:12<00:33,  5.62it/s]\n",
      "\n",
      " 68%|██████████████████████████████████████████████████████▋                         | 410/600 [01:12<00:33,  5.62it/s]\n",
      "\n",
      " 68%|██████████████████████████████████████████████████████▊                         | 411/600 [01:13<00:33,  5.62it/s]\n",
      "\n",
      " 69%|██████████████████████████████████████████████████████▉                         | 412/600 [01:13<00:33,  5.63it/s]\n",
      "\n",
      " 69%|███████████████████████████████████████████████████████                         | 413/600 [01:13<00:33,  5.63it/s]\n",
      "\n",
      " 69%|███████████████████████████████████████████████████████▏                        | 414/600 [01:13<00:33,  5.63it/s]\n",
      "\n",
      " 69%|███████████████████████████████████████████████████████▎                        | 415/600 [01:13<00:32,  5.63it/s]\n",
      "\n",
      " 69%|███████████████████████████████████████████████████████▍                        | 416/600 [01:13<00:32,  5.63it/s]\n",
      "\n",
      " 70%|███████████████████████████████████████████████████████▌                        | 417/600 [01:14<00:32,  5.63it/s]\n",
      "\n",
      " 70%|███████████████████████████████████████████████████████▋                        | 418/600 [01:14<00:32,  5.63it/s]\n",
      "\n",
      " 70%|███████████████████████████████████████████████████████▊                        | 419/600 [01:14<00:32,  5.64it/s]\n",
      "\n",
      " 70%|████████████████████████████████████████████████████████                        | 420/600 [01:14<00:31,  5.64it/s]\n",
      "\n",
      " 70%|████████████████████████████████████████████████████████▏                       | 421/600 [01:14<00:31,  5.64it/s]\n",
      "\n",
      " 70%|████████████████████████████████████████████████████████▎                       | 422/600 [01:14<00:31,  5.64it/s]\n",
      "\n",
      " 70%|████████████████████████████████████████████████████████▍                       | 423/600 [01:14<00:31,  5.64it/s]\n",
      "\n",
      " 71%|████████████████████████████████████████████████████████▌                       | 424/600 [01:15<00:31,  5.64it/s]\n",
      "\n",
      " 71%|████████████████████████████████████████████████████████▋                       | 425/600 [01:15<00:31,  5.64it/s]\n",
      "\n",
      " 71%|████████████████████████████████████████████████████████▊                       | 426/600 [01:15<00:30,  5.62it/s]\n",
      "\n",
      " 71%|████████████████████████████████████████████████████████▉                       | 427/600 [01:16<00:30,  5.62it/s]\n",
      "\n",
      " 71%|█████████████████████████████████████████████████████████                       | 428/600 [01:16<00:30,  5.62it/s]\n",
      "\n",
      " 72%|█████████████████████████████████████████████████████████▏                      | 429/600 [01:16<00:30,  5.62it/s]\n",
      "\n",
      " 72%|█████████████████████████████████████████████████████████▎                      | 430/600 [01:16<00:30,  5.62it/s]\n",
      "\n",
      " 72%|█████████████████████████████████████████████████████████▍                      | 431/600 [01:16<00:30,  5.62it/s]\n",
      "\n",
      " 72%|█████████████████████████████████████████████████████████▌                      | 432/600 [01:16<00:29,  5.62it/s]\n",
      "\n",
      " 72%|█████████████████████████████████████████████████████████▋                      | 433/600 [01:16<00:29,  5.63it/s]\n",
      "\n",
      " 72%|█████████████████████████████████████████████████████████▊                      | 434/600 [01:17<00:29,  5.63it/s]\n",
      "\n",
      " 72%|██████████████████████████████████████████████████████████                      | 435/600 [01:17<00:29,  5.63it/s]\n",
      "\n",
      " 73%|██████████████████████████████████████████████████████████▏                     | 436/600 [01:17<00:29,  5.63it/s]\n",
      "\n",
      " 73%|██████████████████████████████████████████████████████████▎                     | 437/600 [01:17<00:28,  5.63it/s]\n",
      "\n",
      " 73%|██████████████████████████████████████████████████████████▍                     | 438/600 [01:17<00:28,  5.63it/s]\n",
      "\n",
      " 73%|██████████████████████████████████████████████████████████▌                     | 439/600 [01:17<00:28,  5.63it/s]\n",
      "\n",
      " 73%|██████████████████████████████████████████████████████████▋                     | 440/600 [01:18<00:28,  5.63it/s]\n",
      "\n",
      " 74%|██████████████████████████████████████████████████████████▊                     | 441/600 [01:18<00:28,  5.63it/s]\n",
      "\n",
      " 74%|██████████████████████████████████████████████████████████▉                     | 442/600 [01:18<00:28,  5.64it/s]\n",
      "\n",
      " 74%|███████████████████████████████████████████████████████████                     | 443/600 [01:18<00:27,  5.64it/s]\n",
      "\n",
      " 74%|███████████████████████████████████████████████████████████▏                    | 444/600 [01:18<00:27,  5.64it/s]\n",
      "\n",
      " 74%|███████████████████████████████████████████████████████████▎                    | 445/600 [01:18<00:27,  5.64it/s]\n",
      "\n",
      " 74%|███████████████████████████████████████████████████████████▍                    | 446/600 [01:19<00:27,  5.64it/s]\n",
      "\n",
      " 74%|███████████████████████████████████████████████████████████▌                    | 447/600 [01:19<00:27,  5.64it/s]\n",
      "\n",
      " 75%|███████████████████████████████████████████████████████████▋                    | 448/600 [01:19<00:26,  5.65it/s]\n",
      "\n",
      " 75%|███████████████████████████████████████████████████████████▊                    | 449/600 [01:19<00:26,  5.65it/s]\n",
      "\n",
      " 75%|████████████████████████████████████████████████████████████                    | 450/600 [01:19<00:26,  5.65it/s]\n",
      "\n",
      " 75%|████████████████████████████████████████████████████████████▏                   | 451/600 [01:19<00:26,  5.65it/s]\n",
      "\n",
      " 75%|████████████████████████████████████████████████████████████▎                   | 452/600 [01:19<00:26,  5.65it/s]\n",
      "\n",
      " 76%|████████████████████████████████████████████████████████████▍                   | 453/600 [01:20<00:25,  5.65it/s]\n",
      "\n",
      " 76%|████████████████████████████████████████████████████████████▌                   | 454/600 [01:20<00:25,  5.66it/s]\n",
      "\n",
      " 76%|████████████████████████████████████████████████████████████▋                   | 455/600 [01:20<00:25,  5.66it/s]\n",
      "\n",
      " 76%|████████████████████████████████████████████████████████████▊                   | 456/600 [01:20<00:25,  5.66it/s]\n",
      "\n",
      " 76%|████████████████████████████████████████████████████████████▉                   | 457/600 [01:20<00:25,  5.65it/s]\n",
      "\n",
      " 76%|█████████████████████████████████████████████████████████████                   | 458/600 [01:20<00:25,  5.66it/s]\n",
      "\n",
      " 76%|█████████████████████████████████████████████████████████████▏                  | 459/600 [01:21<00:24,  5.65it/s]\n",
      "\n",
      " 77%|█████████████████████████████████████████████████████████████▎                  | 460/600 [01:21<00:24,  5.65it/s]\n",
      "\n",
      " 77%|█████████████████████████████████████████████████████████████▍                  | 461/600 [01:21<00:24,  5.65it/s]\n",
      "\n",
      " 77%|█████████████████████████████████████████████████████████████▌                  | 462/600 [01:21<00:24,  5.65it/s]\n",
      "\n",
      " 77%|█████████████████████████████████████████████████████████████▋                  | 463/600 [01:21<00:24,  5.65it/s]\n",
      "\n",
      " 77%|█████████████████████████████████████████████████████████████▊                  | 464/600 [01:22<00:24,  5.65it/s]\n",
      "\n",
      " 78%|██████████████████████████████████████████████████████████████                  | 465/600 [01:22<00:23,  5.64it/s]\n",
      "\n",
      " 78%|██████████████████████████████████████████████████████████████▏                 | 466/600 [01:22<00:23,  5.64it/s]\n",
      "\n",
      " 78%|██████████████████████████████████████████████████████████████▎                 | 467/600 [01:22<00:23,  5.64it/s]\n",
      "\n",
      " 78%|██████████████████████████████████████████████████████████████▍                 | 468/600 [01:22<00:23,  5.64it/s]\n",
      "\n",
      " 78%|██████████████████████████████████████████████████████████████▌                 | 469/600 [01:23<00:23,  5.64it/s]\n",
      "\n",
      " 78%|██████████████████████████████████████████████████████████████▋                 | 470/600 [01:23<00:23,  5.64it/s]\n",
      "\n",
      " 78%|██████████████████████████████████████████████████████████████▊                 | 471/600 [01:23<00:22,  5.62it/s]\n",
      "\n",
      " 79%|██████████████████████████████████████████████████████████████▉                 | 472/600 [01:23<00:22,  5.62it/s]\n",
      "\n",
      " 79%|███████████████████████████████████████████████████████████████                 | 473/600 [01:24<00:22,  5.62it/s]\n",
      "\n",
      " 79%|███████████████████████████████████████████████████████████████▏                | 474/600 [01:24<00:22,  5.62it/s]\n",
      "\n",
      " 79%|███████████████████████████████████████████████████████████████▎                | 475/600 [01:24<00:22,  5.62it/s]\n",
      "\n",
      " 79%|███████████████████████████████████████████████████████████████▍                | 476/600 [01:24<00:22,  5.62it/s]\n",
      "\n",
      " 80%|███████████████████████████████████████████████████████████████▌                | 477/600 [01:24<00:21,  5.62it/s]\n",
      "\n",
      " 80%|███████████████████████████████████████████████████████████████▋                | 478/600 [01:24<00:21,  5.63it/s]\n",
      "\n",
      " 80%|███████████████████████████████████████████████████████████████▊                | 479/600 [01:25<00:21,  5.63it/s]\n",
      "\n",
      " 80%|████████████████████████████████████████████████████████████████                | 480/600 [01:25<00:21,  5.63it/s]\n",
      "\n",
      " 80%|████████████████████████████████████████████████████████████████▏               | 481/600 [01:25<00:21,  5.63it/s]\n",
      "\n",
      " 80%|████████████████████████████████████████████████████████████████▎               | 482/600 [01:25<00:20,  5.64it/s]\n",
      "\n",
      " 80%|████████████████████████████████████████████████████████████████▍               | 483/600 [01:25<00:20,  5.64it/s]\n",
      "\n",
      " 81%|████████████████████████████████████████████████████████████████▌               | 484/600 [01:25<00:20,  5.64it/s]\n",
      "\n",
      " 81%|████████████████████████████████████████████████████████████████▋               | 485/600 [01:26<00:20,  5.64it/s]\n",
      "\n",
      " 81%|████████████████████████████████████████████████████████████████▊               | 486/600 [01:26<00:20,  5.64it/s]\n",
      "\n",
      " 81%|████████████████████████████████████████████████████████████████▉               | 487/600 [01:26<00:20,  5.64it/s]\n",
      "\n",
      " 81%|█████████████████████████████████████████████████████████████████               | 488/600 [01:26<00:19,  5.64it/s]\n",
      "\n",
      " 82%|█████████████████████████████████████████████████████████████████▏              | 489/600 [01:26<00:19,  5.64it/s]\n",
      "\n",
      " 82%|█████████████████████████████████████████████████████████████████▎              | 490/600 [01:27<00:19,  5.63it/s]\n",
      "\n",
      " 82%|█████████████████████████████████████████████████████████████████▍              | 491/600 [01:27<00:19,  5.63it/s]\n",
      "\n",
      " 82%|█████████████████████████████████████████████████████████████████▌              | 492/600 [01:27<00:19,  5.63it/s]\n",
      "\n",
      " 82%|█████████████████████████████████████████████████████████████████▋              | 493/600 [01:27<00:18,  5.63it/s]\n",
      "\n",
      " 82%|█████████████████████████████████████████████████████████████████▊              | 494/600 [01:27<00:18,  5.63it/s]\n",
      "\n",
      " 82%|██████████████████████████████████████████████████████████████████              | 495/600 [01:27<00:18,  5.64it/s]\n",
      "\n",
      " 83%|██████████████████████████████████████████████████████████████████▏             | 496/600 [01:27<00:18,  5.64it/s]\n",
      "\n",
      " 83%|██████████████████████████████████████████████████████████████████▎             | 497/600 [01:28<00:18,  5.64it/s]\n",
      "\n",
      " 83%|██████████████████████████████████████████████████████████████████▍             | 498/600 [01:28<00:18,  5.64it/s]\n",
      "\n",
      " 83%|██████████████████████████████████████████████████████████████████▌             | 499/600 [01:28<00:17,  5.64it/s]\n",
      "\n",
      " 83%|██████████████████████████████████████████████████████████████████▋             | 500/600 [01:28<00:17,  5.64it/s]\n",
      "\n",
      " 84%|██████████████████████████████████████████████████████████████████▊             | 501/600 [01:28<00:17,  5.65it/s]\n",
      "\n",
      " 84%|██████████████████████████████████████████████████████████████████▉             | 502/600 [01:28<00:17,  5.65it/s]\n",
      "\n",
      " 84%|███████████████████████████████████████████████████████████████████             | 503/600 [01:29<00:17,  5.65it/s]\n",
      "\n",
      " 84%|███████████████████████████████████████████████████████████████████▏            | 504/600 [01:29<00:17,  5.64it/s]\n",
      "\n",
      " 84%|███████████████████████████████████████████████████████████████████▎            | 505/600 [01:29<00:16,  5.64it/s]\n",
      "\n",
      " 84%|███████████████████████████████████████████████████████████████████▍            | 506/600 [01:29<00:16,  5.64it/s]\n",
      "\n",
      " 84%|███████████████████████████████████████████████████████████████████▌            | 507/600 [01:29<00:16,  5.64it/s]\n",
      "\n",
      " 85%|███████████████████████████████████████████████████████████████████▋            | 508/600 [01:30<00:16,  5.64it/s]\n",
      "\n",
      " 85%|███████████████████████████████████████████████████████████████████▊            | 509/600 [01:30<00:16,  5.64it/s]\n",
      "\n",
      " 85%|████████████████████████████████████████████████████████████████████            | 510/600 [01:30<00:15,  5.63it/s]\n",
      "\n",
      " 85%|████████████████████████████████████████████████████████████████████▏           | 511/600 [01:30<00:15,  5.63it/s]\n",
      "\n",
      " 85%|████████████████████████████████████████████████████████████████████▎           | 512/600 [01:30<00:15,  5.63it/s]\n",
      "\n",
      " 86%|████████████████████████████████████████████████████████████████████▍           | 513/600 [01:31<00:15,  5.63it/s]\n",
      "\n",
      " 86%|████████████████████████████████████████████████████████████████████▌           | 514/600 [01:31<00:15,  5.63it/s]\n",
      "\n",
      " 86%|████████████████████████████████████████████████████████████████████▋           | 515/600 [01:31<00:15,  5.64it/s]\n",
      "\n",
      " 86%|████████████████████████████████████████████████████████████████████▊           | 516/600 [01:31<00:14,  5.64it/s]\n",
      "\n",
      " 86%|████████████████████████████████████████████████████████████████████▉           | 517/600 [01:31<00:14,  5.63it/s]\n",
      "\n",
      " 86%|█████████████████████████████████████████████████████████████████████           | 518/600 [01:32<00:14,  5.63it/s]\n",
      "\n",
      " 86%|█████████████████████████████████████████████████████████████████████▏          | 519/600 [01:32<00:14,  5.63it/s]\n",
      "\n",
      " 87%|█████████████████████████████████████████████████████████████████████▎          | 520/600 [01:32<00:14,  5.63it/s]\n",
      "\n",
      " 87%|█████████████████████████████████████████████████████████████████████▍          | 521/600 [01:32<00:14,  5.63it/s]\n",
      "\n",
      " 87%|█████████████████████████████████████████████████████████████████████▌          | 522/600 [01:32<00:13,  5.64it/s]\n",
      "\n",
      " 87%|█████████████████████████████████████████████████████████████████████▋          | 523/600 [01:32<00:13,  5.64it/s]\n",
      "\n",
      " 87%|█████████████████████████████████████████████████████████████████████▊          | 524/600 [01:32<00:13,  5.64it/s]\n",
      "\n",
      " 88%|██████████████████████████████████████████████████████████████████████          | 525/600 [01:33<00:13,  5.64it/s]\n",
      "\n",
      " 88%|██████████████████████████████████████████████████████████████████████▏         | 526/600 [01:33<00:13,  5.64it/s]\n",
      "\n",
      " 88%|██████████████████████████████████████████████████████████████████████▎         | 527/600 [01:33<00:12,  5.64it/s]\n",
      "\n",
      " 88%|██████████████████████████████████████████████████████████████████████▍         | 528/600 [01:33<00:12,  5.64it/s]\n",
      "\n",
      " 88%|██████████████████████████████████████████████████████████████████████▌         | 529/600 [01:33<00:12,  5.65it/s]\n",
      "\n",
      " 88%|██████████████████████████████████████████████████████████████████████▋         | 530/600 [01:33<00:12,  5.65it/s]\n",
      "\n",
      " 88%|██████████████████████████████████████████████████████████████████████▊         | 531/600 [01:34<00:12,  5.65it/s]\n",
      "\n",
      " 89%|██████████████████████████████████████████████████████████████████████▉         | 532/600 [01:34<00:12,  5.65it/s]\n",
      "\n",
      " 89%|███████████████████████████████████████████████████████████████████████         | 533/600 [01:34<00:11,  5.65it/s]\n",
      "\n",
      " 89%|███████████████████████████████████████████████████████████████████████▏        | 534/600 [01:34<00:11,  5.65it/s]\n",
      "\n",
      " 89%|███████████████████████████████████████████████████████████████████████▎        | 535/600 [01:34<00:11,  5.65it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|███████████████████████████████████████████████████████████████████████▍        | 536/600 [01:34<00:11,  5.65it/s]\n",
      "\n",
      " 90%|███████████████████████████████████████████████████████████████████████▌        | 537/600 [01:34<00:11,  5.65it/s]\n",
      "\n",
      " 90%|███████████████████████████████████████████████████████████████████████▋        | 538/600 [01:35<00:10,  5.66it/s]\n",
      "\n",
      " 90%|███████████████████████████████████████████████████████████████████████▊        | 539/600 [01:35<00:10,  5.66it/s]\n",
      "\n",
      " 90%|████████████████████████████████████████████████████████████████████████        | 540/600 [01:35<00:10,  5.66it/s]\n",
      "\n",
      " 90%|████████████████████████████████████████████████████████████████████████▏       | 541/600 [01:35<00:10,  5.65it/s]\n",
      "\n",
      " 90%|████████████████████████████████████████████████████████████████████████▎       | 542/600 [01:35<00:10,  5.65it/s]\n",
      "\n",
      " 90%|████████████████████████████████████████████████████████████████████████▍       | 543/600 [01:36<00:10,  5.65it/s]\n",
      "\n",
      " 91%|████████████████████████████████████████████████████████████████████████▌       | 544/600 [01:36<00:09,  5.66it/s]\n",
      "\n",
      " 91%|████████████████████████████████████████████████████████████████████████▋       | 545/600 [01:36<00:09,  5.66it/s]\n",
      "\n",
      " 91%|████████████████████████████████████████████████████████████████████████▊       | 546/600 [01:36<00:09,  5.66it/s]\n",
      "\n",
      " 91%|████████████████████████████████████████████████████████████████████████▉       | 547/600 [01:36<00:09,  5.66it/s]\n",
      "\n",
      " 91%|█████████████████████████████████████████████████████████████████████████       | 548/600 [01:36<00:09,  5.66it/s]\n",
      "\n",
      " 92%|█████████████████████████████████████████████████████████████████████████▏      | 549/600 [01:37<00:09,  5.65it/s]\n",
      "\n",
      " 92%|█████████████████████████████████████████████████████████████████████████▎      | 550/600 [01:37<00:08,  5.64it/s]\n",
      "\n",
      " 92%|█████████████████████████████████████████████████████████████████████████▍      | 551/600 [01:37<00:08,  5.64it/s]\n",
      "\n",
      " 92%|█████████████████████████████████████████████████████████████████████████▌      | 552/600 [01:37<00:08,  5.64it/s]\n",
      "\n",
      " 92%|█████████████████████████████████████████████████████████████████████████▋      | 553/600 [01:38<00:08,  5.64it/s]\n",
      "\n",
      " 92%|█████████████████████████████████████████████████████████████████████████▊      | 554/600 [01:38<00:08,  5.64it/s]\n",
      "\n",
      " 92%|██████████████████████████████████████████████████████████████████████████      | 555/600 [01:38<00:07,  5.64it/s]\n",
      "\n",
      " 93%|██████████████████████████████████████████████████████████████████████████▏     | 556/600 [01:38<00:07,  5.65it/s]\n",
      "\n",
      " 93%|██████████████████████████████████████████████████████████████████████████▎     | 557/600 [01:38<00:07,  5.65it/s]\n",
      "\n",
      " 93%|██████████████████████████████████████████████████████████████████████████▍     | 558/600 [01:38<00:07,  5.65it/s]\n",
      "\n",
      " 93%|██████████████████████████████████████████████████████████████████████████▌     | 559/600 [01:39<00:07,  5.65it/s]\n",
      "\n",
      " 93%|██████████████████████████████████████████████████████████████████████████▋     | 560/600 [01:39<00:07,  5.64it/s]\n",
      "\n",
      " 94%|██████████████████████████████████████████████████████████████████████████▊     | 561/600 [01:39<00:06,  5.65it/s]\n",
      "\n",
      " 94%|██████████████████████████████████████████████████████████████████████████▉     | 562/600 [01:39<00:06,  5.64it/s]\n",
      "\n",
      " 94%|███████████████████████████████████████████████████████████████████████████     | 563/600 [01:39<00:06,  5.64it/s]\n",
      "\n",
      " 94%|███████████████████████████████████████████████████████████████████████████▏    | 564/600 [01:40<00:06,  5.63it/s]\n",
      "\n",
      " 94%|███████████████████████████████████████████████████████████████████████████▎    | 565/600 [01:40<00:06,  5.63it/s]\n",
      "\n",
      " 94%|███████████████████████████████████████████████████████████████████████████▍    | 566/600 [01:40<00:06,  5.63it/s]\n",
      "\n",
      " 94%|███████████████████████████████████████████████████████████████████████████▌    | 567/600 [01:40<00:05,  5.64it/s]\n",
      "\n",
      " 95%|███████████████████████████████████████████████████████████████████████████▋    | 568/600 [01:40<00:05,  5.64it/s]\n",
      "\n",
      " 95%|███████████████████████████████████████████████████████████████████████████▊    | 569/600 [01:40<00:05,  5.63it/s]\n",
      "\n",
      " 95%|████████████████████████████████████████████████████████████████████████████    | 570/600 [01:41<00:05,  5.63it/s]\n",
      "\n",
      " 95%|████████████████████████████████████████████████████████████████████████████▏   | 571/600 [01:41<00:05,  5.64it/s]\n",
      "\n",
      " 95%|████████████████████████████████████████████████████████████████████████████▎   | 572/600 [01:41<00:04,  5.63it/s]\n",
      "\n",
      " 96%|████████████████████████████████████████████████████████████████████████████▍   | 573/600 [01:41<00:04,  5.64it/s]\n",
      "\n",
      " 96%|████████████████████████████████████████████████████████████████████████████▌   | 574/600 [01:41<00:04,  5.64it/s]\n",
      "\n",
      " 96%|████████████████████████████████████████████████████████████████████████████▋   | 575/600 [01:42<00:04,  5.64it/s]\n",
      "\n",
      " 96%|████████████████████████████████████████████████████████████████████████████▊   | 576/600 [01:42<00:04,  5.64it/s]\n",
      "\n",
      " 96%|████████████████████████████████████████████████████████████████████████████▉   | 577/600 [01:42<00:04,  5.64it/s]\n",
      "\n",
      " 96%|█████████████████████████████████████████████████████████████████████████████   | 578/600 [01:42<00:03,  5.64it/s]\n",
      "\n",
      " 96%|█████████████████████████████████████████████████████████████████████████████▏  | 579/600 [01:42<00:03,  5.64it/s]\n",
      "\n",
      " 97%|█████████████████████████████████████████████████████████████████████████████▎  | 580/600 [01:42<00:03,  5.64it/s]\n",
      "\n",
      " 97%|█████████████████████████████████████████████████████████████████████████████▍  | 581/600 [01:43<00:03,  5.64it/s]\n",
      "\n",
      " 97%|█████████████████████████████████████████████████████████████████████████████▌  | 582/600 [01:43<00:03,  5.64it/s]\n",
      "\n",
      " 97%|█████████████████████████████████████████████████████████████████████████████▋  | 583/600 [01:43<00:03,  5.64it/s]\n",
      "\n",
      " 97%|█████████████████████████████████████████████████████████████████████████████▊  | 584/600 [01:43<00:02,  5.64it/s]\n",
      "\n",
      " 98%|██████████████████████████████████████████████████████████████████████████████  | 585/600 [01:43<00:02,  5.64it/s]\n",
      "\n",
      " 98%|██████████████████████████████████████████████████████████████████████████████▏ | 586/600 [01:43<00:02,  5.64it/s]\n",
      "\n",
      " 98%|██████████████████████████████████████████████████████████████████████████████▎ | 587/600 [01:44<00:02,  5.64it/s]\n",
      "\n",
      " 98%|██████████████████████████████████████████████████████████████████████████████▍ | 588/600 [01:44<00:02,  5.64it/s]\n",
      "\n",
      " 98%|██████████████████████████████████████████████████████████████████████████████▌ | 589/600 [01:44<00:01,  5.64it/s]\n",
      "\n",
      " 98%|██████████████████████████████████████████████████████████████████████████████▋ | 590/600 [01:44<00:01,  5.64it/s]\n",
      "\n",
      " 98%|██████████████████████████████████████████████████████████████████████████████▊ | 591/600 [01:44<00:01,  5.64it/s]\n",
      "\n",
      " 99%|██████████████████████████████████████████████████████████████████████████████▉ | 592/600 [01:44<00:01,  5.64it/s]\n",
      "\n",
      " 99%|███████████████████████████████████████████████████████████████████████████████ | 593/600 [01:45<00:01,  5.64it/s]\n",
      "\n",
      " 99%|███████████████████████████████████████████████████████████████████████████████▏| 594/600 [01:45<00:01,  5.64it/s]\n",
      "\n",
      " 99%|███████████████████████████████████████████████████████████████████████████████▎| 595/600 [01:45<00:00,  5.64it/s]\n",
      "\n",
      " 99%|███████████████████████████████████████████████████████████████████████████████▍| 596/600 [01:45<00:00,  5.64it/s]\n",
      "\n",
      "100%|███████████████████████████████████████████████████████████████████████████████▌| 597/600 [01:45<00:00,  5.64it/s]\n",
      "\n",
      "100%|███████████████████████████████████████████████████████████████████████████████▋| 598/600 [01:46<00:00,  5.64it/s]\n",
      "\n",
      "100%|███████████████████████████████████████████████████████████████████████████████▊| 599/600 [01:46<00:00,  5.64it/s]\n",
      "\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 600/600 [01:46<00:00,  5.64it/s]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.models import Model, load_model\n",
    "import keras.applications.resnet50 as resnet\n",
    "from keras.layers import UpSampling2D, Conv2D\n",
    "\n",
    "\n",
    "# Please set an appropriate image file\n",
    "INPUT_IMG_FILE = \"./ISIC_0012207.jpg\"\n",
    "\n",
    "################################################################\n",
    "# The following parameters can be changed to other models\n",
    "# that use global average pooling.\n",
    "# e.g.) InceptionResnetV2 / NASNetLarge\n",
    "NETWORK_INPUT_SIZE = (256,192)\n",
    "#MODEL_CLASS = resnet.ResNet50\n",
    "PREPROCESS_FN = resnet.preprocess_input\n",
    "LAST_CONV_LAYER_0 = \"output_0\"\n",
    "LAST_CONV_LAYER_1 = \"output_1\"\n",
    "LAST_CONV_LAYER_2 = \"output_2\"\n",
    "LAST_CONV_LAYER_3 = \"output_3\"\n",
    "LAST_CONV_LAYER_4 = \"output_4\"\n",
    "PRED_LAYER = \"prediction\"\n",
    "\n",
    "K.clear_session()\n",
    "model = UXception_all_separable(input_shape=(img_height,img_width,3))\n",
    "#model = load_model('./weights/2017/keras_dice_coef_0_conv.model')\n",
    "model.summary()\n",
    "model.load_weights('./weights/2017/keras_2017_all_speravle.model')\n",
    "#model.summary()    \n",
    "\n",
    "last_conv_output_0 = model.get_layer(LAST_CONV_LAYER_0).output\n",
    "last_conv_output_1 = model.get_layer(LAST_CONV_LAYER_1).output\n",
    "last_conv_output_2 = model.get_layer(LAST_CONV_LAYER_2).output\n",
    "last_conv_output_3 = model.get_layer(LAST_CONV_LAYER_3).output\n",
    "last_conv_output_4 = model.get_layer(LAST_CONV_LAYER_4).output\n",
    "\n",
    "\n",
    "x0 = UpSampling2D(size=(1, 1))(\n",
    "    last_conv_output_0)\n",
    "x1 = UpSampling2D(size=(2, 2))(\n",
    "    last_conv_output_1)\n",
    "x2 = UpSampling2D(size=(4, 4))(\n",
    "    last_conv_output_2)\n",
    "x3 = UpSampling2D(size=(8, 8))(\n",
    "    last_conv_output_3)\n",
    "x4 = UpSampling2D(size=(16, 16))(\n",
    "    last_conv_output_4)\n",
    "\n",
    "x0 = Conv2D(filters=1, kernel_size=(\n",
    "    1, 1),activation='sigmoid', name=\"predictions_2\")(x0)\n",
    "x1 = Conv2D(filters=1, kernel_size=(\n",
    "    1, 1),activation='sigmoid', name=\"predictions_2\")(x1)\n",
    "x2 = Conv2D(filters=1, kernel_size=(\n",
    "    1, 1),activation='sigmoid', name=\"predictions_2\")(x2)\n",
    "x3 = Conv2D(filters=1, kernel_size=(\n",
    "    1, 1),activation='sigmoid', name=\"predictions_2\")(x3)\n",
    "x4 = Conv2D(filters=1, kernel_size=(\n",
    "    1, 1),activation='sigmoid', name=\"predictions_2\")(x4)\n",
    "\n",
    "\n",
    "model_0 = Model(inputs=model.input,\n",
    "                  outputs=x0)\n",
    "model_1 = Model(inputs=model.input,\n",
    "                  outputs=x1) \n",
    "model_2 = Model(inputs=model.input,\n",
    "                  outputs=x2) \n",
    "model_3 = Model(inputs=model.input,\n",
    "                  outputs=x3)                                          \n",
    "model_4 = Model(inputs=model.input,\n",
    "                  outputs=x4)\n",
    "\n",
    "img_path = 'C:/Users/hyc/Desktop/skin_lesion/2017/2017/test_img_resized/'\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "def make_dir_if_not(path):\n",
    "    if not os.path.exists(path):\n",
    "        os.mkdir(path)\n",
    "for name in tqdm(os.listdir(img_path)):\n",
    "    for num in range(5):\n",
    "        path = './gray_cam_output_{}/'.format(num)\n",
    "        make_dir_if_not(path)\n",
    "    original_img = cv2.imread(img_path+name)/255   \n",
    "    #img = cv2.resize(original_img, NETWORK_INPUT_SIZE)/255\n",
    "    imgs = np.expand_dims(original_img, axis=0)\n",
    "    #for name in\n",
    "    preds_0 = model_0.predict(imgs)[0,:,:,0]\n",
    "    preds_1 = model_1.predict(imgs)[0,:,:,0]\n",
    "    preds_2 = model_2.predict(imgs)[0,:,:,0]\n",
    "    preds_3 = model_3.predict(imgs)[0,:,:,0]\n",
    "    preds_4 = model_4.predict(imgs)[0,:,:,0]\n",
    "\n",
    "    preds_0 = preds_0/np.max(preds_0)\n",
    "   # print(np.max(preds_0))\n",
    "    preds_1 = preds_1/np.max(preds_1)\n",
    "    preds_2 = preds_2/np.max(preds_2)\n",
    "    preds_3 = preds_3/np.max(preds_3)\n",
    "    preds_4 = preds_4/np.max(preds_4)\n",
    "    #preds_0 = cv2.applyColorMap(preds_0, cv2.COLORMAP_JET)\n",
    "    \n",
    "    name_0 = name.replace('.jpg','output_0.jpg')\n",
    "    name_1 = name.replace('.jpg','output_1.jpg')\n",
    "    name_2 = name.replace('.jpg','output_2.jpg')\n",
    "    name_3 = name.replace('.jpg','output_3.jpg')\n",
    "    name_4 = name.replace('.jpg','output_4.jpg')\n",
    "    \n",
    "    \n",
    "    \n",
    "    cv2.imwrite('./gray_cam_output_{}/'.format(0)+name_0,preds_0*255)\n",
    "    cv2.imwrite('./gray_cam_output_{}/'.format(1)+name_1,preds_1*255)\n",
    "    cv2.imwrite('./gray_cam_output_{}/'.format(2)+name_2,preds_2*255)\n",
    "    cv2.imwrite('./gray_cam_output_{}/'.format(3)+name_3,preds_3*255)\n",
    "    cv2.imwrite('./gray_cam_output_{}/'.format(4)+name_4,preds_4*255)\n",
    "\n",
    "    for num in range(5):\n",
    "        path = './color_cam_output_{}/'.format(num)\n",
    "        make_dir_if_not(path)\n",
    "    gray_0 = cv2.imread('./gray_cam_output_{}/'.format(0)+name_0)       \n",
    "    gray_1 = cv2.imread('./gray_cam_output_{}/'.format(1)+name_1)\n",
    "    gray_2 = cv2.imread('./gray_cam_output_{}/'.format(2)+name_2)\n",
    "    gray_3 = cv2.imread('./gray_cam_output_{}/'.format(3)+name_3)\n",
    "    gray_4 = cv2.imread('./gray_cam_output_{}/'.format(4)+name_4)\n",
    "\n",
    "    color_0 = cv2.applyColorMap(gray_0, cv2.COLORMAP_JET)    \n",
    "    color_1 = cv2.applyColorMap(gray_1, cv2.COLORMAP_JET)   \n",
    "    color_2 = cv2.applyColorMap(gray_2, cv2.COLORMAP_JET)   \n",
    "    color_3 = cv2.applyColorMap(gray_3, cv2.COLORMAP_JET)   \n",
    "    color_4 = cv2.applyColorMap(gray_4, cv2.COLORMAP_JET)\n",
    "  \n",
    "    cv2.imwrite('./color_cam_output_{}/'.format(0)+name_0,color_0)    \n",
    "    cv2.imwrite('./color_cam_output_{}/'.format(1)+name_1,color_1)\n",
    "    cv2.imwrite('./color_cam_output_{}/'.format(2)+name_2,color_2)\n",
    "    cv2.imwrite('./color_cam_output_{}/'.format(3)+name_3,color_3)\n",
    "    cv2.imwrite('./color_cam_output_{}/'.format(4)+name_4,color_4)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(192, 256, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "img = cv2.imread('./output_1.jpg')\n",
    "print(img.shape)\n",
    "preds_0 = cv2.applyColorMap(img, cv2.COLORMAP_JET)\n",
    "cv2.imwrite('./output_1_color.jpg',preds_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x468 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(6, 6.5))\n",
    "plt.imshow(np.concatenate([preds_4,preds_3,preds_2,preds_1,preds_0],axis=-1))\n",
    "plt.savefig('output.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 192, 256, 1)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#model.load_weights('./weights/2017/keras_2017_all_speravle.model')\n",
    "preds = cam_model.predict(imgs)\n",
    "print(preds.shape)\n",
    "preds =  preds[0,:,:,0]\n",
    "#preds = np.stack([preds[0,:,:,0]*255,preds[0,:,:,0]*255,preds[0,:,:,0]*255],axis=-1)\n",
    "plt.close()\n",
    "plt.figure(2)\n",
    "plt.pcolor(preds)\n",
    "plt.colorbar()\n",
    "cv2.imwrite('output_1.jpg',preds*255)\n",
    "# 4. post processing\n",
    "plt.axis('off')\n",
    "plt.imshow(preds)\n",
    "plt.savefig('output_2.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "cv2.imwrite('cam.jpg',class_activation_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
