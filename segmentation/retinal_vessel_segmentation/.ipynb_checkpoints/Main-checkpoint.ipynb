{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from experiments.data_loaders.standard_loader import MyDataLoader\n",
    "# from infers.simple_mnist_infer import SimpleMnistInfer\n",
    "from perception.models.dense_unet import  SegmentionModel\n",
    "from perception.trainers.segmention_trainer import SegmentionTrainer\n",
    "from configs.utils.config_utils import process_config\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#print(help(plt.imread))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_train():\n",
    "    \"\"\"\n",
    "    训练模型\n",
    "\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    print('[INFO] Reading Configs...')\n",
    "\n",
    "    config = None\n",
    "\n",
    "    try:\n",
    "        config = process_config('./configs/segmention_config.json')  \n",
    "        config.prob_path = '.\\\\experiments\\\\VesselNet\\\\dataset\\\\DRIVE\\\\train\\\\probmap\\\\'\n",
    "       # config.train_img_path = \".\\\\experiments\\\\VesselNet\\\\dataset\\\\DRIVE\\\\train\\\\dark\\\\\"\n",
    "        #config.train_groundtruth_path = \".\\\\experiments\\\\VesselNet\\\\dataset\\\\DRIVE\\\\train\\\\dark_gt\\\\\"\n",
    "        #config.val_img_path = \".\\\\experiments\\\\VesselNet\\\\dataset\\\\DRIVE\\\\validate\\\\dark\\\\\"\n",
    "        #config.val_groundtruth_path = \".\\\\experiments\\\\VesselNet\\\\dataset\\\\DRIVE\\\\validate\\\\dark_gt\\\\\"\n",
    "         \n",
    "     #   config.train_img_path = \".\\\\experiments\\\\VesselNet\\\\dataset\\\\DRIVE\\\\train\\\\bright\\\\\"\n",
    "     #   config.train_groundtruth_path = \".\\\\experiments\\\\VesselNet\\\\dataset\\\\DRIVE\\\\train\\\\bright_gt\\\\\"\n",
    "     #   config.val_img_path = \".\\\\experiments\\\\VesselNet\\\\dataset\\\\DRIVE\\\\validate\\\\bright\\\\\"\n",
    "     #   config.val_groundtruth_path = \".\\\\experiments\\\\VesselNet\\\\dataset\\\\DRIVE\\\\validate\\\\bright_gt\\\\\"\n",
    "         \n",
    "        \n",
    "        #config.train_img_path = \".\\\\experiments\\\\VesselNet\\\\dataset\\\\HRF\\\\train\\\\images\\\\\"\n",
    "        #config.train_groundtruth_path = \".\\\\experiments\\\\VesselNet\\\\dataset\\\\HRF\\\\train\\\\gt\\\\\"\n",
    "        #config.val_img_path = \".\\\\experiments\\\\VesselNet\\\\dataset\\\\HRF\\\\validate\\\\images\\\\\"\n",
    "        #config.val_groundtruth_path = \".\\\\experiments\\\\VesselNet\\\\dataset\\\\HRF\\\\validate\\\\gt\\\\\"\n",
    "        #config.height = 1168\n",
    "        #config.width = 1727\n",
    "        \n",
    "        #config.val_img_path = \".\\\\experiments\\\\VesselNet\\\\dataset\\\\DRIVE\\\\validate\\\\FOV\\\\\"\n",
    "        #config.val_groundtruth_path = \".\\\\experiments\\\\VesselNet\\\\dataset\\\\DRIVE\\\\validate\\\\FOV_gt\\\\\"\n",
    "\n",
    "\n",
    "        \n",
    "        #config.patch_height = 48\n",
    "        #config.patch_width = 48\n",
    "        #config.stride_width = 5\n",
    "        #config.stride_height = 5\n",
    "        #config.train_img_path = \".\\\\experiments\\\\VesselNet\\\\dataset\\\\DRIVE\\\\validate\\\\origin\\\\\"\n",
    "        #config.train_groundtruth_path = \".\\\\experiments\\\\VesselNet\\\\dataset\\\\DRIVE\\\\validate\\\\pusedo\\\\\"\n",
    "        #config.val_img_path = \".\\\\experiments\\\\VesselNet\\\\dataset\\\\DRIVE\\\\validate\\\\FOV\\\\\"\n",
    "        #config.val_groundtruth_path = \".\\\\experiments\\\\VesselNet\\\\dataset\\\\DRIVE\\\\validate\\\\FOV_gt\\\\\"\n",
    "        #config.height = 540\n",
    "        #config.width = 540\n",
    "        \n",
    "        #config = process_config('./configs/segmention_config_CHASEDB1.json')\n",
    "       # config = process_config('./configs/segmention_config.json')        \n",
    "       # config.train_img_path = \".\\\\experiments\\\\VesselNet\\\\dataset\\\\CHASEDB1\\\\train\\\\\"\n",
    "        #config.train_groundtruth_path =\".\\\\experiments\\\\VesselNet\\\\dataset\\\\train\\\\\"\n",
    "        \n",
    "        #config.val_img_path = \".\\\\experiments\\\\VesselNet\\\\dataset\\\\CHASEDB1\\\\validate\\\\\"\n",
    "        #config.val_groundtruth_path = \".\\\\experiments\\\\VesselNet\\\\dataset\\\\validate\\\\groundtruth\\\\\"\n",
    "        \n",
    "        #config.val_datatype = 'jpg'\n",
    "        #config.val_gt_datatype = 'png'\n",
    "        #config.height  = 960\n",
    "        #config.width = 999\n",
    "        \n",
    "        \n",
    "       # config = process_config('./configs/segmention_config_STARE.json')\n",
    "       #config = process_config('./configs/segmention_config.json')        \n",
    "       # config.train_img_path = \".\\\\experiments\\\\VesselNet\\\\dataset\\\\STARE\\\\img_bmp\\\\\"\n",
    "       # config.train_groundtruth_path =\".\\\\experiments\\\\VesselNet\\\\dataset\\\\STARE\\\\gt_bmp\\\\\"\n",
    "      #  config.val_img_path = \".\\\\experiments\\\\VesselNet\\\\dataset\\\\STARE\\\\img_bmp\\\\\"\n",
    "      #  config.val_groundtruth_path = \".\\\\experiments\\\\VesselNet\\\\dataset\\\\STARE\\\\gt_bmp\\\\\"     \n",
    "      #  config.height = \n",
    "      #  config.width = 700\n",
    "       # config.epochs = 6\n",
    "        \n",
    "       # config.test_img_path =\".\\\\experiments\\\\VesselNet\\\\test\\\\probmap\\\\\"\n",
    "        config.epoch = 30\n",
    "        print(config)\n",
    "    except Exception as e:\n",
    "        print('[Exception] Config Error, %s' % e)\n",
    "        exit(0)\n",
    "    # np.random.seed(47)  # 固定随机数\n",
    "\n",
    "    print('[INFO] Preparing Data...')\n",
    "    #dataloader = MyDataLoader(config=config,dataset='CHASEDB1')\n",
    "    #dataloader = MyDataLoader(config=config,dataset='HRF')\n",
    "    dataloader = MyDataLoader(config=config,dataset='prob')\n",
    "    #dataloader = MyDataLoader(config=config,dataset='CHASEDB1')\n",
    "    dataloader.prepare_dataset()\n",
    "    mode = 'DRIVE'\n",
    "    #target_path = './metric/STARE/'\n",
    "    if mode == 'STARE':\n",
    "        config = process_config('./configs/segmention_config_STARE.json')\n",
    "        config = process_config('./configs/segmention_config.json')        \n",
    "        config.train_img_path = \".\\\\experiments\\\\VesselNet\\\\dataset\\\\STARE\\\\img_bmp\\\\\"\n",
    "        config.train_groundtruth_path =\".\\\\experiments\\\\VesselNet\\\\dataset\\\\STARE\\\\gt_bmp\\\\\"\n",
    "        config.val_img_path = \".\\\\experiments\\\\VesselNet\\\\dataset\\\\STARE\\\\img_bmp\\\\\"\n",
    "        config.val_groundtruth_path = \".\\\\experiments\\\\VesselNet\\\\dataset\\\\STARE\\\\gt_bmp\\\\\"     \n",
    "        config.height = 605\n",
    "        config.width = 700\n",
    "        config.epochs = 6        \n",
    "        total_imgs,total_gt=dataloader.get_train_data()\n",
    "        #print(train_imgs.shape) \n",
    "        \n",
    "        for iter_ in range(20):\n",
    "            if not os.path.exists(target_path+'test'):\n",
    "                os.mkdir(target_path+'test')\n",
    "            if not os.path.exists(target_path+'mask'):\n",
    "                os.mkdir(target_path+'mask')\n",
    "                \n",
    "            val_imgs, val_gt = total_imgs[iter_,:,:,:] , total_gt[iter_,:,:,:]\n",
    "            cv2.imwrite(target_path+'test/'+str(iter_)+'.bmp',val_imgs)\n",
    "            cv2.imwrite(target_path+'tmask/'+str(iter_)+'.bmp',val_gt)\n",
    "            val_imgs = np.expand_dims(val_imgs,0)\n",
    "            val_gt = np.expand_dims(val_gt,0)\n",
    "            if iter_ == 0:\n",
    "                \n",
    "           # val_imgs, val_gt = total_imgs[iter_] , total_gt[iter_]\n",
    "                train_imgs , train_gt = total_imgs[1:,:,:,:], total_gt[1:,:,:,:]\n",
    "                #train_imgs, train_gt = np.expand_dims(train_imgs,0),np.expand_dims(train_gt,0)\n",
    "            elif iter_ == 19:\n",
    "                train_imgs,train_gt = total_imgs[:iter_,:,:,:], total_gt[:iter_,:,:,:] \n",
    "            else:\n",
    "                train_imgs,train_gt = np.concatenate([total_imgs[:iter_,:,:,:],total_imgs[iter_+1:,:,:,:]],axis=0),np.concatenate([total_gt[:iter_,:,:,:],total_gt[iter_+1:,:,:,:]],axis=0)\n",
    "            print(iter_)\n",
    "            print(train_imgs.shape)\n",
    "            print(total_imgs.shape)\n",
    "            print('[INFO] Building Model...')\n",
    "            model = SegmentionModel(config=config)\n",
    "#\n",
    "            print('[INFO] Training...iter:{}'.format(iter_))\n",
    "            trainer = SegmentionTrainer(\n",
    "            model=model.model,\n",
    "            data=[train_imgs,train_gt,val_imgs,val_gt],\n",
    "            config=config,\n",
    "            iter_=iter_)\n",
    "            trainer.train()\n",
    "            print('[INFO] Finishing...iter:{}'.format(iter_))\n",
    "    else:\n",
    "        iter_ = 'prob'\n",
    "        train_imgs, train_gt = dataloader.get_train_data()\n",
    "        val_imgs,val_gt= dataloader.get_val_data()\n",
    "        prob_map = dataloader.get_prob_data()\n",
    "        print(train_imgs.shape)\n",
    "        print(val_imgs.shape)\n",
    "        print(prob_map.shape)\n",
    "        print('[INFO] Building Model...')\n",
    "        model = SegmentionModel(config=config)\n",
    "        \n",
    "        print('[INFO] Training...')\n",
    "        trainer = SegmentionTrainer(\n",
    "        model=model.model,\n",
    "        data=[train_imgs,train_gt,val_imgs,val_gt,prob_map],\n",
    "        config=config,\n",
    "        iter_=iter_)\n",
    "        trainer.train()\n",
    "        print('[INFO] Finishing...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Staring Train\n",
      "[INFO] Reading Configs...\n",
      "batch_size: 25\n",
      "checkpoint: ./experiments\\VesselNet\\checkpoint/\n",
      "epoch: 30\n",
      "epochs: 10\n",
      "exp_name: VesselNet\n",
      "hdf5_path: ./experiments\\VesselNet\\hdf5/\n",
      "height: 584\n",
      "patch_height: 128\n",
      "patch_width: 128\n",
      "prob_path: .\\experiments\\VesselNet\\dataset\\DRIVE\\train\\probmap\\\n",
      "seg_num: 1\n",
      "stride_height: 33\n",
      "stride_width: 33\n",
      "subsample: 500\n",
      "test_datatype: tif\n",
      "test_gt_datatype: tif\n",
      "test_gt_path: ./experiments\\VesselNet\\test/groundtruth/\n",
      "test_img_path: ./experiments\\VesselNet\\test/origin/\n",
      "test_result_path: ./experiments\\VesselNet\\test/result/\n",
      "total_train: 40\n",
      "total_val: 20\n",
      "train_datatype: tif\n",
      "train_groundtruth_path: ./experiments\\VesselNet\\dataset/train/groundtruth/\n",
      "train_gt_datatype: tif\n",
      "train_img_path: ./experiments\\VesselNet\\dataset/train/origin/\n",
      "val_datatype: tif\n",
      "val_groundtruth_path: ./experiments\\VesselNet\\dataset/validate/groundtruth/\n",
      "val_gt_datatype: tif\n",
      "val_img_path: ./experiments\\VesselNet\\dataset/validate/origin/\n",
      "width: 565\n",
      "\n",
      "[INFO] Preparing Data...\n",
      "./experiments\\VesselNet\\dataset/train/origin/\n",
      "./experiments\\VesselNet\\dataset/train/groundtruth/\n",
      "[INFO] Reading...\n",
      "./experiments\\VesselNet\\dataset/validate/origin/\n",
      "./experiments\\VesselNet\\dataset/validate/groundtruth/\n",
      "[INFO] Reading...\n",
      "./experiments\\VesselNet\\dataset/train/origin/\n",
      "./experiments\\VesselNet\\dataset/train/groundtruth/\n",
      "[INFO] Reading...\n",
      "[INFO] Saving Training Data\n",
      "[INFO] Saving Validation Data\n",
      "[INFO] Saving prob Data\n",
      "(40, 584, 565, 1)\n",
      "(20, 584, 565, 1)\n",
      "(40, 1, 584, 565)\n",
      "[INFO] Building Model...\n",
      "[INFO] Saving model...\n",
      "[INFO] Model saved\n",
      "[INFO] Training...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "all the input array dimensions except for the concatenation axis must match exactly",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-38bb43ed796e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'__main__'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Staring Train'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mmain_train\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[1;31m# test_main()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-4-c0174e9ba87e>\u001b[0m in \u001b[0;36mmain_train\u001b[1;34m()\u001b[0m\n\u001b[0;32m    150\u001b[0m         \u001b[0mconfig\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    151\u001b[0m         iter_=iter_)\n\u001b[1;32m--> 152\u001b[1;33m         \u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    153\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'[INFO] Finishing...'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\眼球血管分割代码\\VesselNet\\Retina-VesselNet-master\\Retina-VesselNet-master\\perception\\trainers\\segmention_trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    100\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 102\u001b[1;33m                 \u001b[0mgen\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mDataGenerator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miter_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    103\u001b[0m                 \u001b[1;31m#gen.visual_patch()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m \t\thist = self.model.fit_generator(gen.train_gen(),\n",
      "\u001b[1;32m~\\Desktop\\眼球血管分割代码\\VesselNet\\Retina-VesselNet-master\\Retina-VesselNet-master\\perception\\trainers\\segmention_trainer.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data, config, iter_)\u001b[0m\n\u001b[0;32m    122\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0miter_\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'prob'\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    123\u001b[0m                         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_img\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mimg_process1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 124\u001b[1;33m                         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mval_img\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mimg_process1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    125\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    126\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\眼球血管分割代码\\VesselNet\\Retina-VesselNet-master\\Retina-VesselNet-master\\configs\\utils\\img_utils.py\u001b[0m in \u001b[0;36mimg_process1\u001b[1;34m(data, data2, rl)\u001b[0m\n\u001b[0;32m    171\u001b[0m             \u001b[0mtrain_imgs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain_img\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    172\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 173\u001b[1;33m             \u001b[0mtrain_imgs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain_imgs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdata2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    174\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    175\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: all the input array dimensions except for the concatenation axis must match exactly"
     ]
    }
   ],
   "source": [
    "\n",
    "if __name__ == '__main__':\n",
    "    print('Staring Train')\n",
    "    main_train()\n",
    "    # test_main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Reading Configs...\n",
      "batch_size: 25\n",
      "checkpoint: ./experiments\\VesselNet\\checkpoint/\n",
      "epochs: 10\n",
      "exp_name: VesselNet\n",
      "hdf5_path: ./experiments\\VesselNet\\hdf5/\n",
      "height: 584\n",
      "patch_height: 128\n",
      "patch_width: 128\n",
      "seg_num: 1\n",
      "stride_height: 33\n",
      "stride_width: 33\n",
      "subsample: 500\n",
      "test_datatype: tif\n",
      "test_groundtruth_path: .\\experiments\\VesselNet\\dataset\\DRIVE\\validate\\dark_gt\\\n",
      "test_gt_datatype: tif\n",
      "test_gt_path: ./experiments\\VesselNet\\test/groundtruth/\n",
      "test_img_path: .\\experiments\\VesselNet\\dataset\\DRIVE\\validate\\dark\\\n",
      "test_result_path: ./experiments\\VesselNet\\test/result/\n",
      "total_train: 40\n",
      "total_val: 20\n",
      "train_datatype: tif\n",
      "train_groundtruth_path: ./experiments\\VesselNet\\dataset/train/groundtruth/\n",
      "train_gt_datatype: tif\n",
      "train_img_path: ./experiments\\VesselNet\\dataset/train/origin/\n",
      "val_datatype: tif\n",
      "val_groundtruth_path: ./experiments\\VesselNet\\dataset/validate/groundtruth/\n",
      "val_gt_datatype: tif\n",
      "val_img_path: ./experiments\\VesselNet\\dataset/validate/origin/\n",
      "width: 565\n",
      "\n",
      "[INFO] Predicting...\n",
      "loading_orig_weights\n",
      "10\n",
      "G_ratio:1 R_ratio:0\n",
      "[Info] Analyze filename... 01_test\n",
      "new full images shape: \n",
      "(1, 590, 590, 1)\n",
      "225/225 [==============================] - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - 3s 11ms/step\n",
      "N_patches_h: 15\n",
      "N_patches_w: 15\n",
      "N_patches_img: 225\n",
      "According to the dimension inserted, there are 1 full images (of 590x590 each)\n",
      "225 225\n",
      "using avg\n",
      "(584, 565, 1)\n",
      "G_ratio:1 R_ratio:0\n",
      "[Info] Analyze filename... 03_test\n",
      "new full images shape: \n",
      "(1, 590, 590, 1)\n",
      "225/225 [==============================] - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - 1s 5ms/step\n",
      "N_patches_h: 15\n",
      "N_patches_w: 15\n",
      "N_patches_img: 225\n",
      "According to the dimension inserted, there are 1 full images (of 590x590 each)\n",
      "225 225\n",
      "using avg\n",
      "(584, 565, 1)\n",
      "G_ratio:1 R_ratio:0\n",
      "[Info] Analyze filename... 04_test\n",
      "new full images shape: \n",
      "(1, 590, 590, 1)\n",
      "225/225 [==============================] - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - 1s 5ms/step\n",
      "N_patches_h: 15\n",
      "N_patches_w: 15\n",
      "N_patches_img: 225\n",
      "According to the dimension inserted, there are 1 full images (of 590x590 each)\n",
      "225 225\n",
      "using avg\n",
      "(584, 565, 1)\n",
      "G_ratio:1 R_ratio:0\n",
      "[Info] Analyze filename... 05_test\n",
      "new full images shape: \n",
      "(1, 590, 590, 1)\n",
      "225/225 [==============================] - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - 1s 5ms/step\n",
      "N_patches_h: 15\n",
      "N_patches_w: 15\n",
      "N_patches_img: 225\n",
      "According to the dimension inserted, there are 1 full images (of 590x590 each)\n",
      "225 225\n",
      "using avg\n",
      "(584, 565, 1)\n",
      "G_ratio:1 R_ratio:0\n",
      "[Info] Analyze filename... 06_test\n",
      "new full images shape: \n",
      "(1, 590, 590, 1)\n",
      "225/225 [==============================] - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - 1s 5ms/step\n",
      "N_patches_h: 15\n",
      "N_patches_w: 15\n",
      "N_patches_img: 225\n",
      "According to the dimension inserted, there are 1 full images (of 590x590 each)\n",
      "225 225\n",
      "using avg\n",
      "(584, 565, 1)\n",
      "G_ratio:1 R_ratio:0\n",
      "[Info] Analyze filename... 08_test\n",
      "new full images shape: \n",
      "(1, 590, 590, 1)\n",
      "225/225 [==============================] - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - 1s 5ms/step\n",
      "N_patches_h: 15\n",
      "N_patches_w: 15\n",
      "N_patches_img: 225\n",
      "According to the dimension inserted, there are 1 full images (of 590x590 each)\n",
      "225 225\n",
      "using avg\n",
      "(584, 565, 1)\n",
      "G_ratio:1 R_ratio:0\n",
      "[Info] Analyze filename... 10_test\n",
      "new full images shape: \n",
      "(1, 590, 590, 1)\n",
      "225/225 [==============================] - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - 1s 5ms/step\n",
      "N_patches_h: 15\n",
      "N_patches_w: 15\n",
      "N_patches_img: 225\n",
      "According to the dimension inserted, there are 1 full images (of 590x590 each)\n",
      "225 225\n",
      "using avg\n",
      "(584, 565, 1)\n",
      "G_ratio:1 R_ratio:0\n",
      "[Info] Analyze filename... 15_test\n",
      "new full images shape: \n",
      "(1, 590, 590, 1)\n",
      "225/225 [==============================] - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - 1s 5ms/step\n",
      "N_patches_h: 15\n",
      "N_patches_w: 15\n",
      "N_patches_img: 225\n",
      "According to the dimension inserted, there are 1 full images (of 590x590 each)\n",
      "225 225\n",
      "using avg\n",
      "(584, 565, 1)\n",
      "G_ratio:1 R_ratio:0\n",
      "[Info] Analyze filename... 19_test\n",
      "new full images shape: \n",
      "(1, 590, 590, 1)\n",
      "225/225 [==============================] - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - 1s 5ms/step\n",
      "N_patches_h: 15\n",
      "N_patches_w: 15\n",
      "N_patches_img: 225\n",
      "According to the dimension inserted, there are 1 full images (of 590x590 each)\n",
      "225 225\n",
      "using avg\n",
      "(584, 565, 1)\n",
      "G_ratio:1 R_ratio:0\n",
      "[Info] Analyze filename... 20_test\n",
      "new full images shape: \n",
      "(1, 590, 590, 1)\n",
      "225/225 [==============================] - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - 1s 5ms/step\n",
      "N_patches_h: 15\n",
      "N_patches_w: 15\n",
      "N_patches_img: 225\n",
      "According to the dimension inserted, there are 1 full images (of 590x590 each)\n",
      "225 225\n",
      "using avg\n",
      "(584, 565, 1)\n",
      "[INFO] Metric results...\n",
      "[INFO] Fininshed...\n"
     ]
    }
   ],
   "source": [
    "from perception.infers.segmention_infer import SegmentionInfer\n",
    "#from perception.infers.segmention_infer_STARE import SegmentionInfer\n",
    "\n",
    "from perception.metric.segmention_metric import *\n",
    "from configs.utils.config_utils import process_config\n",
    "\n",
    "\n",
    "repredict=True\n",
    "\n",
    "def main_test():\n",
    "    print('[INFO] Reading Configs...')\n",
    "    config = None\n",
    "\n",
    "    try:\n",
    "        config = process_config('./configs/segmention_config.json')\n",
    "        #config.test_img_path = \".\\\\experiments\\\\VesselNet\\\\dataset\\\\DRIVE\\\\validate\\\\bright\\\\\"\n",
    "        #config.test_groundtruth_path = \".\\\\experiments\\\\VesselNet\\\\dataset\\\\DRIVE\\\\validate\\\\bright_gt\\\\\"\n",
    "        config.test_img_path = \".\\\\experiments\\\\VesselNet\\\\dataset\\\\DRIVE\\\\validate\\\\dark\\\\\"\n",
    "        config.test_groundtruth_path = \".\\\\experiments\\\\VesselNet\\\\dataset\\\\DRIVE\\\\validate\\\\dark_gt\\\\\"\n",
    "           \n",
    "        #config.test_img_path = \".\\\\experiments\\\\VesselNet\\\\dataset\\\\DRIVE\\\\train\\\\semi_validate_img\\\\\"\n",
    "        #config.test_groundtruth_path = \".\\\\experiments\\\\VesselNet\\\\dataset\\\\DRIVE\\\\train\\\\semi_validate_gt\\\\\"\n",
    "        #config.test_result_path = \".\\\\experiments\\\\VesselNet\\\\dataset\\\\DRIVE\\\\train\\\\result\\\\\"\n",
    "\n",
    "        #config.test_img_path = './experiments/VesselNet/dataset/DRIVE/train/origin/'\n",
    "        #config.test_gt_path = './experiments/VesselNet/dataset/DRIVE/train/img_gt/'\n",
    "        \n",
    "        #config = process_config('./configs/segmention_config_CHASEDB1.json')\n",
    "        #config.train_img_path = \".\\\\experiments\\\\VesselNet\\\\dataset\\\\CHASEDB1\\\\train\\\\\"\n",
    "       # config.train_groundtruth_path =\".\\\\experiments\\\\VesselNet\\\\dataset\\\\train\\\\\"\n",
    "        #config.val_img_path = \".\\\\experiments\\\\VesselNet\\\\dataset\\\\CHASEDB1\\\\validate\\\\\"\n",
    "        #config.val_groundtruth_path = \".\\\\experiments\\\\VesselNet\\\\dataset\\\\validate\\\\groundtruth\\\\\"\n",
    "      \n",
    "        #config.test_img_path =\".\\\\experiments\\\\VesselNet\\\\dataset\\\\HRF\\\\validate\\\\images\\\\\"\n",
    "       # config.test_gt_path = '.\\\\experiments\\\\VesselNet\\\\dataset\\\\HRF\\\\validate\\\\gt\\\\'\n",
    "        #config.test_result_path='.\\\\experiments\\\\VesselNet\\\\dataset\\\\HRF\\\\result\\\\'\n",
    "       #config.test_datatype='jpg'\n",
    "       # config.test_gt_datatype ='tif'\n",
    "        #config = process_config('./configs/segmention_config_STARE.json')\n",
    "        #config.test_img_path =\".\\\\experiments\\\\VesselNet\\\\dataset\\\\STARE\\\\img_bmp\\\\\"\n",
    "        #config.test_gt_path = '.\\\\experiments\\\\VesselNet\\\\dataset\\\\STARE\\\\gt_bmp\\\\'\n",
    "        #config.test_result_path='.\\\\experiments\\\\VesselNet\\\\dataset\\\\STARE\\\\result\\\\'\n",
    "        #config.test_datatype='bmp'\n",
    "        #config.test_gt_datatype ='bmp'\n",
    "        #config.patch_height = 48\n",
    "        #config.patch_width = 48        \n",
    "        #config.stride_width = 5\n",
    "        #config.stride_height = 5\n",
    "        \n",
    "        print(config)\n",
    "    except Exception as e:\n",
    "        print('[Exception] Config Error, %s' % e)\n",
    "        exit(0)\n",
    "\n",
    "    if repredict==True:\n",
    "\n",
    "        print('[INFO] Predicting...')\n",
    "        infer = SegmentionInfer(config)\n",
    "        infer.predict()\n",
    "\n",
    "    print('[INFO] Metric results...')\n",
    "    gtlist=fileList(config.test_gt_path,'*'+config.test_gt_datatype)\n",
    "    problist=fileList(config.test_result_path,'*.bmp')\n",
    "    #print(gtlist)\n",
    "   # print()\n",
    "    modelName=['DenseNet-Unet']\n",
    "    #drawCurve(gtlist,[problist],modelName,'DRIVE',config.checkpoint)\n",
    "\n",
    "    print('[INFO] Fininshed...')\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main_test()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
